[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Vertikal Willis",
    "section": "",
    "text": "Hello! Thanks for visiting my website. I’m Vertikal Willis, 25 years old, and single. I’m from Medan and now living in Jakarta. I’ve got total 5 years of work experience, mostly as a buyer/procurement professional. I decided to switch careers to data science because I feel it suits me better. Processing complex data in creative ways to find strong insights and solutions gives me real joy. I think a data scientist is like an artist, be able to make something out of nothing by using data – it’s an art form!\nTo see my complete CV please email to vertikalwillis@gmail.com or contact me through LinkedIn!\n\nEducation\n\nDibimbing DS Bootcamp                                                2023  Data Science Batch 19  -. Most valuable person  -. 2nd best of final project  -. 3 x student of the month \nUniversitas Prima Indonesia                                        2016 - 2020 Bachelor’s degree in industrial engineering -. GPA : 3.68 / 4\n\n\nCertificates\n\nDibimbing DS  Report Card  MVP  Completion\nHackerRank SQL  Advanced SQL queries \n\n\nSkills\n\n\nPython  \n\n\n\n\n\n\nSQL  \n\n\n\n\n\n\nPower BI  \n\n\n\n\n\n\nTableau  \n\n\n\n\n\n\nExcel VBA  \n\n\n\n\n\n\n\n\nTools\n\n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\n  \n\n\n\nFind me\n\n\n\n\n Email \n\n\n\n LinkedIn \n\n\n\n GitHub \n\n\n\n HackerRank \n\n\n\n 10FastFingers"
  },
  {
    "objectID": "ipynb/final-project.html",
    "href": "ipynb/final-project.html",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "• Data Introduction  • Data Preparation (Import libraries, data cleaning & data wrangling) • Basic exploratory data analysis      • Descriptive statistic      • Univariate analysis      • Multivariate analysis  • Deep exploratory data analysis      • Services and internet services analysis      • Monthly charges analysis      • Customer analysis      • Benefits analysis      • Churn analysis  • Modelling     • Features selection and encoding      • Splits data and define custom metrics      • Model building combination 1      • Model building combination 2      • Model building combination 3\n• Model interpretation     • PDP and ICE plots      • Checking prediction’s confidence using confidence interval \n\n\n\nThis dataset contain informations about customers that churn and not churned in a telco company. Below is the column informations: 1.customerID = customer unique ID. 2.gender = customer gender (M/F). 3.SeniorCitizen = old / young customer. 4.Partner = either a customer has partners or not. 5.Dependents = either a customer has dependents or not. 6.tenure = how long the customer subscribed (in month). 7.MultipleLines = either a customer using multiple lines or not (phone lines). 8.InternetService = either a customer using InternetService lines or not. 9.OnlineSecurity = either a customer has OnlineSecurity or not. 10.OnlineBackup = either a customer has OnlineBackup or not. 11.DeviceProtection = either a customer has DeviceProtection or not. 12.TechSupport = either a customer has TechSupport or not. 13.StreamingTV = either a customer has StreamingTV or not. 14.StreamingMovies = either a customer has StreamingMovie or not. 15.Contract = types of contract. 16.PaperlessBilling = either a customer has PaperlessBilling or not. 17.PaymentMethod = types of the payment method. 18.MonthlyCharges = how much charges per month. 19.TotalCharges = total charges of all time. 20.Churn = either a customer churn or not. 21.Hobby = customer hobby.\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib as mpl\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom pdpbox import pdp, info_plots\nsns.set_style('darkgrid')\nmpl.rcParams['figure.dpi'] = 300 #set figure dpi\nsns.set() #set figure styling\n\n\n#import dataset\ndf = pd.read_csv('telco.csv')\ndf.head()\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\nHobby\n\n\n\n\n0\n7590-VHVEG\nFemale\n0\nYes\nNo\n135\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n29.85\n29.85\nNo\nSwimming\n\n\n1\n5575-GNVDE\nMale\n0\nNo\nNo\n34\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nOne year\nNo\nMailed check\n56.95\n1889.5\nNo\nRunning\n\n\n2\n3668-QPYBK\nMale\n0\nNo\nNo\n140\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nMailed check\n53.85\n7560\nYes\nHiking\n\n\n3\n7795-CFOCW\nMale\n0\nNo\nNo\n136\nNo\nNo phone service\nDSL\nYes\n...\nYes\nNo\nNo\nOne year\nNo\nBank transfer (automatic)\n42.45\n1840.75\nNo\nSwimming\n\n\n4\n9237-HQITU\nFemale\n0\nNo\nNo\n2\nYes\nNo\nFiber optic\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n70.70\n151.65\nYes\nRunning\n\n\n\n\n5 rows × 22 columns\n\n\n\n\n#take a look at the dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 7043 entries, 0 to 7042\nData columns (total 22 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   customerID        7043 non-null   object \n 1   gender            7043 non-null   object \n 2   SeniorCitizen     7043 non-null   int64  \n 3   Partner           7043 non-null   object \n 4   Dependents        7043 non-null   object \n 5   tenure            7043 non-null   int64  \n 6   PhoneService      7043 non-null   object \n 7   MultipleLines     7043 non-null   object \n 8   InternetService   7043 non-null   object \n 9   OnlineSecurity    7043 non-null   object \n 10  OnlineBackup      7043 non-null   object \n 11  DeviceProtection  6627 non-null   object \n 12  TechSupport       7043 non-null   object \n 13  StreamingTV       7043 non-null   object \n 14  StreamingMovies   7043 non-null   object \n 15  Contract          6798 non-null   object \n 16  PaperlessBilling  7043 non-null   object \n 17  PaymentMethod     7043 non-null   object \n 18  MonthlyCharges    7043 non-null   float64\n 19  TotalCharges      4859 non-null   object \n 20  Churn             7043 non-null   object \n 21  Hobby             4201 non-null   object \ndtypes: float64(1), int64(2), object(19)\nmemory usage: 1.2+ MB\n\n\nThere are 4 columns with missing values which are DeviceProtection, Contract, TotalCharges and Hobby.\n\n#checking percentage of missing values\nmissingkolom = ['DeviceProtection','Contract','TotalCharges','Hobby']\nfor x in missingkolom:\n    print(f'Missing value of column {x} (%) : {round(df[x].isna().sum()/len(df) * 100,2)}')\n\nMissing value of column DeviceProtection (%) : 5.91\nMissing value of column Contract (%) : 3.48\nMissing value of column TotalCharges (%) : 31.01\nMissing value of column Hobby (%) : 40.35\n\n\n\n#impute missing values with univariate imputation by value proportion\ndf['DeviceProtection'] = df['DeviceProtection'].fillna(\n                             pd.Series(np.random.choice(['No','Yes','No internet service'], \n                             p = list(df['DeviceProtection'].value_counts(normalize=True)), size=len(df))))\n\ndf['Contract'] = df['Contract'].fillna(\n                     pd.Series(np.random.choice(['Month-to-month','Two year','One year'], \n                     p = list(df['Contract'].value_counts(normalize=True)), size=len(df))))\n\nHere I impute DeviceProtection and Contract with univariate imputation by value proportion for the following reasons: 1.The missing values is not that much (&lt;10%). 2.The columns don’t have any relationship with other columns so that multivariate imputation is not possible. 3.Using proportion is more precise in this case rather than use ‘mode’.\n\n#delete column Hobby\ndf.drop(columns=['Hobby'],inplace=True)\n\nReasons to delete: 1.Missing values is too many. 2.By business context, Hobby doesn’t give enough useful informations. 3.Cannot be imputed by multivariate imputation.\n\n#impute TotalCharges from tenure and MonthlyCharges\ndf['TotalCharges'] = df['TotalCharges'].fillna(df['tenure'] * df['MonthlyCharges'])\n\nEven this column has so many missing values, I decided to impute it with multivariate imputation because: 1.By business context, TotalCharges is more or less tenure * MonthlyCharges. 2.So even the missing values are high, it can still be imputed with a strong justification.\n\n#there's a space in the total charges column.\nfor x in df.TotalCharges:\n    try:\n        float(x)\n    except:\n        print(f'Unable to convert to float with this value : {x}')\n\nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \n\n\n\ndf[df.TotalCharges == ' '].head()\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\n\n\n\n\n488\n4472-LVYGI\nFemale\n0\nYes\nYes\n0\nNo\nNo phone service\nDSL\nYes\n...\nYes\nYes\nYes\nNo\nOne year\nYes\nBank transfer (automatic)\n52.55\n\nNo\n\n\n753\n3115-CZMZD\nMale\n0\nNo\nYes\n0\nYes\nNo\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n20.25\n\nNo\n\n\n936\n5709-LVOEQ\nFemale\n0\nYes\nYes\n0\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nYes\nYes\nTwo year\nNo\nMailed check\n80.85\n\nNo\n\n\n1082\n4367-NUYAO\nMale\n0\nYes\nYes\n0\nYes\nYes\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n25.75\n\nNo\n\n\n1334\n1768-ZAIFU\nFemale\n1\nNo\nNo\n0\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n25.20\n\nYes\n\n\n\n\n5 rows × 21 columns\n\n\n\nWhen the tenure value is 0, the TotalCharges value is empty (‘space’). This is because customers who have just joined (less than a month) have not been charged yet, resulting in a TotalCharges value of 0. Since there are only 12 rows with this condition, I will delete them.\n\n#drop rows that has empty TotalCharges.\ndf = df.drop(df.index[df.TotalCharges == ' ']).reset_index(drop=True)\n\n\n#check for duplicate data, if True then there's no duplicate.\ndf.customerID.nunique() == len(df) \n\nTrue\n\n\n\n#feature engineered 2 new features for the sake of easier analysis.\ndf['Services'] = df[['PhoneService','InternetService']].apply(\n                     lambda x: 'Both' if list(x).count('No') == 0 else\n                     'Internet Only' if x[0] == 'No' else 'Phone Only', axis=1)\n\ndf['TotalBenefits'] = df.loc[:,'OnlineSecurity':'StreamingMovies']\\\n                          .apply(lambda x: list(x).count('Yes'), axis=1)\n\nNew features explanation:  1.Services = Combined values of PhoneService and InternetService. 2.TotalBenefits = Sum of benefits taken on OnlineSecurity until StreamingMovies.\n\n#Change values of 1 and 0 to 'Yes' and 'No'\ndf['SeniorCitizen'] = df.SeniorCitizen.apply(lambda x: 'Yes' if x == 1 else 'No')\n\nChange numerical value to strings for simpler and consistent analysis.\n\n#drop useless column\ndf.drop(columns=['customerID'], inplace=True)\n\n\n#change columns object data type to numerical\ndf.tenure = df.tenure.astype('int64')\ndf.MonthlyCharges = df.MonthlyCharges.astype('float64')\ndf.TotalCharges = df.TotalCharges.astype('float64')\n\n\n#checking values of real totalcharges and calculated totalcharges\ndf['TotalChargesDiff'] = df[['tenure','MonthlyCharges','TotalCharges']].apply(\n                             lambda x: round(abs(1 - (x[0] * x[1] / x[2])) * 100, 3), axis=1)\n\nHere, I have created a new column called TotalChargesDiff to check the differences (%) between the actual TotalCharges value (from the dataset) and the calculated TotalCharges value (obtained by multiplying tenure with MonthlyCharges). If the difference is above 40%, I will consider those rows as invalid because the values of tenure and MonthlyCharges cannot be trusted.\n\ndf['TotalChargesDiff'].sort_values(ascending=False).head(10)\n\n0       13400.000\n5        1357.404\n18        788.048\n19        330.214\n3         213.633\n128        73.511\n47         72.615\n4631       64.286\n5802       63.380\n20         58.263\nName: TotalChargesDiff, dtype: float64\n\n\nYou can observe that some data points have a TotalChargesDiff that reaches hundreds or even thousands percent.\n\n#removing rows that have &gt; 40% TotalChargesDiff.\ndf = df[df.TotalChargesDiff &lt; 40].reset_index(drop=True)\ndf.drop(columns=['TotalChargesDiff'], inplace=True)\n\n\ndef numericategoric(df):\n    num = len(df._get_numeric_data().columns)\n    cat = len(df.columns) - num\n    print(\"TotalNumericalData = \" + str(num))\n    print(\"TotalCategoricalData = \" + str(cat))\n    print(\"Numerical = \" + str(list(df._get_numeric_data().columns )))\n    print(\"Categorical = \" + str(list(df.drop(df._get_numeric_data().columns, axis=1).columns)))\n\n\nnumericategoric(df)\n\nTotalNumericalData = 4\nTotalCategoricalData = 18\nNumerical = ['tenure', 'MonthlyCharges', 'TotalCharges', 'TotalBenefits']\nCategorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn', 'Services']\n\n\nShow numerical and categorical columns\n\n#assign categorical and numerical columns on different dataframe for easier analysis.\ndfnum = df._get_numeric_data()\ndfcat = df.drop(columns = dfnum.columns)\n\n\n\n\n\n\n\n#numerical columns describe.\ndfnum.describe()\n\n\n\n\n\n\n\n\ntenure\nMonthlyCharges\nTotalCharges\nTotalBenefits\n\n\n\n\ncount\n7012.000000\n7012.000000\n7012.000000\n7012.000000\n\n\nmean\n32.506560\n64.732760\n2286.410207\n2.042356\n\n\nstd\n24.564234\n30.109753\n2265.759401\n1.835886\n\n\nmin\n1.000000\n12.000000\n13.500000\n0.000000\n\n\n25%\n9.000000\n35.450000\n402.437500\n0.000000\n\n\n50%\n29.000000\n70.300000\n1397.250000\n2.000000\n\n\n75%\n56.000000\n89.850000\n3784.125000\n3.000000\n\n\nmax\n140.000000\n118.750000\n8684.800000\n6.000000\n\n\n\n\n\n\n\n1.All columns seems to have a normal min-max values. Nothing weird here. 2.Average tenure is about 30 months which is pretty low. 3.Average MonthlyCharge is about 65-70 USD which is pretty good. 4.Out of 6 benefits available, the average taken by customer is around 2, which is pretty low.\n\ndfcat.describe()\n\n\n\n\n\n\n\n\ngender\nSeniorCitizen\nPartner\nDependents\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\nOnlineBackup\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nChurn\nServices\n\n\n\n\ncount\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n\n\nunique\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n2\n4\n2\n3\n\n\ntop\nMale\nNo\nNo\nNo\nYes\nNo\nFiber optic\nNo\nNo\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\nNo\nBoth\n\n\nfreq\n3542\n5874\n3624\n4920\n6336\n3372\n3087\n3486\n3075\n3066\n3459\n2798\n2769\n3850\n4155\n2354\n5155\n4821\n\n\n\n\n\n\n\n1.Male and Female has the same proportion. 2.Most of customers is non SeniorCitizen with no Partner and No Dependents. 3.Favorite InternetService is Fiber optic. 4.Majority of customers is subscribed with ‘Month-to-month’ Contract. 5.5155 out of 7012 is non-Churn customers which make this dataset is imbalanced. 6.All these columns have low cardiality values.\n\n\n\n\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    axarr[dfnum.columns.get_loc(x)].boxplot(df[x],patch_artist=True)\n    axarr[dfnum.columns.get_loc(x)].set_xlabel(x)\nplt.suptitle('Outliers checking on numeric columns')\nfig.tight_layout(pad=1)\nplt.show()\n\n\n\n\nWill drop outlier in tenure.\n\n#drop outlier in tenure\ndf = df[df.tenure &lt; 125]\n\n\n#plot distribution for numerical columns\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=dfnum[x], \n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)])\nplt.suptitle('Distribution plot', weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\nAbove plots are distribution plots on all numerical columns. 1.tenure and MonthlyCharges have a ‘U-shaped’ distribution. 2.TotalCharges has a positive-skew distribution.\n\n#count plot for categorical columns\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(x=df[features[i-1]], color='green')\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\nHere I count plotted all categorical columns.\n\n\n\n\n#count plots against 'churn'\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(data=df, x=df[features[i-1]], hue='Churn')\n    plt.legend(prop={'size': 8})\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot vs Churned', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\nI added Churn count into the categorical plots. 1.You can see for column Gender, the values and Churn count is pretty equal which make this column will have a very low predictive power. 2.For InternetService, fiber optic has way higher in churn probability compare to DSL. 3.Same ways also applied on Month-to-month Contract and Electronic-check PaymentMethod.\n\n#distribution plots against 'churn'\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=df, \n                 x = dfnum[x],\n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)], \n                 hue='Churn')\n    \nplt.suptitle(\"Distribution plot\", weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\nLet’s also compare Churn distribution on numerical columns. Customers tend to churn when the tenure is low and not churn when the MonthlyCharges is very low. I will do further analysis about these columns later.\n\n#change binary column into numerical\nbinary = ['gender','SeniorCitizen','Partner','Dependents','PhoneService','PaperlessBilling','Churn']\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\ndfcorr = df[binary]\nfor col in binary:\n    dfcorr[col] = dfcorr[col].map(value_mapping).astype('int64')\n\n\nplt.figure(figsize=(10,8))\nsns.heatmap(dfcorr.corr(), annot=True, fmt='.2f')\nplt.show()\n\n\n\n\nCorrelation! 1.TotalCharges and tenure have a high positive correlation (causation : the longer the customers subscribed, the more they paid). 2.TotalBenefits also has a strong correlation with MonthlyCharges and TotalCharges (causation : more benefits taken also make the MonthlyCharges higher). Note : Correlation doesn’t indicate causation. Understanding the specific context, industry knowledge, and conducting further analysis or experiments can help determine if there is a causal relationship between the variables or if other factors are influencing the observed correlations.\n\n\n\n\n\n#create a function to plot churn probability for numerical columns.\ndef prob_plot(df,colom,x):\n    means = df[colom].mean()\n    medians = df[colom].median()\n    data = df[df.Churn == 'Yes'][colom].astype('float64')\n    data1 = df[df.Churn == 'No'][colom].astype('float64')\n    \n    kde = gaussian_kde(data)\n    kde1 = gaussian_kde(data1)\n    dist_space = np.linspace( min(data), max(data), 200)\n    dist_space1 = np.linspace( min(data1), max(data1), 200)\n    axarr[x].plot( dist_space, kde(dist_space), label='Churned', color='orange' )\n    axarr[x].plot( dist_space1, kde1(dist_space1), label='Not churn', color='blue')\n    axarr[x].axvline(x = means, linestyle = '--', color='g', label='Mean')\n    axarr[x].axvline(x = medians, linestyle = '--', color='r', label='Median')\n    axarr[x].set_title('Probability', fontweight='bold', size=12)\n    axarr[x].set(ylabel = 'Probability', xlabel = colom)\n    axarr[x].legend()\n\n\n\n\n#count plot for Services.\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(data=df[df.Services == 'Both'], \n              x='InternetService', \n              ax=axarr[0])\n\nsns.countplot(data=df[df.Services == 'Internet Only'], \n              x='InternetService', \n              ax=axarr[1])\n\naxarr[0].set_title(\"Both phone service & internet service\", weight='bold')\naxarr[1].set_title(\"Internet service only\", weight='bold')\n\nplt.suptitle(\"Comparison of internet services on product services\")\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\nIt is observed that customers tend to prefer Fiber optic over DSL for ‘phone & internet service’. However, when considering ‘internet service only’ without phone, there is no option for Fiber optic available. This suggests that in order to utilize Fiber optic, a phone connection (or phone service) is required.\n\n#plot churn probability for 'services' & 'internet services'\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\n\ndf.groupby('Services')['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(list(x)))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[0])\n\ndf[df.Services != 'Phone Only'].groupby(['InternetService'])['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(x))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[1])\n\naxarr[0].set_title('Services churn probability', weight='bold')\naxarr[1].set_title('Internet service churn probability', weight='bold')\n\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\nCustomers that used ‘Both’ services and InternetService fiber optic tends to churn more.\n\n\n\n\n#checking InternetService price.\ndf_filtered = df[(df.Services == 'Both') & (df.TotalBenefits == 0) & (df.MultipleLines == 'No')].copy()\ndf_filtered.groupby('InternetService')['MonthlyCharges'].mean()\n\nInternetService\nDSL            44.965089\nFiber optic    70.074454\nName: MonthlyCharges, dtype: float64\n\n\n\nThe price of Fiber optic is higher, around 25 USD, compared to DSL. However, it’s important to keep in mind that these prices include a phone service with a single line.\n\n\ndf_filtered = df[(df.Services == 'Phone Only') & (df.TotalBenefits == 0)].copy()\ndf_filtered.groupby('MultipleLines')['MonthlyCharges'].mean()\n\nMultipleLines\nNo     19.958088\nYes    24.980060\nName: MonthlyCharges, dtype: float64\n\n\n\nplt.figure(figsize=(10,5))\nsns.histplot(data=df_filtered, \n             x='MonthlyCharges', \n             hue='MultipleLines', \n             multiple='stack')\n\nplt.title('Phone service distribution', weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nWe can see that the price for a ‘phone service’ with a single line is around 20 USD, while the price for a ‘phone service’ with multiple lines is around 25 USD. This also means that the price for DSL is around 25 USD, while the price for Fiber optic is around 50 USD, which is twice as much as DSL.\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nmc_dist = sns.histplot(data=df, \n                       x = 'MonthlyCharges',\n                       hue='Churn', \n                       ax=axarr[0], \n                       multiple='stack')\n\naxarr[0].set_title('Distribution', fontweight='bold', size=12)\n\nprob_plot(df,'MonthlyCharges',1)\naxarr[1].legend(loc='upper right')\nplt.show()\n\n\n\n\nAt a MonthlyCharges range of approximately +- 20 USD, the ratio of non-churn customers is very high. It is known that products within this price range are typically ‘phone service only’. However, between the price range of 60 - 100 USD, the churn probability increases significantly. I am planning to conduct further analysis specifically for customers within this price range.\n\ndf_filtered = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both') & (df.MultipleLines == 'No')]\ndf_agg = df_filtered.groupby('TotalBenefits')['MonthlyCharges'].agg('mean').reset_index()\ndf_agg['MonthlyCharges'] = df_agg.MonthlyCharges.round()\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.scatterplot(data=df_filtered, \n                x='MonthlyCharges', \n                y='TotalBenefits', \n                s=35, \n                ax=axarr[0])\n\nsns.barplot(df_agg, x = 'TotalBenefits', y = 'MonthlyCharges')\naxarr[0].set_title('MonthlyCharges vs Totalbenefits', weight='bold')\naxarr[1].set_title('Average MonthlyCharges vs Totalbenefits', weight='bold')\nfig.tight_layout(pad = 1)\nplt.show()\n\n\n\n\nHere, you can observe that as more TotalBenefits are taken, the MonthlyCharges also increase. On the left plot, you can see that there are 5 outlier data points, which will be removed later.\n\ndf_fil = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both')\\\n              & (df.MultipleLines == 'No') & (df.TotalBenefits == 1)]\n\nbenefits = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\ndf_benefit = pd.DataFrame()\nfor x in benefits:\n    df_value = pd.DataFrame([x, \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].min(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].max(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].mean(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].median()\n                     ]).transpose()\n    \n    df_benefit = pd.concat([df_benefit, df_value])\ndf_benefit.columns = ['Benefit','MinCharges','MaxCharges','MeanCharges','MedianCharges']    \n\n\ndf_benefit\n\n\n\n\n\n\n\n\nBenefit\nMinCharges\nMaxCharges\nMeanCharges\nMedianCharges\n\n\n\n\n0\nOnlineSecurity\n73.2\n76.45\n74.795588\n74.95\n\n\n0\nOnlineBackup\n72.75\n76.65\n74.708511\n74.65\n\n\n0\nDeviceProtection\n69.55\n76.65\n74.604762\n74.9\n\n\n0\nTechSupport\n73.85\n76.55\n75.045455\n74.7\n\n\n0\nStreamingTV\n77.65\n81.9\n79.749242\n79.825\n\n\n0\nStreamingMovies\n12.0\n86.1\n79.045902\n80.15\n\n\n\n\n\n\n\nAbove are the prices of benefits with Fiber optic and a single line phone connection. You can see that StreamingTV and StreamingMovies are more expensive compared to other benefits, approximately +- 5 USD.\nNow that we know the prices of every product, here’s a recap:\nDSL = approximately 25 USD. Fiber optic = approximately 50 USD. Phone service (single line) = approximately 20 USD. Phone service (multiple lines) = approximately 25 USD. OnlineSecurity - TechSupport = approximately 5 USD. StreamingTV - StreamingMovies = approximately 10 USD.\nWith this data, we can perform a simple ‘anomaly detection’ by manually calculating the MonthlyCharges and comparing them with the actual MonthlyCharges, similar to how we calculated the TotalChargesDiff above.\n\n#checking for MonthlyCharges values with the calculated one (similar with checking TotalCharges difference).\ndef MonthlyChargesDiff(x):\n    estimation = 0\n    if x['PhoneService'] == 'Yes':\n        estimation += 20\n    if x['MultipleLines'] == 'Yes':\n        estimation += 5\n    if x['InternetService'] == 'DSL':\n        estimation += 25\n    if x['InternetService'] == 'Fiber optic':\n        estimation += 50\n        \n    if (x['StreamingTV'] == 'Yes') & (x['StreamingMovies'] == 'Yes'):\n        estimation += 20 + (x['TotalBenefits'] - 2) * 5\n    elif (x['StreamingTV'] == 'Yes') | (x['StreamingMovies'] == 'Yes'):\n        estimation += 10 + (x['TotalBenefits'] - 1) * 5\n    else:\n        estimation += x['TotalBenefits'] * 5\n        \n    return abs(1 - (estimation / x['MonthlyCharges'])) * 100\n    \n   \n\n\ndf['MonthlyChargesEstimationDifference'] = df.apply(MonthlyChargesDiff, axis=1)\n\n\ndf[df.MonthlyChargesEstimationDifference &gt; 40][['MonthlyCharges','MonthlyChargesEstimationDifference']]\n\n\n\n\n\n\n\n\nMonthlyCharges\nMonthlyChargesEstimationDifference\n\n\n\n\n12\n29.00\n296.551724\n\n\n389\n12.00\n733.333333\n\n\n666\n12.00\n566.666667\n\n\n859\n26.41\n278.644453\n\n\n1439\n18.26\n447.645126\n\n\n2185\n21.63\n362.320851\n\n\n4090\n31.26\n219.897633\n\n\n5848\n15.00\n466.666667\n\n\n6718\n21.00\n304.761905\n\n\n\n\n\n\n\nYou can see that there are 9 rows with extreme MonthlyCharges values. These are considered as ‘anomalies’, so let’s remove them.\n\n#remove MonthlyCharges extreme values.\ndf = df[df.MonthlyChargesEstimationDifference &lt; 40].reset_index(drop=True)\n\n\n\n\n\n#creating a function to engineered a new feature.\ndef statuss(x):\n    x = list(x)\n    if (x[0] == 'Yes') & (x[1] == 'Yes'):\n        return 'Both'\n    elif (x[0] == 'Yes') & (x[1] == 'No'):\n        return 'Partner Only'\n    elif (x[0] == 'No') & (x[1] == 'Yes'):\n        return 'Dependent Only'\n    else:\n        return 'Single'\n\n\ndf['Status'] = df[['Partner','Dependents']].apply(statuss, axis=1)\n\nI have created a new feature called ‘Status’. This feature is derived from the columns Partner and Dependents. 1.If customers have both Partner and Dependents, it will be labeled as ‘Both’. 2.If customers have Partner but no Dependents, it will be labeled as ‘Partner Only’. 3.If customers have Dependents but no Partner, it will be labeled as ‘Dependent Only’. 4.If customers have neither Partner nor Dependents, it will be labeled as ‘Single’.\n\nplt.figure(figsize=(10,5))\nsns.countplot(df.sort_values('Status', ascending=True), x='Status')\nplt.title('Status Count', size=16, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nMajority of customers are Single.\n\nfig, axarr = plt.subplots(1,3, figsize=(15, 6))\nk = ['tenure','MonthlyCharges','TotalBenefits']\nfor x in k:\n    sns.barplot(data=df.groupby(['Status'])[[x]].mean().reset_index(), \n                x='Status', \n                y=x, \n                ax=axarr[k.index(x)],\n                palette=['grey', 'g','m','b'])\n    \n    axarr[k.index(x)].set_title(f'{x} average', weight='bold', size=15)\n    \nfig.tight_layout()\nplt.show()\n\n\n\n\nCustomers labeled as ‘Partner Only’ are considered the best since they have the longest tenure and the highest MonthlyCharges. The second-best group is ‘Both’, although these customers may not have MonthlyCharges as high as those in the ‘Single’ group, their tenure is almost double that of the ‘Single’ group.\n\nplt.figure(figsize=(10,5))\nsns.barplot(data=df.groupby('Status')[['Churn']].agg(lambda x: list(x).count('Yes') / len(x)).reset_index(), \n            x='Status', \n            y='Churn')\n\nplt.title('Churn Probability', weight='bold', size=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\nSingle customers have the highest churn probability.\n\ndf.SeniorCitizen.value_counts(normalize=True)\n\nSeniorCitizen\nNo     0.837903\nYes    0.162097\nName: proportion, dtype: float64\n\n\nThe majority of customers are young people.\n\ndf_status = df.groupby('SeniorCitizen')[['Status']]\ndf_status = df_status.agg(Single = ('Status', lambda x: list(x).count('Single') * 100 / len(x)), \n                          PartnerOnly = ('Status', lambda x: list(x).count('Partner Only') * 100  / len(x)), \n                          Both = ('Status', lambda x: list(x).count('Both') * 100  / len(x)), \n                          DependentOnly = ('Status', lambda x: list(x).count('Dependent Only') * 100  / len(x)))\ndf_status = df_status.reset_index().melt(id_vars='SeniorCitizen')\ndf_status = df_status.rename(columns={'variable':'Status'})\n\n\nplt.figure(figsize=(10,5))\n\nsns.barplot(data=df_status, \n            x ='SeniorCitizen', \n            y='value', \n            hue='Status')\n\nplt.title(\"Status comparison between senior citizen\", size=15, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nFor non-Senior citizens, ‘Single’ customers have the highest frequency, followed by ‘Both’. For Senior citizens, ‘Single’ is also the highest category, but the difference with ‘PartnerOnly’ is not as significant. From the plots above, we can also conclude that young people tend to have dependents more than older people.\n\ndf_status = df.groupby('Status')[['OnlineSecurity','OnlineBackup',\n                                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n                                  .agg(lambda x: list(x).count('Yes'))\n    \ndf_status['total'] = df_status.apply('sum',axis=1)\n\nfor x in df_status.drop(columns='total').columns:\n    df_status[x] = (df_status[x] * 100 / df_status.total).round()\ndf_status.drop(columns='total', inplace=True)\n\n\ndf_status.plot(kind='bar', rot=0)\nplt.title('Benefit count comparison between status (%)', size=12, weight='bold')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()\n\n\n\n\nSingle and PartnerOnly customers tend to prefer entertainment benefits such as StreamingTV and StreamingMovies compared to other customers. Additionally, these customers show a lower preference for using TechSupport and OnlineSecurity.\n\n\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(df[df.Services != 'Phone Only'], \n              x = 'TotalBenefits', ax=axarr[0])\n\nsns.barplot(df[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n            .apply(lambda x: list(x).count('Yes')).reset_index(), x = 'index', y = 0, ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Count', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None)\naxarr[1].set_title('Benefits Count', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\nThe average number of TotalBenefits taken by customers is around 3, with StreamingTV and StreamingMovies being the most popular choices.\n\ndf_total = pd.DataFrame()\nfor x in ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']:\n    total = list(df[df[x] == 'Yes']['Churn']).count('Yes') / len(df[df[x] == 'Yes']['Churn'])\n    df_total = pd.concat([df_total, pd.DataFrame([x],[total])])\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.barplot(df.groupby('TotalBenefits')[['Churn']]\\\n            .agg(lambda x: list(x).count('Yes') * 100 / len(x)).round().reset_index(), \n            x='TotalBenefits', \n            y='Churn', ax=axarr[0])\n\nsns.barplot(df_total.reset_index(), \n            x=0, \n            y='index', \n            ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Churn probability', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None, xlabel='Benefits')\naxarr[1].set_title('Benefits Churn probability', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\nWhile StreamingTV and StreamingMovies are the most favored choices, the churn probability associated with them is also the highest.\n\n\n\n\nfig, axarr = plt.subplots(1, figsize=(10, 6))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                hue ='Churn', \n                s=20)\n\nplt.fill_between((68 , 97),20, alpha=0.2, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.2, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs Churn', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\nHere, I have created two areas, denoted by green and blue, both focusing on MonthlyCharges in the range of 70 - 95 USD. This price range corresponds to the highest churn probability. The green area represents customers with low tenure and is predominantly occupied by churned customers, while the blue area represents customers with high tenure and is predominantly occupied by non-churned customers.\n\nplt.subplots(1, figsize=(15, 8))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                s=35, \n                hue='TotalBenefits', \n                style='InternetService', \n                palette='coolwarm')\n\nplt.fill_between((68 , 97),20, alpha=0.15, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.15, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs TotalBenefits vs InternetService', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\nStill on the same plot, I have added TotalBenefits and InternetService. It can be observed that in the green area, Fiber optic is the dominant InternetService with low TotalBenefits. On the other hand, the blue area is dominated by DSL with high TotalBenefits. This indicates that customers, at the same price point, tend to choose DSL with high TotalBenefits rather than Fiber optic with low TotalBenefits. Note that Fiber optic prices are doubled than DSL.\nWith the observed pattern above, we can create an important new feature, which we will refer to as ‘FO_LB’ (Fiber optic_Low benefit). I will assign a value of ‘1’ to indicate that the internet service is Fiber optic and the Totalbenefits taken are less than or equal to 3. For other cases, I will assign ‘0’.\n\ndf['FO_LB'] = df[['InternetService','TotalBenefits']].apply(\n    lambda x: 1 if (x['InternetService'] == 'Fiber optic') & (x['TotalBenefits'] &lt;= 3) else 0, axis=1)\n\n\n\n\n\nOne important thing to address before we proceed is considering the types of errors to make this project as realistic as possible. Typically, there are two types of errors: false positive (FP) and false negative (FN). However, in this project, I will introduce three types of errors.\n1.FP: False positive  2.FN1: False negative for customers with MonthlyCharges below 95 USD  3.FN2: False negative for customers with MonthlyCharges above 95 USD (VIP customers)  Let’s agree on the misclassification ratio, which is FP:FN1:FN2 = 1:3:5 \nIt’s important to note that this dataset is imbalanced, meaning there is a significant difference in the number of samples between the classes.\nBased on these problems, we can set up our model’s parameters as follows: 1.Hyperparameter tuning. 2.Decision threshold tuning. 3.Oversampling data using SMOTE. 4.Applying weights to the models. I will be using Random Forest, XGBoost, and Logistic Regression.\nMetrics: Custom scoring based on sample misclassification. Precision. Recall. F1_score. Once the models are evaluated using these metrics, I will interpret the best model.\n\n\n\ndf1 = df.copy()\n\n\ndf = df1.copy()\n\n\n#drop columns\ndf.drop(columns = ['Services','MonthlyChargesEstimationDifference','Status','PaperlessBilling','PaymentMethod'], inplace=True)\n\nI have dropped the columns from ‘Services’ to ‘Status’ as these columns were engineered features created for simpler exploratory data analysis (EDA). Additionally, I have also dropped the ‘PaperlessBilling’ and ‘PaymentMethod’ columns because, in the business context, these columns are considered irrelevant for determining customer churn since they represent optional ‘features’ for customers.\n\n#converting 'No internet service' to 'No' in benefit columns.\nKolomBenefit = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfor x in KolomBenefit:\n    df[x] = df[x].apply(lambda x: 'No' if x == 'No internet service' else x)\n\n\n#converting 'No phone service' to 'No'\ndf['MultipleLines'] = df[x].apply(lambda x: 'No' if x == 'No phone service' else x)\n\n\n#dict to mapping string to numerical.\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\n\n\n#binary encoding\nbinary = list(df.drop(columns=['tenure','InternetService','MonthlyCharges','TotalCharges','TotalBenefits','Contract','FO_LB']).columns)\n\nfor col in binary:\n    df[col] = df[col].map(value_mapping).astype('int64')\n\n\n#label encoding\ndf['Contract'] = df['Contract'].apply(lambda x: 1 if x == 'Month-to-month' else 2 if x == 'One year' else 3) \n\n\n#one hot encoding\ndf = pd.get_dummies(df, columns=['InternetService'])\n\n\n#feature selection\ndf = df[['Contract','tenure','InternetService_Fiber optic','MonthlyCharges','FO_LB','InternetService_No','Churn']]\ndf = df.rename(columns={\n                'InternetService_Fiber optic':'Fiber_optic',\n                'InternetService_No':'No_internet'})\n\nHere I only choose a feature that have a strong predictive power (by using feature of importances)\n\n\n\n\n#split train-test\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Churn'), df.Churn.to_numpy(), test_size = 0.2, random_state=123)\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\n\n#custom function to do threshold tuning and custom metrics (used in GridSearchCV)\ndef my_scorer_2(clf, X, y_true, thres = np.arange(0.1,1,0.1)):\n    result_dict = {}\n    for threshold in np.atleast_1d(thres):\n        y_pred = (clf.predict_proba(X)[:,1] &gt; threshold).astype(int)\n        X_segment = (X['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\n        y_stack = np.column_stack((X_segment, y_pred, y_true))\n        y_stack_reg, y_stack_vip = y_stack[y_stack[:,0] == 0], y_stack[y_stack[:,0] == 1]\n        cm_reg = confusion_matrix(y_stack_reg[:,2], y_stack_reg[:,1])\n        cm_vip = confusion_matrix(y_stack_vip[:,2], y_stack_vip[:,1])\n        fn_reg, fn_vip = cm_reg[1][0], cm_vip[1][0]\n        fp = cm_reg[0][1] + cm_vip[0][1]\n        loss_score = (fp * 1) + (fn_reg * 3) + (fn_vip * 5)\n        result_dict[threshold] = np.array([loss_score, metrics.precision_score(y_true, y_pred, zero_division = 0), \n                                           metrics.recall_score(y_true, y_pred), metrics.f1_score(y_true, y_pred)])\n        \n    result_np = np.array([np.insert(value, 0, key) for key, value in result_dict.items()])\n    best_np = result_np[result_np[:,1] == np.min(result_np[:,1])][0]\n    return best_np\n\ndef my_scorer_threshold(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[0]\n\ndef my_scorer_ls(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[1]\n\ndef my_scorer_precision(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[2]\n\ndef my_scorer_recall(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[3]\n\ndef my_scorer_f1(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[4]\n        \n        \n\n\n#Grid scoring parameter\ngrid_scoring = {\n    'threshold': my_scorer_threshold,\n    'loss_score': my_scorer_ls,\n    'precision': my_scorer_precision,\n    'recall': my_scorer_recall,\n    'f1': my_scorer_f1\n}\n\n\n#define weight by missclassification cost which is FP:FN1:FN2 = 1:3:5\nX_segment = (X_train['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\narr_weight = np.column_stack((X_segment, y_train))\nweight = np.apply_along_axis(lambda x: 1 if x[1] == 0 else 5 if x[0] == 1 else 3 , axis=1, arr=arr_weight)\n\n\n\n\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train)\n\n#evaluate the model\nmb1_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb1_rf = np.append(mb1_rf, grid_result.iloc[0,0])\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb1_xg = np.append(mb1_xg, grid_result.iloc[0,0])\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb1_lg = np.append(mb1_lg, grid_result.iloc[0,0])\n\n\nresult_mb1 = pd.DataFrame([mb1_rf,mb1_xg,mb1_lg])\nresult_mb1.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb1['model'] = ['MB1_RF','MB1_XG','MB1_Log_Reg']\nresult_mb1\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n\n\n\n\n\n\n\n\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf_smote = {\n    'class__n_estimators': [250 , 400],\n    'class__max_depth': [10, 25, 50],\n    'class__min_samples_split': [25, 50, 70, 120],\n    'class__min_samples_leaf': [50, 75, 120],\n    'class__bootstrap' : [True, False]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinerf = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', RandomForestClassifier())])\n\n#run grid search cv\nrf = GridSearchCV(estimator = pipelinerf,\n                  param_grid = param_grid_rf_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nrf = RandomForestClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nrf = rf.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb2_rf = np.append(mb2_rf, params)\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg_smote = {\n    'class__learning_rate': [0.1, 0.01, 0.001],\n    'class__n_estimators': [100, 500],\n    'class__max_depth': [5, 10, 25],\n    'class__subsample': [0.8, 0.9, 1.0],\n    'class__colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinexg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', XGBClassifier())])\n\n#run grid search cv\nxg = GridSearchCV(estimator = pipelinexg,\n                  param_grid = param_grid_xg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nxg = XGBClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nxg = xg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb2_xg = np.append(mb2_xg, params)\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg_smote = {\n    'class__penalty': ['l1', 'l2'], \n    'class__C': [0.1, 1.0, 10.0],  \n    'class__solver': ['liblinear'],  \n    'class__max_iter': [50,100,200] \n}\n\n\n#create imbalanced pipeline to SMOTE \npipelinelg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', LogisticRegression())])\n\n#run grid search cv\nlg = GridSearchCV(estimator = pipelinelg,\n                  param_grid = param_grid_lg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nlg = LogisticRegression(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nlg = lg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb2_lg = np.append(mb2_lg, params)\n\n\nresult_mb2 = pd.DataFrame([mb2_rf,mb2_xg,mb2_lg])\nresult_mb2.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb2['model'] = ['MB2_RF','MB2_XG','MB2_Log_Reg']\nresult_mb2\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n\n\n\n\n\nYou see that the threshold on all models are increasing than model building 1 because SMOTE make the models learn more on the positive class.\n\n\n\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb3_rf = np.append(mb3_rf, grid_result.iloc[0,0])\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb3_xg = np.append(mb3_xg, grid_result.iloc[0,0])\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb3_lg = np.append(mb3_lg, grid_result.iloc[0,0])\n\n\nresult_mb3 = pd.DataFrame([mb3_rf,mb3_xg,mb3_lg])\nresult_mb3.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb3['model'] = ['MB3_RF','MB3_XG','MB3_Log_Reg']\nresult_mb3\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\n\nfinal_result = pd.concat([result_mb1, result_mb2, result_mb3]).sort_values('score')\nfinal_result\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\nAnalysis of how the models performed: 1.RandomForest performs best with hyperparameter tuning and a lower decision threshold. However, this model performs worst when using SMOTE. 2.LogisticRegression performs worst when using ‘sample weighting’. 3.XGBoost performs best when using SMOTE. 4.It’s important to note that all models produce similar results when using their best parameters and conditions. 5.In my opinion, the greatest impact is achieved by using hyperparameter tuning and decision threshold tuning, rather than using SMOTE and weighting techniques.\n\n\n\n\nIn this section, I want to show you how to interpret a tree-based model, such as Random Forest, so we can have a better understanding of how the model actually works.\n\n#selecting the best parameter for random forest\nrf_param = final_result[final_result['model'] == 'MB1_RF']['params'][0]\nrf_param\n\n{'bootstrap': True,\n 'max_depth': 25,\n 'min_samples_leaf': 50,\n 'min_samples_split': 50,\n 'n_estimators': 250}\n\n\n\nrf = RandomForestClassifier(**rf_param)\nrf.fit(X_train, y_train)\n\nRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)\n\n\n\n\nWhat is ICE? It is a plot that shows how a model makes predictions based on changing the value of one or more features, while keeping the values of other features constant. This provides us with more insights and understanding of how the model treats features to make predictions. ICE works per row (or per customer in this case), and PDP is simply the average of ICE.\n\ndef pdp_ice_plot(model, df_test, column, clusters=True):\n    df_test = df_test.copy()\n    pdp_isolate = pdp.PDPIsolate(model = model, df = df_test, \n                      num_grid_points=15,\n                      model_features = df_test.columns, \n                      feature = column, feature_name=column)\n    pdp_isolate.plot(\n                center=True, plot_lines=True,\n                cluster=clusters, n_cluster_centers=5,cluster_method='accurate',\n                plot_pts_dist=False, to_bins=True,\n                show_percentile=False, which_classes=None,\n                figsize=(10,6), dpi=300,\n                ncols=2, plot_params={\"pdp_hl\": True},\n                engine='matplotlib', template='plotly_white')\n    plt.show()\n    \n\n\npdp_ice_plot(rf, X_test, 'MonthlyCharges', False)\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe light blue lines represent ICE (Individual Conditional Expectation), and the yellowish blue line represents PDP (Partial Dependence Plot). The X-axis represents MonthlyCharges, while the Y-axis represents the change in prediction probability. At MonthlyCharges of 60.7 USD, you can observe that some customers experience a significant increase in churn probability as the MonthlyCharges increase. However, it is important to note that not all customers have the same response. Some customers are minimally affected, and some may not be affected at all.\n\npdp_ice_plot(rf, X_test, 'MonthlyCharges')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThis is the same plot as above, but I have grouped the ICE into 5 clusters for easier viewing and analysis. You can see that there are some customers who experience a significant increase in churn probability as the MonthlyCharges increase.\n\npdp_ice_plot(rf, X_test, 'tenure')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe longer the tenure, the lower the churn probability. However, the effect is not the same for all customers. Some customers are greatly affected, while others are barely affected.\n\npdp_ice_plot(rf, X_test, 'Contract')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe same also goes with Contract. Longer contract means lower churn probability.\n\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=6,\n                              model_features = X_test.columns, \n                              features=['MonthlyCharges','tenure'], \n                              feature_names=['MonthlyCharges','tenure'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s analyze the combination of MonthlyCharges and tenure. We can observe a spike in churn probability for MonthlyCharges ranging from 56.3 USD to 79.2 USD, particularly for customers with a tenure of less than 7 months.\n\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=10,\n                              model_features = X_test.columns, \n                              features=['tenure','Contract'], \n                              feature_names=['tenure','Contract'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model produces similar churn probabilities for customers with a combination of a 2-year contract and low tenure compared to those with a month-to-month contract and medium tenure (24-36 months).\nYou can see how PDP and ICE plots can be very beneficial in understanding how the model utilizes features to make predictions. In the next section, I will demonstrate how to assess the model’s prediction confidence level.\n\n\n\nTree-based models like RandomForest make predictions by using the mean of all the trees’ prediction probabilities. However, instead of solely relying on the mean, we can also calculate the standard deviation. A higher standard deviation indicates lower confidence in the predictions. Additionally, we can utilize confidence intervals, such as 95% or even more extreme at 99%.\n\n#extract all trees' prediction probability per row\npredict = np.stack([x.predict_proba(X_test)[:,1] for x in rf.estimators_])\n\n\n#assign mean and std. deviation of trees' prediction probability.\ndf_pred = X_test.copy()\ndf_pred['avg'] = np.round(np.mean(predict, axis = 0) * 100, 2)\ndf_pred['std_dev'] = np.round(np.std(predict, axis = 0) * 100, 2)\n\n\nplt.figure(figsize=(10,6))\nsns.histplot(df_pred['std_dev'],color='skyblue', kde=True, edgecolor='none')\nplt.title('Standard deviation distribution', weight='bold')\nplt.show()\n\n\n\n\nMost of predictions have std.deviation under 10%. Let’s calculate confidence interval with 99%.\n\ndf_pred['CI-99%'] = (2.576 * df_pred['std_dev'] / np.sqrt(len(predict))) * 100 / (df_pred['avg'])\n\n\ndf_pred[df_pred.avg &gt; 40].sort_values('CI-99%', ascending=False).head(5)\n\n\n\n\n\n\n\n\nContract\ntenure\nFiber_optic\nMonthlyCharges\nFO_LB\nNo_internet\navg\nstd_dev\nCI-99%\n\n\n\n\n852\n2\n7\n1\n94.05\n1\n0\n40.06\n25.08\n10.199818\n\n\n499\n1\n58\n1\n98.70\n1\n0\n41.05\n18.24\n7.239149\n\n\n1186\n1\n59\n1\n101.10\n1\n0\n40.37\n16.73\n6.751699\n\n\n1137\n1\n15\n1\n96.30\n0\n0\n48.14\n19.69\n6.663701\n\n\n1184\n1\n10\n1\n92.50\n0\n0\n48.17\n19.12\n6.466765\n\n\n\n\n\n\n\nLet’s consider the example of row 1. The model predicts a 40% probability of churn for the customer, with a confidence interval of +- 10%. By default, the model’s output indicates that the customer will not churn. However, due to the high confidence interval, it is safer to assume that the customer will churn.\nChecking the standard deviation and confidence interval of the trees is extremely useful, particularly when the cost of ‘False Negative’ is significant and can have severe consequences."
  },
  {
    "objectID": "ipynb/final-project.html#table-of-contents",
    "href": "ipynb/final-project.html#table-of-contents",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "• Data Introduction  • Data Preparation (Import libraries, data cleaning & data wrangling) • Basic exploratory data analysis      • Descriptive statistic      • Univariate analysis      • Multivariate analysis  • Deep exploratory data analysis      • Services and internet services analysis      • Monthly charges analysis      • Customer analysis      • Benefits analysis      • Churn analysis  • Modelling     • Features selection and encoding      • Splits data and define custom metrics      • Model building combination 1      • Model building combination 2      • Model building combination 3\n• Model interpretation     • PDP and ICE plots      • Checking prediction’s confidence using confidence interval"
  },
  {
    "objectID": "ipynb/final-project.html#data-introduction",
    "href": "ipynb/final-project.html#data-introduction",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "This dataset contain informations about customers that churn and not churned in a telco company. Below is the column informations: 1.customerID = customer unique ID. 2.gender = customer gender (M/F). 3.SeniorCitizen = old / young customer. 4.Partner = either a customer has partners or not. 5.Dependents = either a customer has dependents or not. 6.tenure = how long the customer subscribed (in month). 7.MultipleLines = either a customer using multiple lines or not (phone lines). 8.InternetService = either a customer using InternetService lines or not. 9.OnlineSecurity = either a customer has OnlineSecurity or not. 10.OnlineBackup = either a customer has OnlineBackup or not. 11.DeviceProtection = either a customer has DeviceProtection or not. 12.TechSupport = either a customer has TechSupport or not. 13.StreamingTV = either a customer has StreamingTV or not. 14.StreamingMovies = either a customer has StreamingMovie or not. 15.Contract = types of contract. 16.PaperlessBilling = either a customer has PaperlessBilling or not. 17.PaymentMethod = types of the payment method. 18.MonthlyCharges = how much charges per month. 19.TotalCharges = total charges of all time. 20.Churn = either a customer churn or not. 21.Hobby = customer hobby."
  },
  {
    "objectID": "ipynb/final-project.html#data-preparation",
    "href": "ipynb/final-project.html#data-preparation",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib as mpl\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom pdpbox import pdp, info_plots\nsns.set_style('darkgrid')\nmpl.rcParams['figure.dpi'] = 300 #set figure dpi\nsns.set() #set figure styling\n\n\n#import dataset\ndf = pd.read_csv('telco.csv')\ndf.head()\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\nHobby\n\n\n\n\n0\n7590-VHVEG\nFemale\n0\nYes\nNo\n135\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n29.85\n29.85\nNo\nSwimming\n\n\n1\n5575-GNVDE\nMale\n0\nNo\nNo\n34\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nOne year\nNo\nMailed check\n56.95\n1889.5\nNo\nRunning\n\n\n2\n3668-QPYBK\nMale\n0\nNo\nNo\n140\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nMailed check\n53.85\n7560\nYes\nHiking\n\n\n3\n7795-CFOCW\nMale\n0\nNo\nNo\n136\nNo\nNo phone service\nDSL\nYes\n...\nYes\nNo\nNo\nOne year\nNo\nBank transfer (automatic)\n42.45\n1840.75\nNo\nSwimming\n\n\n4\n9237-HQITU\nFemale\n0\nNo\nNo\n2\nYes\nNo\nFiber optic\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n70.70\n151.65\nYes\nRunning\n\n\n\n\n5 rows × 22 columns\n\n\n\n\n#take a look at the dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 7043 entries, 0 to 7042\nData columns (total 22 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   customerID        7043 non-null   object \n 1   gender            7043 non-null   object \n 2   SeniorCitizen     7043 non-null   int64  \n 3   Partner           7043 non-null   object \n 4   Dependents        7043 non-null   object \n 5   tenure            7043 non-null   int64  \n 6   PhoneService      7043 non-null   object \n 7   MultipleLines     7043 non-null   object \n 8   InternetService   7043 non-null   object \n 9   OnlineSecurity    7043 non-null   object \n 10  OnlineBackup      7043 non-null   object \n 11  DeviceProtection  6627 non-null   object \n 12  TechSupport       7043 non-null   object \n 13  StreamingTV       7043 non-null   object \n 14  StreamingMovies   7043 non-null   object \n 15  Contract          6798 non-null   object \n 16  PaperlessBilling  7043 non-null   object \n 17  PaymentMethod     7043 non-null   object \n 18  MonthlyCharges    7043 non-null   float64\n 19  TotalCharges      4859 non-null   object \n 20  Churn             7043 non-null   object \n 21  Hobby             4201 non-null   object \ndtypes: float64(1), int64(2), object(19)\nmemory usage: 1.2+ MB\n\n\nThere are 4 columns with missing values which are DeviceProtection, Contract, TotalCharges and Hobby.\n\n#checking percentage of missing values\nmissingkolom = ['DeviceProtection','Contract','TotalCharges','Hobby']\nfor x in missingkolom:\n    print(f'Missing value of column {x} (%) : {round(df[x].isna().sum()/len(df) * 100,2)}')\n\nMissing value of column DeviceProtection (%) : 5.91\nMissing value of column Contract (%) : 3.48\nMissing value of column TotalCharges (%) : 31.01\nMissing value of column Hobby (%) : 40.35\n\n\n\n#impute missing values with univariate imputation by value proportion\ndf['DeviceProtection'] = df['DeviceProtection'].fillna(\n                             pd.Series(np.random.choice(['No','Yes','No internet service'], \n                             p = list(df['DeviceProtection'].value_counts(normalize=True)), size=len(df))))\n\ndf['Contract'] = df['Contract'].fillna(\n                     pd.Series(np.random.choice(['Month-to-month','Two year','One year'], \n                     p = list(df['Contract'].value_counts(normalize=True)), size=len(df))))\n\nHere I impute DeviceProtection and Contract with univariate imputation by value proportion for the following reasons: 1.The missing values is not that much (&lt;10%). 2.The columns don’t have any relationship with other columns so that multivariate imputation is not possible. 3.Using proportion is more precise in this case rather than use ‘mode’.\n\n#delete column Hobby\ndf.drop(columns=['Hobby'],inplace=True)\n\nReasons to delete: 1.Missing values is too many. 2.By business context, Hobby doesn’t give enough useful informations. 3.Cannot be imputed by multivariate imputation.\n\n#impute TotalCharges from tenure and MonthlyCharges\ndf['TotalCharges'] = df['TotalCharges'].fillna(df['tenure'] * df['MonthlyCharges'])\n\nEven this column has so many missing values, I decided to impute it with multivariate imputation because: 1.By business context, TotalCharges is more or less tenure * MonthlyCharges. 2.So even the missing values are high, it can still be imputed with a strong justification.\n\n#there's a space in the total charges column.\nfor x in df.TotalCharges:\n    try:\n        float(x)\n    except:\n        print(f'Unable to convert to float with this value : {x}')\n\nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \n\n\n\ndf[df.TotalCharges == ' '].head()\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\n\n\n\n\n488\n4472-LVYGI\nFemale\n0\nYes\nYes\n0\nNo\nNo phone service\nDSL\nYes\n...\nYes\nYes\nYes\nNo\nOne year\nYes\nBank transfer (automatic)\n52.55\n\nNo\n\n\n753\n3115-CZMZD\nMale\n0\nNo\nYes\n0\nYes\nNo\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n20.25\n\nNo\n\n\n936\n5709-LVOEQ\nFemale\n0\nYes\nYes\n0\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nYes\nYes\nTwo year\nNo\nMailed check\n80.85\n\nNo\n\n\n1082\n4367-NUYAO\nMale\n0\nYes\nYes\n0\nYes\nYes\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n25.75\n\nNo\n\n\n1334\n1768-ZAIFU\nFemale\n1\nNo\nNo\n0\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n25.20\n\nYes\n\n\n\n\n5 rows × 21 columns\n\n\n\nWhen the tenure value is 0, the TotalCharges value is empty (‘space’). This is because customers who have just joined (less than a month) have not been charged yet, resulting in a TotalCharges value of 0. Since there are only 12 rows with this condition, I will delete them.\n\n#drop rows that has empty TotalCharges.\ndf = df.drop(df.index[df.TotalCharges == ' ']).reset_index(drop=True)\n\n\n#check for duplicate data, if True then there's no duplicate.\ndf.customerID.nunique() == len(df) \n\nTrue\n\n\n\n#feature engineered 2 new features for the sake of easier analysis.\ndf['Services'] = df[['PhoneService','InternetService']].apply(\n                     lambda x: 'Both' if list(x).count('No') == 0 else\n                     'Internet Only' if x[0] == 'No' else 'Phone Only', axis=1)\n\ndf['TotalBenefits'] = df.loc[:,'OnlineSecurity':'StreamingMovies']\\\n                          .apply(lambda x: list(x).count('Yes'), axis=1)\n\nNew features explanation:  1.Services = Combined values of PhoneService and InternetService. 2.TotalBenefits = Sum of benefits taken on OnlineSecurity until StreamingMovies.\n\n#Change values of 1 and 0 to 'Yes' and 'No'\ndf['SeniorCitizen'] = df.SeniorCitizen.apply(lambda x: 'Yes' if x == 1 else 'No')\n\nChange numerical value to strings for simpler and consistent analysis.\n\n#drop useless column\ndf.drop(columns=['customerID'], inplace=True)\n\n\n#change columns object data type to numerical\ndf.tenure = df.tenure.astype('int64')\ndf.MonthlyCharges = df.MonthlyCharges.astype('float64')\ndf.TotalCharges = df.TotalCharges.astype('float64')\n\n\n#checking values of real totalcharges and calculated totalcharges\ndf['TotalChargesDiff'] = df[['tenure','MonthlyCharges','TotalCharges']].apply(\n                             lambda x: round(abs(1 - (x[0] * x[1] / x[2])) * 100, 3), axis=1)\n\nHere, I have created a new column called TotalChargesDiff to check the differences (%) between the actual TotalCharges value (from the dataset) and the calculated TotalCharges value (obtained by multiplying tenure with MonthlyCharges). If the difference is above 40%, I will consider those rows as invalid because the values of tenure and MonthlyCharges cannot be trusted.\n\ndf['TotalChargesDiff'].sort_values(ascending=False).head(10)\n\n0       13400.000\n5        1357.404\n18        788.048\n19        330.214\n3         213.633\n128        73.511\n47         72.615\n4631       64.286\n5802       63.380\n20         58.263\nName: TotalChargesDiff, dtype: float64\n\n\nYou can observe that some data points have a TotalChargesDiff that reaches hundreds or even thousands percent.\n\n#removing rows that have &gt; 40% TotalChargesDiff.\ndf = df[df.TotalChargesDiff &lt; 40].reset_index(drop=True)\ndf.drop(columns=['TotalChargesDiff'], inplace=True)\n\n\ndef numericategoric(df):\n    num = len(df._get_numeric_data().columns)\n    cat = len(df.columns) - num\n    print(\"TotalNumericalData = \" + str(num))\n    print(\"TotalCategoricalData = \" + str(cat))\n    print(\"Numerical = \" + str(list(df._get_numeric_data().columns )))\n    print(\"Categorical = \" + str(list(df.drop(df._get_numeric_data().columns, axis=1).columns)))\n\n\nnumericategoric(df)\n\nTotalNumericalData = 4\nTotalCategoricalData = 18\nNumerical = ['tenure', 'MonthlyCharges', 'TotalCharges', 'TotalBenefits']\nCategorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn', 'Services']\n\n\nShow numerical and categorical columns\n\n#assign categorical and numerical columns on different dataframe for easier analysis.\ndfnum = df._get_numeric_data()\ndfcat = df.drop(columns = dfnum.columns)"
  },
  {
    "objectID": "ipynb/final-project.html#basic-exploratory-data-analysis.",
    "href": "ipynb/final-project.html#basic-exploratory-data-analysis.",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "#numerical columns describe.\ndfnum.describe()\n\n\n\n\n\n\n\n\ntenure\nMonthlyCharges\nTotalCharges\nTotalBenefits\n\n\n\n\ncount\n7012.000000\n7012.000000\n7012.000000\n7012.000000\n\n\nmean\n32.506560\n64.732760\n2286.410207\n2.042356\n\n\nstd\n24.564234\n30.109753\n2265.759401\n1.835886\n\n\nmin\n1.000000\n12.000000\n13.500000\n0.000000\n\n\n25%\n9.000000\n35.450000\n402.437500\n0.000000\n\n\n50%\n29.000000\n70.300000\n1397.250000\n2.000000\n\n\n75%\n56.000000\n89.850000\n3784.125000\n3.000000\n\n\nmax\n140.000000\n118.750000\n8684.800000\n6.000000\n\n\n\n\n\n\n\n1.All columns seems to have a normal min-max values. Nothing weird here. 2.Average tenure is about 30 months which is pretty low. 3.Average MonthlyCharge is about 65-70 USD which is pretty good. 4.Out of 6 benefits available, the average taken by customer is around 2, which is pretty low.\n\ndfcat.describe()\n\n\n\n\n\n\n\n\ngender\nSeniorCitizen\nPartner\nDependents\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\nOnlineBackup\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nChurn\nServices\n\n\n\n\ncount\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n\n\nunique\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n2\n4\n2\n3\n\n\ntop\nMale\nNo\nNo\nNo\nYes\nNo\nFiber optic\nNo\nNo\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\nNo\nBoth\n\n\nfreq\n3542\n5874\n3624\n4920\n6336\n3372\n3087\n3486\n3075\n3066\n3459\n2798\n2769\n3850\n4155\n2354\n5155\n4821\n\n\n\n\n\n\n\n1.Male and Female has the same proportion. 2.Most of customers is non SeniorCitizen with no Partner and No Dependents. 3.Favorite InternetService is Fiber optic. 4.Majority of customers is subscribed with ‘Month-to-month’ Contract. 5.5155 out of 7012 is non-Churn customers which make this dataset is imbalanced. 6.All these columns have low cardiality values.\n\n\n\n\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    axarr[dfnum.columns.get_loc(x)].boxplot(df[x],patch_artist=True)\n    axarr[dfnum.columns.get_loc(x)].set_xlabel(x)\nplt.suptitle('Outliers checking on numeric columns')\nfig.tight_layout(pad=1)\nplt.show()\n\n\n\n\nWill drop outlier in tenure.\n\n#drop outlier in tenure\ndf = df[df.tenure &lt; 125]\n\n\n#plot distribution for numerical columns\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=dfnum[x], \n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)])\nplt.suptitle('Distribution plot', weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\nAbove plots are distribution plots on all numerical columns. 1.tenure and MonthlyCharges have a ‘U-shaped’ distribution. 2.TotalCharges has a positive-skew distribution.\n\n#count plot for categorical columns\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(x=df[features[i-1]], color='green')\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\nHere I count plotted all categorical columns.\n\n\n\n\n#count plots against 'churn'\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(data=df, x=df[features[i-1]], hue='Churn')\n    plt.legend(prop={'size': 8})\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot vs Churned', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\nI added Churn count into the categorical plots. 1.You can see for column Gender, the values and Churn count is pretty equal which make this column will have a very low predictive power. 2.For InternetService, fiber optic has way higher in churn probability compare to DSL. 3.Same ways also applied on Month-to-month Contract and Electronic-check PaymentMethod.\n\n#distribution plots against 'churn'\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=df, \n                 x = dfnum[x],\n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)], \n                 hue='Churn')\n    \nplt.suptitle(\"Distribution plot\", weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\nLet’s also compare Churn distribution on numerical columns. Customers tend to churn when the tenure is low and not churn when the MonthlyCharges is very low. I will do further analysis about these columns later.\n\n#change binary column into numerical\nbinary = ['gender','SeniorCitizen','Partner','Dependents','PhoneService','PaperlessBilling','Churn']\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\ndfcorr = df[binary]\nfor col in binary:\n    dfcorr[col] = dfcorr[col].map(value_mapping).astype('int64')\n\n\nplt.figure(figsize=(10,8))\nsns.heatmap(dfcorr.corr(), annot=True, fmt='.2f')\nplt.show()\n\n\n\n\nCorrelation! 1.TotalCharges and tenure have a high positive correlation (causation : the longer the customers subscribed, the more they paid). 2.TotalBenefits also has a strong correlation with MonthlyCharges and TotalCharges (causation : more benefits taken also make the MonthlyCharges higher). Note : Correlation doesn’t indicate causation. Understanding the specific context, industry knowledge, and conducting further analysis or experiments can help determine if there is a causal relationship between the variables or if other factors are influencing the observed correlations."
  },
  {
    "objectID": "ipynb/final-project.html#deep-dive-exploratory-data-analysis",
    "href": "ipynb/final-project.html#deep-dive-exploratory-data-analysis",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "#create a function to plot churn probability for numerical columns.\ndef prob_plot(df,colom,x):\n    means = df[colom].mean()\n    medians = df[colom].median()\n    data = df[df.Churn == 'Yes'][colom].astype('float64')\n    data1 = df[df.Churn == 'No'][colom].astype('float64')\n    \n    kde = gaussian_kde(data)\n    kde1 = gaussian_kde(data1)\n    dist_space = np.linspace( min(data), max(data), 200)\n    dist_space1 = np.linspace( min(data1), max(data1), 200)\n    axarr[x].plot( dist_space, kde(dist_space), label='Churned', color='orange' )\n    axarr[x].plot( dist_space1, kde1(dist_space1), label='Not churn', color='blue')\n    axarr[x].axvline(x = means, linestyle = '--', color='g', label='Mean')\n    axarr[x].axvline(x = medians, linestyle = '--', color='r', label='Median')\n    axarr[x].set_title('Probability', fontweight='bold', size=12)\n    axarr[x].set(ylabel = 'Probability', xlabel = colom)\n    axarr[x].legend()\n\n\n\n\n#count plot for Services.\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(data=df[df.Services == 'Both'], \n              x='InternetService', \n              ax=axarr[0])\n\nsns.countplot(data=df[df.Services == 'Internet Only'], \n              x='InternetService', \n              ax=axarr[1])\n\naxarr[0].set_title(\"Both phone service & internet service\", weight='bold')\naxarr[1].set_title(\"Internet service only\", weight='bold')\n\nplt.suptitle(\"Comparison of internet services on product services\")\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\nIt is observed that customers tend to prefer Fiber optic over DSL for ‘phone & internet service’. However, when considering ‘internet service only’ without phone, there is no option for Fiber optic available. This suggests that in order to utilize Fiber optic, a phone connection (or phone service) is required.\n\n#plot churn probability for 'services' & 'internet services'\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\n\ndf.groupby('Services')['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(list(x)))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[0])\n\ndf[df.Services != 'Phone Only'].groupby(['InternetService'])['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(x))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[1])\n\naxarr[0].set_title('Services churn probability', weight='bold')\naxarr[1].set_title('Internet service churn probability', weight='bold')\n\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\nCustomers that used ‘Both’ services and InternetService fiber optic tends to churn more.\n\n\n\n\n#checking InternetService price.\ndf_filtered = df[(df.Services == 'Both') & (df.TotalBenefits == 0) & (df.MultipleLines == 'No')].copy()\ndf_filtered.groupby('InternetService')['MonthlyCharges'].mean()\n\nInternetService\nDSL            44.965089\nFiber optic    70.074454\nName: MonthlyCharges, dtype: float64\n\n\n\nThe price of Fiber optic is higher, around 25 USD, compared to DSL. However, it’s important to keep in mind that these prices include a phone service with a single line.\n\n\ndf_filtered = df[(df.Services == 'Phone Only') & (df.TotalBenefits == 0)].copy()\ndf_filtered.groupby('MultipleLines')['MonthlyCharges'].mean()\n\nMultipleLines\nNo     19.958088\nYes    24.980060\nName: MonthlyCharges, dtype: float64\n\n\n\nplt.figure(figsize=(10,5))\nsns.histplot(data=df_filtered, \n             x='MonthlyCharges', \n             hue='MultipleLines', \n             multiple='stack')\n\nplt.title('Phone service distribution', weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nWe can see that the price for a ‘phone service’ with a single line is around 20 USD, while the price for a ‘phone service’ with multiple lines is around 25 USD. This also means that the price for DSL is around 25 USD, while the price for Fiber optic is around 50 USD, which is twice as much as DSL.\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nmc_dist = sns.histplot(data=df, \n                       x = 'MonthlyCharges',\n                       hue='Churn', \n                       ax=axarr[0], \n                       multiple='stack')\n\naxarr[0].set_title('Distribution', fontweight='bold', size=12)\n\nprob_plot(df,'MonthlyCharges',1)\naxarr[1].legend(loc='upper right')\nplt.show()\n\n\n\n\nAt a MonthlyCharges range of approximately +- 20 USD, the ratio of non-churn customers is very high. It is known that products within this price range are typically ‘phone service only’. However, between the price range of 60 - 100 USD, the churn probability increases significantly. I am planning to conduct further analysis specifically for customers within this price range.\n\ndf_filtered = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both') & (df.MultipleLines == 'No')]\ndf_agg = df_filtered.groupby('TotalBenefits')['MonthlyCharges'].agg('mean').reset_index()\ndf_agg['MonthlyCharges'] = df_agg.MonthlyCharges.round()\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.scatterplot(data=df_filtered, \n                x='MonthlyCharges', \n                y='TotalBenefits', \n                s=35, \n                ax=axarr[0])\n\nsns.barplot(df_agg, x = 'TotalBenefits', y = 'MonthlyCharges')\naxarr[0].set_title('MonthlyCharges vs Totalbenefits', weight='bold')\naxarr[1].set_title('Average MonthlyCharges vs Totalbenefits', weight='bold')\nfig.tight_layout(pad = 1)\nplt.show()\n\n\n\n\nHere, you can observe that as more TotalBenefits are taken, the MonthlyCharges also increase. On the left plot, you can see that there are 5 outlier data points, which will be removed later.\n\ndf_fil = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both')\\\n              & (df.MultipleLines == 'No') & (df.TotalBenefits == 1)]\n\nbenefits = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\ndf_benefit = pd.DataFrame()\nfor x in benefits:\n    df_value = pd.DataFrame([x, \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].min(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].max(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].mean(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].median()\n                     ]).transpose()\n    \n    df_benefit = pd.concat([df_benefit, df_value])\ndf_benefit.columns = ['Benefit','MinCharges','MaxCharges','MeanCharges','MedianCharges']    \n\n\ndf_benefit\n\n\n\n\n\n\n\n\nBenefit\nMinCharges\nMaxCharges\nMeanCharges\nMedianCharges\n\n\n\n\n0\nOnlineSecurity\n73.2\n76.45\n74.795588\n74.95\n\n\n0\nOnlineBackup\n72.75\n76.65\n74.708511\n74.65\n\n\n0\nDeviceProtection\n69.55\n76.65\n74.604762\n74.9\n\n\n0\nTechSupport\n73.85\n76.55\n75.045455\n74.7\n\n\n0\nStreamingTV\n77.65\n81.9\n79.749242\n79.825\n\n\n0\nStreamingMovies\n12.0\n86.1\n79.045902\n80.15\n\n\n\n\n\n\n\nAbove are the prices of benefits with Fiber optic and a single line phone connection. You can see that StreamingTV and StreamingMovies are more expensive compared to other benefits, approximately +- 5 USD.\nNow that we know the prices of every product, here’s a recap:\nDSL = approximately 25 USD. Fiber optic = approximately 50 USD. Phone service (single line) = approximately 20 USD. Phone service (multiple lines) = approximately 25 USD. OnlineSecurity - TechSupport = approximately 5 USD. StreamingTV - StreamingMovies = approximately 10 USD.\nWith this data, we can perform a simple ‘anomaly detection’ by manually calculating the MonthlyCharges and comparing them with the actual MonthlyCharges, similar to how we calculated the TotalChargesDiff above.\n\n#checking for MonthlyCharges values with the calculated one (similar with checking TotalCharges difference).\ndef MonthlyChargesDiff(x):\n    estimation = 0\n    if x['PhoneService'] == 'Yes':\n        estimation += 20\n    if x['MultipleLines'] == 'Yes':\n        estimation += 5\n    if x['InternetService'] == 'DSL':\n        estimation += 25\n    if x['InternetService'] == 'Fiber optic':\n        estimation += 50\n        \n    if (x['StreamingTV'] == 'Yes') & (x['StreamingMovies'] == 'Yes'):\n        estimation += 20 + (x['TotalBenefits'] - 2) * 5\n    elif (x['StreamingTV'] == 'Yes') | (x['StreamingMovies'] == 'Yes'):\n        estimation += 10 + (x['TotalBenefits'] - 1) * 5\n    else:\n        estimation += x['TotalBenefits'] * 5\n        \n    return abs(1 - (estimation / x['MonthlyCharges'])) * 100\n    \n   \n\n\ndf['MonthlyChargesEstimationDifference'] = df.apply(MonthlyChargesDiff, axis=1)\n\n\ndf[df.MonthlyChargesEstimationDifference &gt; 40][['MonthlyCharges','MonthlyChargesEstimationDifference']]\n\n\n\n\n\n\n\n\nMonthlyCharges\nMonthlyChargesEstimationDifference\n\n\n\n\n12\n29.00\n296.551724\n\n\n389\n12.00\n733.333333\n\n\n666\n12.00\n566.666667\n\n\n859\n26.41\n278.644453\n\n\n1439\n18.26\n447.645126\n\n\n2185\n21.63\n362.320851\n\n\n4090\n31.26\n219.897633\n\n\n5848\n15.00\n466.666667\n\n\n6718\n21.00\n304.761905\n\n\n\n\n\n\n\nYou can see that there are 9 rows with extreme MonthlyCharges values. These are considered as ‘anomalies’, so let’s remove them.\n\n#remove MonthlyCharges extreme values.\ndf = df[df.MonthlyChargesEstimationDifference &lt; 40].reset_index(drop=True)\n\n\n\n\n\n#creating a function to engineered a new feature.\ndef statuss(x):\n    x = list(x)\n    if (x[0] == 'Yes') & (x[1] == 'Yes'):\n        return 'Both'\n    elif (x[0] == 'Yes') & (x[1] == 'No'):\n        return 'Partner Only'\n    elif (x[0] == 'No') & (x[1] == 'Yes'):\n        return 'Dependent Only'\n    else:\n        return 'Single'\n\n\ndf['Status'] = df[['Partner','Dependents']].apply(statuss, axis=1)\n\nI have created a new feature called ‘Status’. This feature is derived from the columns Partner and Dependents. 1.If customers have both Partner and Dependents, it will be labeled as ‘Both’. 2.If customers have Partner but no Dependents, it will be labeled as ‘Partner Only’. 3.If customers have Dependents but no Partner, it will be labeled as ‘Dependent Only’. 4.If customers have neither Partner nor Dependents, it will be labeled as ‘Single’.\n\nplt.figure(figsize=(10,5))\nsns.countplot(df.sort_values('Status', ascending=True), x='Status')\nplt.title('Status Count', size=16, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nMajority of customers are Single.\n\nfig, axarr = plt.subplots(1,3, figsize=(15, 6))\nk = ['tenure','MonthlyCharges','TotalBenefits']\nfor x in k:\n    sns.barplot(data=df.groupby(['Status'])[[x]].mean().reset_index(), \n                x='Status', \n                y=x, \n                ax=axarr[k.index(x)],\n                palette=['grey', 'g','m','b'])\n    \n    axarr[k.index(x)].set_title(f'{x} average', weight='bold', size=15)\n    \nfig.tight_layout()\nplt.show()\n\n\n\n\nCustomers labeled as ‘Partner Only’ are considered the best since they have the longest tenure and the highest MonthlyCharges. The second-best group is ‘Both’, although these customers may not have MonthlyCharges as high as those in the ‘Single’ group, their tenure is almost double that of the ‘Single’ group.\n\nplt.figure(figsize=(10,5))\nsns.barplot(data=df.groupby('Status')[['Churn']].agg(lambda x: list(x).count('Yes') / len(x)).reset_index(), \n            x='Status', \n            y='Churn')\n\nplt.title('Churn Probability', weight='bold', size=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\nSingle customers have the highest churn probability.\n\ndf.SeniorCitizen.value_counts(normalize=True)\n\nSeniorCitizen\nNo     0.837903\nYes    0.162097\nName: proportion, dtype: float64\n\n\nThe majority of customers are young people.\n\ndf_status = df.groupby('SeniorCitizen')[['Status']]\ndf_status = df_status.agg(Single = ('Status', lambda x: list(x).count('Single') * 100 / len(x)), \n                          PartnerOnly = ('Status', lambda x: list(x).count('Partner Only') * 100  / len(x)), \n                          Both = ('Status', lambda x: list(x).count('Both') * 100  / len(x)), \n                          DependentOnly = ('Status', lambda x: list(x).count('Dependent Only') * 100  / len(x)))\ndf_status = df_status.reset_index().melt(id_vars='SeniorCitizen')\ndf_status = df_status.rename(columns={'variable':'Status'})\n\n\nplt.figure(figsize=(10,5))\n\nsns.barplot(data=df_status, \n            x ='SeniorCitizen', \n            y='value', \n            hue='Status')\n\nplt.title(\"Status comparison between senior citizen\", size=15, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nFor non-Senior citizens, ‘Single’ customers have the highest frequency, followed by ‘Both’. For Senior citizens, ‘Single’ is also the highest category, but the difference with ‘PartnerOnly’ is not as significant. From the plots above, we can also conclude that young people tend to have dependents more than older people.\n\ndf_status = df.groupby('Status')[['OnlineSecurity','OnlineBackup',\n                                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n                                  .agg(lambda x: list(x).count('Yes'))\n    \ndf_status['total'] = df_status.apply('sum',axis=1)\n\nfor x in df_status.drop(columns='total').columns:\n    df_status[x] = (df_status[x] * 100 / df_status.total).round()\ndf_status.drop(columns='total', inplace=True)\n\n\ndf_status.plot(kind='bar', rot=0)\nplt.title('Benefit count comparison between status (%)', size=12, weight='bold')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()\n\n\n\n\nSingle and PartnerOnly customers tend to prefer entertainment benefits such as StreamingTV and StreamingMovies compared to other customers. Additionally, these customers show a lower preference for using TechSupport and OnlineSecurity.\n\n\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(df[df.Services != 'Phone Only'], \n              x = 'TotalBenefits', ax=axarr[0])\n\nsns.barplot(df[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n            .apply(lambda x: list(x).count('Yes')).reset_index(), x = 'index', y = 0, ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Count', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None)\naxarr[1].set_title('Benefits Count', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\nThe average number of TotalBenefits taken by customers is around 3, with StreamingTV and StreamingMovies being the most popular choices.\n\ndf_total = pd.DataFrame()\nfor x in ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']:\n    total = list(df[df[x] == 'Yes']['Churn']).count('Yes') / len(df[df[x] == 'Yes']['Churn'])\n    df_total = pd.concat([df_total, pd.DataFrame([x],[total])])\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.barplot(df.groupby('TotalBenefits')[['Churn']]\\\n            .agg(lambda x: list(x).count('Yes') * 100 / len(x)).round().reset_index(), \n            x='TotalBenefits', \n            y='Churn', ax=axarr[0])\n\nsns.barplot(df_total.reset_index(), \n            x=0, \n            y='index', \n            ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Churn probability', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None, xlabel='Benefits')\naxarr[1].set_title('Benefits Churn probability', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\nWhile StreamingTV and StreamingMovies are the most favored choices, the churn probability associated with them is also the highest.\n\n\n\n\nfig, axarr = plt.subplots(1, figsize=(10, 6))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                hue ='Churn', \n                s=20)\n\nplt.fill_between((68 , 97),20, alpha=0.2, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.2, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs Churn', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\nHere, I have created two areas, denoted by green and blue, both focusing on MonthlyCharges in the range of 70 - 95 USD. This price range corresponds to the highest churn probability. The green area represents customers with low tenure and is predominantly occupied by churned customers, while the blue area represents customers with high tenure and is predominantly occupied by non-churned customers.\n\nplt.subplots(1, figsize=(15, 8))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                s=35, \n                hue='TotalBenefits', \n                style='InternetService', \n                palette='coolwarm')\n\nplt.fill_between((68 , 97),20, alpha=0.15, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.15, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs TotalBenefits vs InternetService', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\nStill on the same plot, I have added TotalBenefits and InternetService. It can be observed that in the green area, Fiber optic is the dominant InternetService with low TotalBenefits. On the other hand, the blue area is dominated by DSL with high TotalBenefits. This indicates that customers, at the same price point, tend to choose DSL with high TotalBenefits rather than Fiber optic with low TotalBenefits. Note that Fiber optic prices are doubled than DSL.\nWith the observed pattern above, we can create an important new feature, which we will refer to as ‘FO_LB’ (Fiber optic_Low benefit). I will assign a value of ‘1’ to indicate that the internet service is Fiber optic and the Totalbenefits taken are less than or equal to 3. For other cases, I will assign ‘0’.\n\ndf['FO_LB'] = df[['InternetService','TotalBenefits']].apply(\n    lambda x: 1 if (x['InternetService'] == 'Fiber optic') & (x['TotalBenefits'] &lt;= 3) else 0, axis=1)"
  },
  {
    "objectID": "ipynb/final-project.html#modelling",
    "href": "ipynb/final-project.html#modelling",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "One important thing to address before we proceed is considering the types of errors to make this project as realistic as possible. Typically, there are two types of errors: false positive (FP) and false negative (FN). However, in this project, I will introduce three types of errors.\n1.FP: False positive  2.FN1: False negative for customers with MonthlyCharges below 95 USD  3.FN2: False negative for customers with MonthlyCharges above 95 USD (VIP customers)  Let’s agree on the misclassification ratio, which is FP:FN1:FN2 = 1:3:5 \nIt’s important to note that this dataset is imbalanced, meaning there is a significant difference in the number of samples between the classes.\nBased on these problems, we can set up our model’s parameters as follows: 1.Hyperparameter tuning. 2.Decision threshold tuning. 3.Oversampling data using SMOTE. 4.Applying weights to the models. I will be using Random Forest, XGBoost, and Logistic Regression.\nMetrics: Custom scoring based on sample misclassification. Precision. Recall. F1_score. Once the models are evaluated using these metrics, I will interpret the best model.\n\n\n\ndf1 = df.copy()\n\n\ndf = df1.copy()\n\n\n#drop columns\ndf.drop(columns = ['Services','MonthlyChargesEstimationDifference','Status','PaperlessBilling','PaymentMethod'], inplace=True)\n\nI have dropped the columns from ‘Services’ to ‘Status’ as these columns were engineered features created for simpler exploratory data analysis (EDA). Additionally, I have also dropped the ‘PaperlessBilling’ and ‘PaymentMethod’ columns because, in the business context, these columns are considered irrelevant for determining customer churn since they represent optional ‘features’ for customers.\n\n#converting 'No internet service' to 'No' in benefit columns.\nKolomBenefit = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfor x in KolomBenefit:\n    df[x] = df[x].apply(lambda x: 'No' if x == 'No internet service' else x)\n\n\n#converting 'No phone service' to 'No'\ndf['MultipleLines'] = df[x].apply(lambda x: 'No' if x == 'No phone service' else x)\n\n\n#dict to mapping string to numerical.\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\n\n\n#binary encoding\nbinary = list(df.drop(columns=['tenure','InternetService','MonthlyCharges','TotalCharges','TotalBenefits','Contract','FO_LB']).columns)\n\nfor col in binary:\n    df[col] = df[col].map(value_mapping).astype('int64')\n\n\n#label encoding\ndf['Contract'] = df['Contract'].apply(lambda x: 1 if x == 'Month-to-month' else 2 if x == 'One year' else 3) \n\n\n#one hot encoding\ndf = pd.get_dummies(df, columns=['InternetService'])\n\n\n#feature selection\ndf = df[['Contract','tenure','InternetService_Fiber optic','MonthlyCharges','FO_LB','InternetService_No','Churn']]\ndf = df.rename(columns={\n                'InternetService_Fiber optic':'Fiber_optic',\n                'InternetService_No':'No_internet'})\n\nHere I only choose a feature that have a strong predictive power (by using feature of importances)\n\n\n\n\n#split train-test\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Churn'), df.Churn.to_numpy(), test_size = 0.2, random_state=123)\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\n\n#custom function to do threshold tuning and custom metrics (used in GridSearchCV)\ndef my_scorer_2(clf, X, y_true, thres = np.arange(0.1,1,0.1)):\n    result_dict = {}\n    for threshold in np.atleast_1d(thres):\n        y_pred = (clf.predict_proba(X)[:,1] &gt; threshold).astype(int)\n        X_segment = (X['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\n        y_stack = np.column_stack((X_segment, y_pred, y_true))\n        y_stack_reg, y_stack_vip = y_stack[y_stack[:,0] == 0], y_stack[y_stack[:,0] == 1]\n        cm_reg = confusion_matrix(y_stack_reg[:,2], y_stack_reg[:,1])\n        cm_vip = confusion_matrix(y_stack_vip[:,2], y_stack_vip[:,1])\n        fn_reg, fn_vip = cm_reg[1][0], cm_vip[1][0]\n        fp = cm_reg[0][1] + cm_vip[0][1]\n        loss_score = (fp * 1) + (fn_reg * 3) + (fn_vip * 5)\n        result_dict[threshold] = np.array([loss_score, metrics.precision_score(y_true, y_pred, zero_division = 0), \n                                           metrics.recall_score(y_true, y_pred), metrics.f1_score(y_true, y_pred)])\n        \n    result_np = np.array([np.insert(value, 0, key) for key, value in result_dict.items()])\n    best_np = result_np[result_np[:,1] == np.min(result_np[:,1])][0]\n    return best_np\n\ndef my_scorer_threshold(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[0]\n\ndef my_scorer_ls(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[1]\n\ndef my_scorer_precision(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[2]\n\ndef my_scorer_recall(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[3]\n\ndef my_scorer_f1(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[4]\n        \n        \n\n\n#Grid scoring parameter\ngrid_scoring = {\n    'threshold': my_scorer_threshold,\n    'loss_score': my_scorer_ls,\n    'precision': my_scorer_precision,\n    'recall': my_scorer_recall,\n    'f1': my_scorer_f1\n}\n\n\n#define weight by missclassification cost which is FP:FN1:FN2 = 1:3:5\nX_segment = (X_train['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\narr_weight = np.column_stack((X_segment, y_train))\nweight = np.apply_along_axis(lambda x: 1 if x[1] == 0 else 5 if x[0] == 1 else 3 , axis=1, arr=arr_weight)\n\n\n\n\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train)\n\n#evaluate the model\nmb1_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb1_rf = np.append(mb1_rf, grid_result.iloc[0,0])\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb1_xg = np.append(mb1_xg, grid_result.iloc[0,0])\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb1_lg = np.append(mb1_lg, grid_result.iloc[0,0])\n\n\nresult_mb1 = pd.DataFrame([mb1_rf,mb1_xg,mb1_lg])\nresult_mb1.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb1['model'] = ['MB1_RF','MB1_XG','MB1_Log_Reg']\nresult_mb1\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n\n\n\n\n\n\n\n\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf_smote = {\n    'class__n_estimators': [250 , 400],\n    'class__max_depth': [10, 25, 50],\n    'class__min_samples_split': [25, 50, 70, 120],\n    'class__min_samples_leaf': [50, 75, 120],\n    'class__bootstrap' : [True, False]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinerf = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', RandomForestClassifier())])\n\n#run grid search cv\nrf = GridSearchCV(estimator = pipelinerf,\n                  param_grid = param_grid_rf_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nrf = RandomForestClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nrf = rf.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb2_rf = np.append(mb2_rf, params)\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg_smote = {\n    'class__learning_rate': [0.1, 0.01, 0.001],\n    'class__n_estimators': [100, 500],\n    'class__max_depth': [5, 10, 25],\n    'class__subsample': [0.8, 0.9, 1.0],\n    'class__colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinexg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', XGBClassifier())])\n\n#run grid search cv\nxg = GridSearchCV(estimator = pipelinexg,\n                  param_grid = param_grid_xg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nxg = XGBClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nxg = xg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb2_xg = np.append(mb2_xg, params)\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg_smote = {\n    'class__penalty': ['l1', 'l2'], \n    'class__C': [0.1, 1.0, 10.0],  \n    'class__solver': ['liblinear'],  \n    'class__max_iter': [50,100,200] \n}\n\n\n#create imbalanced pipeline to SMOTE \npipelinelg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', LogisticRegression())])\n\n#run grid search cv\nlg = GridSearchCV(estimator = pipelinelg,\n                  param_grid = param_grid_lg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nlg = LogisticRegression(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nlg = lg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb2_lg = np.append(mb2_lg, params)\n\n\nresult_mb2 = pd.DataFrame([mb2_rf,mb2_xg,mb2_lg])\nresult_mb2.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb2['model'] = ['MB2_RF','MB2_XG','MB2_Log_Reg']\nresult_mb2\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n\n\n\n\n\nYou see that the threshold on all models are increasing than model building 1 because SMOTE make the models learn more on the positive class.\n\n\n\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb3_rf = np.append(mb3_rf, grid_result.iloc[0,0])\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb3_xg = np.append(mb3_xg, grid_result.iloc[0,0])\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb3_lg = np.append(mb3_lg, grid_result.iloc[0,0])\n\n\nresult_mb3 = pd.DataFrame([mb3_rf,mb3_xg,mb3_lg])\nresult_mb3.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb3['model'] = ['MB3_RF','MB3_XG','MB3_Log_Reg']\nresult_mb3\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\n\nfinal_result = pd.concat([result_mb1, result_mb2, result_mb3]).sort_values('score')\nfinal_result\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\nAnalysis of how the models performed: 1.RandomForest performs best with hyperparameter tuning and a lower decision threshold. However, this model performs worst when using SMOTE. 2.LogisticRegression performs worst when using ‘sample weighting’. 3.XGBoost performs best when using SMOTE. 4.It’s important to note that all models produce similar results when using their best parameters and conditions. 5.In my opinion, the greatest impact is achieved by using hyperparameter tuning and decision threshold tuning, rather than using SMOTE and weighting techniques."
  },
  {
    "objectID": "ipynb/final-project.html#model-interpretation",
    "href": "ipynb/final-project.html#model-interpretation",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "In this section, I want to show you how to interpret a tree-based model, such as Random Forest, so we can have a better understanding of how the model actually works.\n\n#selecting the best parameter for random forest\nrf_param = final_result[final_result['model'] == 'MB1_RF']['params'][0]\nrf_param\n\n{'bootstrap': True,\n 'max_depth': 25,\n 'min_samples_leaf': 50,\n 'min_samples_split': 50,\n 'n_estimators': 250}\n\n\n\nrf = RandomForestClassifier(**rf_param)\nrf.fit(X_train, y_train)\n\nRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)\n\n\n\n\nWhat is ICE? It is a plot that shows how a model makes predictions based on changing the value of one or more features, while keeping the values of other features constant. This provides us with more insights and understanding of how the model treats features to make predictions. ICE works per row (or per customer in this case), and PDP is simply the average of ICE.\n\ndef pdp_ice_plot(model, df_test, column, clusters=True):\n    df_test = df_test.copy()\n    pdp_isolate = pdp.PDPIsolate(model = model, df = df_test, \n                      num_grid_points=15,\n                      model_features = df_test.columns, \n                      feature = column, feature_name=column)\n    pdp_isolate.plot(\n                center=True, plot_lines=True,\n                cluster=clusters, n_cluster_centers=5,cluster_method='accurate',\n                plot_pts_dist=False, to_bins=True,\n                show_percentile=False, which_classes=None,\n                figsize=(10,6), dpi=300,\n                ncols=2, plot_params={\"pdp_hl\": True},\n                engine='matplotlib', template='plotly_white')\n    plt.show()\n    \n\n\npdp_ice_plot(rf, X_test, 'MonthlyCharges', False)\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe light blue lines represent ICE (Individual Conditional Expectation), and the yellowish blue line represents PDP (Partial Dependence Plot). The X-axis represents MonthlyCharges, while the Y-axis represents the change in prediction probability. At MonthlyCharges of 60.7 USD, you can observe that some customers experience a significant increase in churn probability as the MonthlyCharges increase. However, it is important to note that not all customers have the same response. Some customers are minimally affected, and some may not be affected at all.\n\npdp_ice_plot(rf, X_test, 'MonthlyCharges')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThis is the same plot as above, but I have grouped the ICE into 5 clusters for easier viewing and analysis. You can see that there are some customers who experience a significant increase in churn probability as the MonthlyCharges increase.\n\npdp_ice_plot(rf, X_test, 'tenure')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe longer the tenure, the lower the churn probability. However, the effect is not the same for all customers. Some customers are greatly affected, while others are barely affected.\n\npdp_ice_plot(rf, X_test, 'Contract')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe same also goes with Contract. Longer contract means lower churn probability.\n\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=6,\n                              model_features = X_test.columns, \n                              features=['MonthlyCharges','tenure'], \n                              feature_names=['MonthlyCharges','tenure'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s analyze the combination of MonthlyCharges and tenure. We can observe a spike in churn probability for MonthlyCharges ranging from 56.3 USD to 79.2 USD, particularly for customers with a tenure of less than 7 months.\n\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=10,\n                              model_features = X_test.columns, \n                              features=['tenure','Contract'], \n                              feature_names=['tenure','Contract'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model produces similar churn probabilities for customers with a combination of a 2-year contract and low tenure compared to those with a month-to-month contract and medium tenure (24-36 months).\nYou can see how PDP and ICE plots can be very beneficial in understanding how the model utilizes features to make predictions. In the next section, I will demonstrate how to assess the model’s prediction confidence level.\n\n\n\nTree-based models like RandomForest make predictions by using the mean of all the trees’ prediction probabilities. However, instead of solely relying on the mean, we can also calculate the standard deviation. A higher standard deviation indicates lower confidence in the predictions. Additionally, we can utilize confidence intervals, such as 95% or even more extreme at 99%.\n\n#extract all trees' prediction probability per row\npredict = np.stack([x.predict_proba(X_test)[:,1] for x in rf.estimators_])\n\n\n#assign mean and std. deviation of trees' prediction probability.\ndf_pred = X_test.copy()\ndf_pred['avg'] = np.round(np.mean(predict, axis = 0) * 100, 2)\ndf_pred['std_dev'] = np.round(np.std(predict, axis = 0) * 100, 2)\n\n\nplt.figure(figsize=(10,6))\nsns.histplot(df_pred['std_dev'],color='skyblue', kde=True, edgecolor='none')\nplt.title('Standard deviation distribution', weight='bold')\nplt.show()\n\n\n\n\nMost of predictions have std.deviation under 10%. Let’s calculate confidence interval with 99%.\n\ndf_pred['CI-99%'] = (2.576 * df_pred['std_dev'] / np.sqrt(len(predict))) * 100 / (df_pred['avg'])\n\n\ndf_pred[df_pred.avg &gt; 40].sort_values('CI-99%', ascending=False).head(5)\n\n\n\n\n\n\n\n\nContract\ntenure\nFiber_optic\nMonthlyCharges\nFO_LB\nNo_internet\navg\nstd_dev\nCI-99%\n\n\n\n\n852\n2\n7\n1\n94.05\n1\n0\n40.06\n25.08\n10.199818\n\n\n499\n1\n58\n1\n98.70\n1\n0\n41.05\n18.24\n7.239149\n\n\n1186\n1\n59\n1\n101.10\n1\n0\n40.37\n16.73\n6.751699\n\n\n1137\n1\n15\n1\n96.30\n0\n0\n48.14\n19.69\n6.663701\n\n\n1184\n1\n10\n1\n92.50\n0\n0\n48.17\n19.12\n6.466765\n\n\n\n\n\n\n\nLet’s consider the example of row 1. The model predicts a 40% probability of churn for the customer, with a confidence interval of +- 10%. By default, the model’s output indicates that the customer will not churn. However, due to the high confidence interval, it is safer to assume that the customer will churn.\nChecking the standard deviation and confidence interval of the trees is extremely useful, particularly when the cost of ‘False Negative’ is significant and can have severe consequences."
  },
  {
    "objectID": "posts/post-ketiga/index.html",
    "href": "posts/post-ketiga/index.html",
    "title": "Telco customer churn analysis",
    "section": "",
    "text": "On this occasion, I would like to discuss one of my projects that involves the telco customer churn dataset. Who doesn’t know about telco customer churn? This dataset is exceedingly common, and I’m confident that every data science practitioner has worked with it at some point. So, why am I still using this dataset? It’s because I want to demonstrate a different and more detailed approach on how to process it. Here, I will conduct a deeper Exploratory Data Analysis (EDA) and showcase how to create and fine-tune a machine learning model to align it with the intended business objectives, followed by interpreting the results.\nOf course, the goals of this project are to produce actionable insights and the most suitable predictive model aligned with the existing business concepts. On this particular blog post, I will show detailed step by step on how to do the projects (including the codes) so this will be very technical, but if you just want to see the big picture you can visit this link:\nPresentation link : Click here  App deployment link : shinyapps.io"
  },
  {
    "objectID": "posts/post-ketiga/index.html#table-of-contents",
    "href": "posts/post-ketiga/index.html#table-of-contents",
    "title": "Telco customer churn analysis",
    "section": "Table Of Contents",
    "text": "Table Of Contents\n• Data Introduction  • Data Preparation (Import libraries, data cleaning & data wrangling) • Basic exploratory data analysis      • Descriptive statistic      • Univariate analysis      • Multivariate analysis  • Deep exploratory data analysis      • Services and internet services analysis      • Monthly charges analysis      • Customer analysis      • Benefits analysis      • Churn analysis  • Modelling     • Features selection and encoding      • Splits data and define custom metrics      • Model building combination 1      • Model building combination 2      • Model building combination 3\n• Model interpretation     • PDP and ICE plots      • Checking prediction’s confidence using confidence interval"
  },
  {
    "objectID": "posts/post-ketiga/index.html#data-introduction",
    "href": "posts/post-ketiga/index.html#data-introduction",
    "title": "Telco customer churn analysis",
    "section": "Data Introduction",
    "text": "Data Introduction\nThis dataset contain informations about customers that churn and not churned in a telco company. Below is the column informations: 1.customerID = customer unique ID. 2.gender = customer gender (M/F). 3.SeniorCitizen = old / young customer. 4.Partner = either a customer has partners or not. 5.Dependents = either a customer has dependents or not. 6.tenure = how long the customer subscribed (in month). 7.MultipleLines = either a customer using multiple lines or not (phone lines). 8.InternetService = either a customer using InternetService lines or not. 9.OnlineSecurity = either a customer has OnlineSecurity or not. 10.OnlineBackup = either a customer has OnlineBackup or not. 11.DeviceProtection = either a customer has DeviceProtection or not. 12.TechSupport = either a customer has TechSupport or not. 13.StreamingTV = either a customer has StreamingTV or not. 14.StreamingMovies = either a customer has StreamingMovie or not. 15.Contract = types of contract. 16.PaperlessBilling = either a customer has PaperlessBilling or not. 17.PaymentMethod = types of the payment method. 18.MonthlyCharges = how much charges per month. 19.TotalCharges = total charges of all time. 20.Churn = either a customer churn or not. 21.Hobby = customer hobby."
  },
  {
    "objectID": "posts/post-ketiga/index.html#data-preparation",
    "href": "posts/post-ketiga/index.html#data-preparation",
    "title": "Telco customer churn analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib as mpl\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom pdpbox import pdp, info_plots\nsns.set_style('darkgrid')\nmpl.rcParams['figure.dpi'] = 300 #set figure dpi\nsns.set() #set figure styling\n\n\n\n\nCode\n#import dataset\ndf = pd.read_csv('telco.csv')\ndf.head()\n\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\nHobby\n\n\n\n\n0\n7590-VHVEG\nFemale\n0\nYes\nNo\n135\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n29.85\n29.85\nNo\nSwimming\n\n\n1\n5575-GNVDE\nMale\n0\nNo\nNo\n34\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nOne year\nNo\nMailed check\n56.95\n1889.5\nNo\nRunning\n\n\n2\n3668-QPYBK\nMale\n0\nNo\nNo\n140\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nMailed check\n53.85\n7560\nYes\nHiking\n\n\n3\n7795-CFOCW\nMale\n0\nNo\nNo\n136\nNo\nNo phone service\nDSL\nYes\n...\nYes\nNo\nNo\nOne year\nNo\nBank transfer (automatic)\n42.45\n1840.75\nNo\nSwimming\n\n\n4\n9237-HQITU\nFemale\n0\nNo\nNo\n2\nYes\nNo\nFiber optic\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n70.70\n151.65\nYes\nRunning\n\n\n\n\n5 rows × 22 columns\n\n\n\n\n\nCode\n#take a look at the dataframe\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 7043 entries, 0 to 7042\nData columns (total 22 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   customerID        7043 non-null   object \n 1   gender            7043 non-null   object \n 2   SeniorCitizen     7043 non-null   int64  \n 3   Partner           7043 non-null   object \n 4   Dependents        7043 non-null   object \n 5   tenure            7043 non-null   int64  \n 6   PhoneService      7043 non-null   object \n 7   MultipleLines     7043 non-null   object \n 8   InternetService   7043 non-null   object \n 9   OnlineSecurity    7043 non-null   object \n 10  OnlineBackup      7043 non-null   object \n 11  DeviceProtection  6627 non-null   object \n 12  TechSupport       7043 non-null   object \n 13  StreamingTV       7043 non-null   object \n 14  StreamingMovies   7043 non-null   object \n 15  Contract          6798 non-null   object \n 16  PaperlessBilling  7043 non-null   object \n 17  PaymentMethod     7043 non-null   object \n 18  MonthlyCharges    7043 non-null   float64\n 19  TotalCharges      4859 non-null   object \n 20  Churn             7043 non-null   object \n 21  Hobby             4201 non-null   object \ndtypes: float64(1), int64(2), object(19)\nmemory usage: 1.2+ MB\n\n\nThere are 4 columns with missing values which are DeviceProtection, Contract, TotalCharges and Hobby.\n\n\nCode\n#checking percentage of missing values\nmissingkolom = ['DeviceProtection','Contract','TotalCharges','Hobby']\nfor x in missingkolom:\n    print(f'Missing value of column {x} (%) : {round(df[x].isna().sum()/len(df) * 100,2)}')\n\n\nMissing value of column DeviceProtection (%) : 5.91\nMissing value of column Contract (%) : 3.48\nMissing value of column TotalCharges (%) : 31.01\nMissing value of column Hobby (%) : 40.35\n\n\n\n\nCode\n#impute missing values with univariate imputation by value proportion\ndf['DeviceProtection'] = df['DeviceProtection'].fillna(\n                             pd.Series(np.random.choice(['No','Yes','No internet service'], \n                             p = list(df['DeviceProtection'].value_counts(normalize=True)), size=len(df))))\n\ndf['Contract'] = df['Contract'].fillna(\n                     pd.Series(np.random.choice(['Month-to-month','Two year','One year'], \n                     p = list(df['Contract'].value_counts(normalize=True)), size=len(df))))\n\n\nHere I impute DeviceProtection and Contract with univariate imputation by value proportion for the following reasons: 1.The missing values is not that much (&lt;10%). 2.The columns don’t have any relationship with other columns so that multivariate imputation is not possible. 3.Using proportion is more precise in this case rather than use ‘mode’.\n\n\nCode\n#delete column Hobby\ndf.drop(columns=['Hobby'],inplace=True)\n\n\nReasons to delete: 1.Missing values is too many. 2.By business context, Hobby doesn’t give enough useful informations. 3.Cannot be imputed by multivariate imputation.\n\n\nCode\n#impute TotalCharges from tenure and MonthlyCharges\ndf['TotalCharges'] = df['TotalCharges'].fillna(df['tenure'] * df['MonthlyCharges'])\n\n\nEven this column has so many missing values, I decided to impute it with multivariate imputation because: 1.By business context, TotalCharges is more or less tenure * MonthlyCharges. 2.So even the missing values are high, it can still be imputed with a strong justification.\n\n\nCode\n#there's a space in the total charges column.\nfor x in df.TotalCharges:\n    try:\n        float(x)\n    except:\n        print(f'Unable to convert to float with this value : {x}')\n\n\nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \n\n\n\n\nCode\ndf[df.TotalCharges == ' '].head()\n\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\n\n\n\n\n488\n4472-LVYGI\nFemale\n0\nYes\nYes\n0\nNo\nNo phone service\nDSL\nYes\n...\nYes\nYes\nYes\nNo\nOne year\nYes\nBank transfer (automatic)\n52.55\n\nNo\n\n\n753\n3115-CZMZD\nMale\n0\nNo\nYes\n0\nYes\nNo\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n20.25\n\nNo\n\n\n936\n5709-LVOEQ\nFemale\n0\nYes\nYes\n0\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nYes\nYes\nTwo year\nNo\nMailed check\n80.85\n\nNo\n\n\n1082\n4367-NUYAO\nMale\n0\nYes\nYes\n0\nYes\nYes\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n25.75\n\nNo\n\n\n1334\n1768-ZAIFU\nFemale\n1\nNo\nNo\n0\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n25.20\n\nYes\n\n\n\n\n5 rows × 21 columns\n\n\n\nWhen the tenure value is 0, the TotalCharges value is empty (‘space’). This is because customers who have just joined (less than a month) have not been charged yet, resulting in a TotalCharges value of 0. Since there are only 12 rows with this condition, I will delete them.\n\n\nCode\n#drop rows that has empty TotalCharges.\ndf = df.drop(df.index[df.TotalCharges == ' ']).reset_index(drop=True)\n\n\n\n\nCode\n#check for duplicate data, if True then there's no duplicate.\ndf.customerID.nunique() == len(df) \n\n\nTrue\n\n\n\n\nCode\n#feature engineered 2 new features for the sake of easier analysis.\ndf['Services'] = df[['PhoneService','InternetService']].apply(\n                     lambda x: 'Both' if list(x).count('No') == 0 else\n                     'Internet Only' if x[0] == 'No' else 'Phone Only', axis=1)\n\ndf['TotalBenefits'] = df.loc[:,'OnlineSecurity':'StreamingMovies']\\\n                          .apply(lambda x: list(x).count('Yes'), axis=1)\n\n\nNew features explanation:  1.Services = Combined values of PhoneService and InternetService. 2.TotalBenefits = Sum of benefits taken on OnlineSecurity until StreamingMovies.\n\n\nCode\n#Change values of 1 and 0 to 'Yes' and 'No'\ndf['SeniorCitizen'] = df.SeniorCitizen.apply(lambda x: 'Yes' if x == 1 else 'No')\n\n\nChange numerical value to strings for simpler and consistent analysis.\n\n\nCode\n#drop useless column\ndf.drop(columns=['customerID'], inplace=True)\n\n\n\n\nCode\n#change columns object data type to numerical\ndf.tenure = df.tenure.astype('int64')\ndf.MonthlyCharges = df.MonthlyCharges.astype('float64')\ndf.TotalCharges = df.TotalCharges.astype('float64')\n\n\n\n\nCode\n#checking values of real totalcharges and calculated totalcharges\ndf['TotalChargesDiff'] = df[['tenure','MonthlyCharges','TotalCharges']].apply(\n                             lambda x: round(abs(1 - (x[0] * x[1] / x[2])) * 100, 3), axis=1)\n\n\nHere, I have created a new column called TotalChargesDiff to check the differences (%) between the actual TotalCharges value (from the dataset) and the calculated TotalCharges value (obtained by multiplying tenure with MonthlyCharges). If the difference is above 40%, I will consider those rows as invalid because the values of tenure and MonthlyCharges cannot be trusted.\n\n\nCode\ndf['TotalChargesDiff'].sort_values(ascending=False).head(10)\n\n\n0       13400.000\n5        1357.404\n18        788.048\n19        330.214\n3         213.633\n128        73.511\n47         72.615\n4631       64.286\n5802       63.380\n20         58.263\nName: TotalChargesDiff, dtype: float64\n\n\nYou can observe that some data points have a TotalChargesDiff that reaches hundreds or even thousands percent.\n\n\nCode\n#removing rows that have &gt; 40% TotalChargesDiff.\ndf = df[df.TotalChargesDiff &lt; 40].reset_index(drop=True)\ndf.drop(columns=['TotalChargesDiff'], inplace=True)\n\n\n\n\nCode\ndef numericategoric(df):\n    num = len(df._get_numeric_data().columns)\n    cat = len(df.columns) - num\n    print(\"TotalNumericalData = \" + str(num))\n    print(\"TotalCategoricalData = \" + str(cat))\n    print(\"Numerical = \" + str(list(df._get_numeric_data().columns )))\n    print(\"Categorical = \" + str(list(df.drop(df._get_numeric_data().columns, axis=1).columns)))\n\n\n\n\nCode\nnumericategoric(df)\n\n\nTotalNumericalData = 4\nTotalCategoricalData = 18\nNumerical = ['tenure', 'MonthlyCharges', 'TotalCharges', 'TotalBenefits']\nCategorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn', 'Services']\n\n\nShow numerical and categorical columns\n\n\nCode\n#assign categorical and numerical columns on different dataframe for easier analysis.\ndfnum = df._get_numeric_data()\ndfcat = df.drop(columns = dfnum.columns)"
  },
  {
    "objectID": "posts/post-ketiga/index.html#basic-exploratory-data-analysis.",
    "href": "posts/post-ketiga/index.html#basic-exploratory-data-analysis.",
    "title": "Telco customer churn analysis",
    "section": "Basic Exploratory Data Analysis.",
    "text": "Basic Exploratory Data Analysis.\n\nDescriptive Statistics\n\n\nCode\n#numerical columns describe.\ndfnum.describe()\n\n\n\n\n\n\n\n\n\ntenure\nMonthlyCharges\nTotalCharges\nTotalBenefits\n\n\n\n\ncount\n7012.000000\n7012.000000\n7012.000000\n7012.000000\n\n\nmean\n32.506560\n64.732760\n2286.410207\n2.042356\n\n\nstd\n24.564234\n30.109753\n2265.759401\n1.835886\n\n\nmin\n1.000000\n12.000000\n13.500000\n0.000000\n\n\n25%\n9.000000\n35.450000\n402.437500\n0.000000\n\n\n50%\n29.000000\n70.300000\n1397.250000\n2.000000\n\n\n75%\n56.000000\n89.850000\n3784.125000\n3.000000\n\n\nmax\n140.000000\n118.750000\n8684.800000\n6.000000\n\n\n\n\n\n\n\n1.All columns seems to have a normal min-max values. Nothing weird here. 2.Average tenure is about 30 months which is pretty low. 3.Average MonthlyCharge is about 65-70 USD which is pretty good. 4.Out of 6 benefits available, the average taken by customer is around 2, which is pretty low.\n\n\nCode\ndfcat.describe()\n\n\n\n\n\n\n\n\n\ngender\nSeniorCitizen\nPartner\nDependents\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\nOnlineBackup\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nChurn\nServices\n\n\n\n\ncount\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n\n\nunique\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n2\n4\n2\n3\n\n\ntop\nMale\nNo\nNo\nNo\nYes\nNo\nFiber optic\nNo\nNo\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\nNo\nBoth\n\n\nfreq\n3542\n5874\n3624\n4920\n6336\n3372\n3087\n3486\n3075\n3066\n3459\n2798\n2769\n3850\n4155\n2354\n5155\n4821\n\n\n\n\n\n\n\n1.Male and Female has the same proportion. 2.Most of customers is non SeniorCitizen with no Partner and No Dependents. 3.Favorite InternetService is Fiber optic. 4.Majority of customers is subscribed with ‘Month-to-month’ Contract. 5.5155 out of 7012 is non-Churn customers which make this dataset is imbalanced. 6.All these columns have low cardiality values.\n\n\nUnivariate Analysis\n\n\nCode\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    axarr[dfnum.columns.get_loc(x)].boxplot(df[x],patch_artist=True)\n    axarr[dfnum.columns.get_loc(x)].set_xlabel(x)\nplt.suptitle('Outliers checking on numeric columns')\nfig.tight_layout(pad=1)\nplt.show()\n\n\n\n\n\nWill drop outlier in tenure.\n\n\nCode\n#drop outlier in tenure\ndf = df[df.tenure &lt; 125]\n\n\n\n\nCode\n#plot distribution for numerical columns\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=dfnum[x], \n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)])\nplt.suptitle('Distribution plot', weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\n\nAbove plots are distribution plots on all numerical columns. 1.tenure and MonthlyCharges have a ‘U-shaped’ distribution. 2.TotalCharges has a positive-skew distribution.\n\n\nCode\n#count plot for categorical columns\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(x=df[features[i-1]], color='green')\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\n\nHere I count plotted all categorical columns.\n\n\nMultivariate Analysis\n\n\nCode\n#count plots against 'churn'\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(data=df, x=df[features[i-1]], hue='Churn')\n    plt.legend(prop={'size': 8})\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot vs Churned', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\n\nI added Churn count into the categorical plots. 1.You can see for column Gender, the values and Churn count is pretty equal which make this column will have a very low predictive power. 2.For InternetService, fiber optic has way higher in churn probability compare to DSL. 3.Same ways also applied on Month-to-month Contract and Electronic-check PaymentMethod.\n\n\nCode\n#distribution plots against 'churn'\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=df, \n                 x = dfnum[x],\n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)], \n                 hue='Churn')\n    \nplt.suptitle(\"Distribution plot\", weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\n\nLet’s also compare Churn distribution on numerical columns. Customers tend to churn when the tenure is low and not churn when the MonthlyCharges is very low. I will do further analysis about these columns later.\n\n\nCode\n#change binary column into numerical\nbinary = ['gender','SeniorCitizen','Partner','Dependents','PhoneService','PaperlessBilling','Churn']\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\ndfcorr = df[binary]\nfor col in binary:\n    dfcorr[col] = dfcorr[col].map(value_mapping).astype('int64')\n\n\n\n\nCode\nplt.figure(figsize=(10,8))\nsns.heatmap(dfcorr.corr(), annot=True, fmt='.2f')\nplt.show()\n\n\n\n\n\nCorrelation! 1.TotalCharges and tenure have a high positive correlation (causation : the longer the customers subscribed, the more they paid). 2.TotalBenefits also has a strong correlation with MonthlyCharges and TotalCharges (causation : more benefits taken also make the MonthlyCharges higher). Note : Correlation doesn’t indicate causation. Understanding the specific context, industry knowledge, and conducting further analysis or experiments can help determine if there is a causal relationship between the variables or if other factors are influencing the observed correlations."
  },
  {
    "objectID": "posts/post-ketiga/index.html#deep-dive-exploratory-data-analysis",
    "href": "posts/post-ketiga/index.html#deep-dive-exploratory-data-analysis",
    "title": "Telco customer churn analysis",
    "section": "Deep-Dive Exploratory Data Analysis",
    "text": "Deep-Dive Exploratory Data Analysis\n\n\nCode\n#create a function to plot churn probability for numerical columns.\ndef prob_plot(df,colom,x):\n    means = df[colom].mean()\n    medians = df[colom].median()\n    data = df[df.Churn == 'Yes'][colom].astype('float64')\n    data1 = df[df.Churn == 'No'][colom].astype('float64')\n    \n    kde = gaussian_kde(data)\n    kde1 = gaussian_kde(data1)\n    dist_space = np.linspace( min(data), max(data), 200)\n    dist_space1 = np.linspace( min(data1), max(data1), 200)\n    axarr[x].plot( dist_space, kde(dist_space), label='Churned', color='orange' )\n    axarr[x].plot( dist_space1, kde1(dist_space1), label='Not churn', color='blue')\n    axarr[x].axvline(x = means, linestyle = '--', color='g', label='Mean')\n    axarr[x].axvline(x = medians, linestyle = '--', color='r', label='Median')\n    axarr[x].set_title('Probability', fontweight='bold', size=12)\n    axarr[x].set(ylabel = 'Probability', xlabel = colom)\n    axarr[x].legend()\n\n\n\nServices & InternetService analysis\n\n\nCode\n#count plot for Services.\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(data=df[df.Services == 'Both'], \n              x='InternetService', \n              ax=axarr[0])\n\nsns.countplot(data=df[df.Services == 'Internet Only'], \n              x='InternetService', \n              ax=axarr[1])\n\naxarr[0].set_title(\"Both phone service & internet service\", weight='bold')\naxarr[1].set_title(\"Internet service only\", weight='bold')\n\nplt.suptitle(\"Comparison of internet services on product services\")\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\n\nIt is observed that customers tend to prefer Fiber optic over DSL for ‘phone & internet service’. However, when considering ‘internet service only’ without phone, there is no option for Fiber optic available. This suggests that in order to utilize Fiber optic, a phone connection (or phone service) is required.\n\n\nCode\n#plot churn probability for 'services' & 'internet services'\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\n\ndf.groupby('Services')['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(list(x)))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[0])\n\ndf[df.Services != 'Phone Only'].groupby(['InternetService'])['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(x))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[1])\n\naxarr[0].set_title('Services churn probability', weight='bold')\naxarr[1].set_title('Internet service churn probability', weight='bold')\n\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\n\nCustomers that used ‘Both’ services and InternetService fiber optic tends to churn more.\n\n\nMonthlyCharges analysis\n\n\nCode\n#checking InternetService price.\ndf_filtered = df[(df.Services == 'Both') & (df.TotalBenefits == 0) & (df.MultipleLines == 'No')].copy()\ndf_filtered.groupby('InternetService')['MonthlyCharges'].mean()\n\n\nInternetService\nDSL            44.965089\nFiber optic    70.074454\nName: MonthlyCharges, dtype: float64\n\n\n\nThe price of Fiber optic is higher, around 25 USD, compared to DSL. However, it’s important to keep in mind that these prices include a phone service with a single line.\n\n\n\nCode\ndf_filtered = df[(df.Services == 'Phone Only') & (df.TotalBenefits == 0)].copy()\ndf_filtered.groupby('MultipleLines')['MonthlyCharges'].mean()\n\n\nMultipleLines\nNo     19.958088\nYes    24.980060\nName: MonthlyCharges, dtype: float64\n\n\n\n\nCode\nplt.figure(figsize=(10,5))\nsns.histplot(data=df_filtered, \n             x='MonthlyCharges', \n             hue='MultipleLines', \n             multiple='stack')\n\nplt.title('Phone service distribution', weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nWe can see that the price for a ‘phone service’ with a single line is around 20 USD, while the price for a ‘phone service’ with multiple lines is around 25 USD. This also means that the price for DSL is around 25 USD, while the price for Fiber optic is around 50 USD, which is twice as much as DSL.\n\n\nCode\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nmc_dist = sns.histplot(data=df, \n                       x = 'MonthlyCharges',\n                       hue='Churn', \n                       ax=axarr[0], \n                       multiple='stack')\n\naxarr[0].set_title('Distribution', fontweight='bold', size=12)\n\nprob_plot(df,'MonthlyCharges',1)\naxarr[1].legend(loc='upper right')\nplt.show()\n\n\n\n\n\nAt a MonthlyCharges range of approximately +- 20 USD, the ratio of non-churn customers is very high. It is known that products within this price range are typically ‘phone service only’. However, between the price range of 60 - 100 USD, the churn probability increases significantly. I am planning to conduct further analysis specifically for customers within this price range.\n\n\nCode\ndf_filtered = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both') & (df.MultipleLines == 'No')]\ndf_agg = df_filtered.groupby('TotalBenefits')['MonthlyCharges'].agg('mean').reset_index()\ndf_agg['MonthlyCharges'] = df_agg.MonthlyCharges.round()\n\n\n\n\nCode\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.scatterplot(data=df_filtered, \n                x='MonthlyCharges', \n                y='TotalBenefits', \n                s=35, \n                ax=axarr[0])\n\nsns.barplot(df_agg, x = 'TotalBenefits', y = 'MonthlyCharges')\naxarr[0].set_title('MonthlyCharges vs Totalbenefits', weight='bold')\naxarr[1].set_title('Average MonthlyCharges vs Totalbenefits', weight='bold')\nfig.tight_layout(pad = 1)\nplt.show()\n\n\n\n\n\nHere, you can observe that as more TotalBenefits are taken, the MonthlyCharges also increase. On the left plot, you can see that there are 5 outlier data points, which will be removed later.\n\n\nCode\ndf_fil = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both')\\\n              & (df.MultipleLines == 'No') & (df.TotalBenefits == 1)]\n\nbenefits = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\ndf_benefit = pd.DataFrame()\nfor x in benefits:\n    df_value = pd.DataFrame([x, \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].min(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].max(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].mean(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].median()\n                     ]).transpose()\n    \n    df_benefit = pd.concat([df_benefit, df_value])\ndf_benefit.columns = ['Benefit','MinCharges','MaxCharges','MeanCharges','MedianCharges']    \n\n\n\n\nCode\ndf_benefit\n\n\n\n\n\n\n\n\n\nBenefit\nMinCharges\nMaxCharges\nMeanCharges\nMedianCharges\n\n\n\n\n0\nOnlineSecurity\n73.2\n76.45\n74.795588\n74.95\n\n\n0\nOnlineBackup\n72.75\n76.65\n74.708511\n74.65\n\n\n0\nDeviceProtection\n69.55\n76.65\n74.604762\n74.9\n\n\n0\nTechSupport\n73.85\n76.55\n75.045455\n74.7\n\n\n0\nStreamingTV\n77.65\n81.9\n79.749242\n79.825\n\n\n0\nStreamingMovies\n12.0\n86.1\n79.045902\n80.15\n\n\n\n\n\n\n\nAbove are the prices of benefits with Fiber optic and a single line phone connection. You can see that StreamingTV and StreamingMovies are more expensive compared to other benefits, approximately +- 5 USD.\nNow that we know the prices of every product, here’s a recap:\nDSL = approximately 25 USD. Fiber optic = approximately 50 USD. Phone service (single line) = approximately 20 USD. Phone service (multiple lines) = approximately 25 USD. OnlineSecurity - TechSupport = approximately 5 USD. StreamingTV - StreamingMovies = approximately 10 USD.\nWith this data, we can perform a simple ‘anomaly detection’ by manually calculating the MonthlyCharges and comparing them with the actual MonthlyCharges, similar to how we calculated the TotalChargesDiff above.\n\n\nCode\n#checking for MonthlyCharges values with the calculated one (similar with checking TotalCharges difference).\ndef MonthlyChargesDiff(x):\n    estimation = 0\n    if x['PhoneService'] == 'Yes':\n        estimation += 20\n    if x['MultipleLines'] == 'Yes':\n        estimation += 5\n    if x['InternetService'] == 'DSL':\n        estimation += 25\n    if x['InternetService'] == 'Fiber optic':\n        estimation += 50\n        \n    if (x['StreamingTV'] == 'Yes') & (x['StreamingMovies'] == 'Yes'):\n        estimation += 20 + (x['TotalBenefits'] - 2) * 5\n    elif (x['StreamingTV'] == 'Yes') | (x['StreamingMovies'] == 'Yes'):\n        estimation += 10 + (x['TotalBenefits'] - 1) * 5\n    else:\n        estimation += x['TotalBenefits'] * 5\n        \n    return abs(1 - (estimation / x['MonthlyCharges'])) * 100\n    \n   \n\n\n\n\nCode\ndf['MonthlyChargesEstimationDifference'] = df.apply(MonthlyChargesDiff, axis=1)\n\n\n\n\nCode\ndf[df.MonthlyChargesEstimationDifference &gt; 40][['MonthlyCharges','MonthlyChargesEstimationDifference']]\n\n\n\n\n\n\n\n\n\nMonthlyCharges\nMonthlyChargesEstimationDifference\n\n\n\n\n12\n29.00\n296.551724\n\n\n389\n12.00\n733.333333\n\n\n666\n12.00\n566.666667\n\n\n859\n26.41\n278.644453\n\n\n1439\n18.26\n447.645126\n\n\n2185\n21.63\n362.320851\n\n\n4090\n31.26\n219.897633\n\n\n5848\n15.00\n466.666667\n\n\n6718\n21.00\n304.761905\n\n\n\n\n\n\n\nYou can see that there are 9 rows with extreme MonthlyCharges values. These are considered as ‘anomalies’, so let’s remove them.\n\n\nCode\n#remove MonthlyCharges extreme values.\ndf = df[df.MonthlyChargesEstimationDifference &lt; 40].reset_index(drop=True)\n\n\n\n\nCustomer analysis\n\n\nCode\n#creating a function to engineered a new feature.\ndef statuss(x):\n    x = list(x)\n    if (x[0] == 'Yes') & (x[1] == 'Yes'):\n        return 'Both'\n    elif (x[0] == 'Yes') & (x[1] == 'No'):\n        return 'Partner Only'\n    elif (x[0] == 'No') & (x[1] == 'Yes'):\n        return 'Dependent Only'\n    else:\n        return 'Single'\n\n\n\n\nCode\ndf['Status'] = df[['Partner','Dependents']].apply(statuss, axis=1)\n\n\nI have created a new feature called ‘Status’. This feature is derived from the columns Partner and Dependents. 1.If customers have both Partner and Dependents, it will be labeled as ‘Both’. 2.If customers have Partner but no Dependents, it will be labeled as ‘Partner Only’. 3.If customers have Dependents but no Partner, it will be labeled as ‘Dependent Only’. 4.If customers have neither Partner nor Dependents, it will be labeled as ‘Single’.\n\n\nCode\nplt.figure(figsize=(10,5))\nsns.countplot(df.sort_values('Status', ascending=True), x='Status')\nplt.title('Status Count', size=16, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nMajority of customers are Single.\n\n\nCode\nfig, axarr = plt.subplots(1,3, figsize=(15, 6))\nk = ['tenure','MonthlyCharges','TotalBenefits']\nfor x in k:\n    sns.barplot(data=df.groupby(['Status'])[[x]].mean().reset_index(), \n                x='Status', \n                y=x, \n                ax=axarr[k.index(x)],\n                palette=['grey', 'g','m','b'])\n    \n    axarr[k.index(x)].set_title(f'{x} average', weight='bold', size=15)\n    \nfig.tight_layout()\nplt.show()\n\n\n\n\n\nCustomers labeled as ‘Partner Only’ are considered the best since they have the longest tenure and the highest MonthlyCharges. The second-best group is ‘Both’, although these customers may not have MonthlyCharges as high as those in the ‘Single’ group, their tenure is almost double that of the ‘Single’ group.\n\n\nCode\nplt.figure(figsize=(10,5))\nsns.barplot(data=df.groupby('Status')[['Churn']].agg(lambda x: list(x).count('Yes') / len(x)).reset_index(), \n            x='Status', \n            y='Churn')\n\nplt.title('Churn Probability', weight='bold', size=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nSingle customers have the highest churn probability.\n\n\nCode\ndf.SeniorCitizen.value_counts(normalize=True)\n\n\nSeniorCitizen\nNo     0.837903\nYes    0.162097\nName: proportion, dtype: float64\n\n\nThe majority of customers are young people.\n\n\nCode\ndf_status = df.groupby('SeniorCitizen')[['Status']]\ndf_status = df_status.agg(Single = ('Status', lambda x: list(x).count('Single') * 100 / len(x)), \n                          PartnerOnly = ('Status', lambda x: list(x).count('Partner Only') * 100  / len(x)), \n                          Both = ('Status', lambda x: list(x).count('Both') * 100  / len(x)), \n                          DependentOnly = ('Status', lambda x: list(x).count('Dependent Only') * 100  / len(x)))\ndf_status = df_status.reset_index().melt(id_vars='SeniorCitizen')\ndf_status = df_status.rename(columns={'variable':'Status'})\n\n\n\n\nCode\nplt.figure(figsize=(10,5))\n\nsns.barplot(data=df_status, \n            x ='SeniorCitizen', \n            y='value', \n            hue='Status')\n\nplt.title(\"Status comparison between senior citizen\", size=15, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFor non-Senior citizens, ‘Single’ customers have the highest frequency, followed by ‘Both’. For Senior citizens, ‘Single’ is also the highest category, but the difference with ‘PartnerOnly’ is not as significant. From the plots above, we can also conclude that young people tend to have dependents more than older people.\n\n\nCode\ndf_status = df.groupby('Status')[['OnlineSecurity','OnlineBackup',\n                                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n                                  .agg(lambda x: list(x).count('Yes'))\n    \ndf_status['total'] = df_status.apply('sum',axis=1)\n\nfor x in df_status.drop(columns='total').columns:\n    df_status[x] = (df_status[x] * 100 / df_status.total).round()\ndf_status.drop(columns='total', inplace=True)\n\n\n\n\nCode\ndf_status.plot(kind='bar', rot=0)\nplt.title('Benefit count comparison between status (%)', size=12, weight='bold')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()\n\n\n\n\n\nSingle and PartnerOnly customers tend to prefer entertainment benefits such as StreamingTV and StreamingMovies compared to other customers. Additionally, these customers show a lower preference for using TechSupport and OnlineSecurity.\n\n\nBenefits analysis\n\n\nCode\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(df[df.Services != 'Phone Only'], \n              x = 'TotalBenefits', ax=axarr[0])\n\nsns.barplot(df[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n            .apply(lambda x: list(x).count('Yes')).reset_index(), x = 'index', y = 0, ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Count', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None)\naxarr[1].set_title('Benefits Count', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\nThe average number of TotalBenefits taken by customers is around 3, with StreamingTV and StreamingMovies being the most popular choices.\n\n\nCode\ndf_total = pd.DataFrame()\nfor x in ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']:\n    total = list(df[df[x] == 'Yes']['Churn']).count('Yes') / len(df[df[x] == 'Yes']['Churn'])\n    df_total = pd.concat([df_total, pd.DataFrame([x],[total])])\n\n\n\n\nCode\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.barplot(df.groupby('TotalBenefits')[['Churn']]\\\n            .agg(lambda x: list(x).count('Yes') * 100 / len(x)).round().reset_index(), \n            x='TotalBenefits', \n            y='Churn', ax=axarr[0])\n\nsns.barplot(df_total.reset_index(), \n            x=0, \n            y='index', \n            ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Churn probability', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None, xlabel='Benefits')\naxarr[1].set_title('Benefits Churn probability', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\nWhile StreamingTV and StreamingMovies are the most favored choices, the churn probability associated with them is also the highest.\n\n\nChurn analysis\n\n\nCode\nfig, axarr = plt.subplots(1, figsize=(10, 6))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                hue ='Churn', \n                s=20)\n\nplt.fill_between((68 , 97),20, alpha=0.2, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.2, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs Churn', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\n\nHere, I have created two areas, denoted by green and blue, both focusing on MonthlyCharges in the range of 70 - 95 USD. This price range corresponds to the highest churn probability. The green area represents customers with low tenure and is predominantly occupied by churned customers, while the blue area represents customers with high tenure and is predominantly occupied by non-churned customers.\n\n\nCode\nplt.subplots(1, figsize=(15, 8))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                s=35, \n                hue='TotalBenefits', \n                style='InternetService', \n                palette='coolwarm')\n\nplt.fill_between((68 , 97),20, alpha=0.15, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.15, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs TotalBenefits vs InternetService', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\n\nStill on the same plot, I have added TotalBenefits and InternetService. It can be observed that in the green area, Fiber optic is the dominant InternetService with low TotalBenefits. On the other hand, the blue area is dominated by DSL with high TotalBenefits. This indicates that customers, at the same price point, tend to choose DSL with high TotalBenefits rather than Fiber optic with low TotalBenefits. Note that Fiber optic prices are doubled than DSL.\nWith the observed pattern above, we can create an important new feature, which we will refer to as ‘FO_LB’ (Fiber optic_Low benefit). I will assign a value of ‘1’ to indicate that the internet service is Fiber optic and the Totalbenefits taken are less than or equal to 3. For other cases, I will assign ‘0’.\n\n\nCode\ndf['FO_LB'] = df[['InternetService','TotalBenefits']].apply(\n    lambda x: 1 if (x['InternetService'] == 'Fiber optic') & (x['TotalBenefits'] &lt;= 3) else 0, axis=1)"
  },
  {
    "objectID": "posts/post-ketiga/index.html#modelling",
    "href": "posts/post-ketiga/index.html#modelling",
    "title": "Telco customer churn analysis",
    "section": "Modelling",
    "text": "Modelling\nOne important thing to address before we proceed is considering the types of errors to make this project as realistic as possible. Typically, there are two types of errors: false positive (FP) and false negative (FN). However, in this project, I will introduce three types of errors.\n1.FP: False positive  2.FN1: False negative for customers with MonthlyCharges below 95 USD  3.FN2: False negative for customers with MonthlyCharges above 95 USD (VIP customers)  Let’s agree on the misclassification ratio, which is FP:FN1:FN2 = 1:3:5 \nIt’s important to note that this dataset is imbalanced, meaning there is a significant difference in the number of samples between the classes.\nBased on these problems, we can set up our model’s parameters as follows: 1.Hyperparameter tuning. 2.Decision threshold tuning. 3.Oversampling data using SMOTE. 4.Applying weights to the models. I will be using Random Forest, XGBoost, and Logistic Regression.\nMetrics: Custom scoring based on sample misclassification. Precision. Recall. F1_score. Once the models are evaluated using these metrics, I will interpret the best model.\n\nFeature selection & encoding\n\n\nCode\ndf1 = df.copy()\n\n\n\n\nCode\ndf = df1.copy()\n\n\n\n\nCode\n#drop columns\ndf.drop(columns = ['Services','MonthlyChargesEstimationDifference','Status','PaperlessBilling','PaymentMethod'], inplace=True)\n\n\nI have dropped the columns from ‘Services’ to ‘Status’ as these columns were engineered features created for simpler exploratory data analysis (EDA). Additionally, I have also dropped the ‘PaperlessBilling’ and ‘PaymentMethod’ columns because, in the business context, these columns are considered irrelevant for determining customer churn since they represent optional ‘features’ for customers.\n\n\nCode\n#converting 'No internet service' to 'No' in benefit columns.\nKolomBenefit = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfor x in KolomBenefit:\n    df[x] = df[x].apply(lambda x: 'No' if x == 'No internet service' else x)\n\n\n\n\nCode\n#converting 'No phone service' to 'No'\ndf['MultipleLines'] = df[x].apply(lambda x: 'No' if x == 'No phone service' else x)\n\n\n\n\nCode\n#dict to mapping string to numerical.\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\n\n\n\n\nCode\n#binary encoding\nbinary = list(df.drop(columns=['tenure','InternetService','MonthlyCharges','TotalCharges','TotalBenefits','Contract','FO_LB']).columns)\n\nfor col in binary:\n    df[col] = df[col].map(value_mapping).astype('int64')\n\n\n\n\nCode\n#label encoding\ndf['Contract'] = df['Contract'].apply(lambda x: 1 if x == 'Month-to-month' else 2 if x == 'One year' else 3) \n\n\n\n\nCode\n#one hot encoding\ndf = pd.get_dummies(df, columns=['InternetService'])\n\n\n\n\nCode\n#feature selection\ndf = df[['Contract','tenure','InternetService_Fiber optic','MonthlyCharges','FO_LB','InternetService_No','Churn']]\ndf = df.rename(columns={\n                'InternetService_Fiber optic':'Fiber_optic',\n                'InternetService_No':'No_internet'})\n\n\nHere I only choose a feature that have a strong predictive power (by using feature of importances)\n\n\nSplits data and define custom function\n\n\nCode\n#split train-test\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Churn'), df.Churn.to_numpy(), test_size = 0.2, random_state=123)\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\n\n\n\nCode\n#custom function to do threshold tuning and custom metrics (used in GridSearchCV)\ndef my_scorer_2(clf, X, y_true, thres = np.arange(0.1,1,0.1)):\n    result_dict = {}\n    for threshold in np.atleast_1d(thres):\n        y_pred = (clf.predict_proba(X)[:,1] &gt; threshold).astype(int)\n        X_segment = (X['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\n        y_stack = np.column_stack((X_segment, y_pred, y_true))\n        y_stack_reg, y_stack_vip = y_stack[y_stack[:,0] == 0], y_stack[y_stack[:,0] == 1]\n        cm_reg = confusion_matrix(y_stack_reg[:,2], y_stack_reg[:,1])\n        cm_vip = confusion_matrix(y_stack_vip[:,2], y_stack_vip[:,1])\n        fn_reg, fn_vip = cm_reg[1][0], cm_vip[1][0]\n        fp = cm_reg[0][1] + cm_vip[0][1]\n        loss_score = (fp * 1) + (fn_reg * 3) + (fn_vip * 5)\n        result_dict[threshold] = np.array([loss_score, metrics.precision_score(y_true, y_pred, zero_division = 0), \n                                           metrics.recall_score(y_true, y_pred), metrics.f1_score(y_true, y_pred)])\n        \n    result_np = np.array([np.insert(value, 0, key) for key, value in result_dict.items()])\n    best_np = result_np[result_np[:,1] == np.min(result_np[:,1])][0]\n    return best_np\n\ndef my_scorer_threshold(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[0]\n\ndef my_scorer_ls(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[1]\n\ndef my_scorer_precision(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[2]\n\ndef my_scorer_recall(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[3]\n\ndef my_scorer_f1(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[4]\n        \n        \n\n\n\n\nCode\n#Grid scoring parameter\ngrid_scoring = {\n    'threshold': my_scorer_threshold,\n    'loss_score': my_scorer_ls,\n    'precision': my_scorer_precision,\n    'recall': my_scorer_recall,\n    'f1': my_scorer_f1\n}\n\n\n\n\nCode\n#define weight by missclassification cost which is FP:FN1:FN2 = 1:3:5\nX_segment = (X_train['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\narr_weight = np.column_stack((X_segment, y_train))\nweight = np.apply_along_axis(lambda x: 1 if x[1] == 0 else 5 if x[0] == 1 else 3 , axis=1, arr=arr_weight)\n\n\n\n\nModel building 1 / Hyperparameter tuning + threshold tuning\n\n\nCode\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train)\n\n#evaluate the model\nmb1_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb1_rf = np.append(mb1_rf, grid_result.iloc[0,0])\n\n\n\n\nCode\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb1_xg = np.append(mb1_xg, grid_result.iloc[0,0])\n\n\n\n\nCode\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb1_lg = np.append(mb1_lg, grid_result.iloc[0,0])\n\n\n\n\nCode\nresult_mb1 = pd.DataFrame([mb1_rf,mb1_xg,mb1_lg])\nresult_mb1.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb1['model'] = ['MB1_RF','MB1_XG','MB1_Log_Reg']\nresult_mb1\n\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n\n\n\n\n\n\n\nModel building 2 / Hyperparameter tuning + threshold tuning + SMOTE\n\n\nCode\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf_smote = {\n    'class__n_estimators': [250 , 400],\n    'class__max_depth': [10, 25, 50],\n    'class__min_samples_split': [25, 50, 70, 120],\n    'class__min_samples_leaf': [50, 75, 120],\n    'class__bootstrap' : [True, False]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinerf = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', RandomForestClassifier())])\n\n#run grid search cv\nrf = GridSearchCV(estimator = pipelinerf,\n                  param_grid = param_grid_rf_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nrf = RandomForestClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nrf = rf.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb2_rf = np.append(mb2_rf, params)\n\n\n\n\nCode\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg_smote = {\n    'class__learning_rate': [0.1, 0.01, 0.001],\n    'class__n_estimators': [100, 500],\n    'class__max_depth': [5, 10, 25],\n    'class__subsample': [0.8, 0.9, 1.0],\n    'class__colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinexg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', XGBClassifier())])\n\n#run grid search cv\nxg = GridSearchCV(estimator = pipelinexg,\n                  param_grid = param_grid_xg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nxg = XGBClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nxg = xg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb2_xg = np.append(mb2_xg, params)\n\n\n\n\nCode\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg_smote = {\n    'class__penalty': ['l1', 'l2'], \n    'class__C': [0.1, 1.0, 10.0],  \n    'class__solver': ['liblinear'],  \n    'class__max_iter': [50,100,200] \n}\n\n\n#create imbalanced pipeline to SMOTE \npipelinelg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', LogisticRegression())])\n\n#run grid search cv\nlg = GridSearchCV(estimator = pipelinelg,\n                  param_grid = param_grid_lg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nlg = LogisticRegression(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nlg = lg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb2_lg = np.append(mb2_lg, params)\n\n\n\n\nCode\nresult_mb2 = pd.DataFrame([mb2_rf,mb2_xg,mb2_lg])\nresult_mb2.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb2['model'] = ['MB2_RF','MB2_XG','MB2_Log_Reg']\nresult_mb2\n\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n\n\n\n\n\nYou see that the threshold on all models are increasing than model building 1 because SMOTE make the models learn more on the positive class.\n\n\nModel building 3 / Hyperparameter tuning + threshold tuning + custom weight\n\n\nCode\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb3_rf = np.append(mb3_rf, grid_result.iloc[0,0])\n\n\n\n\nCode\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb3_xg = np.append(mb3_xg, grid_result.iloc[0,0])\n\n\n\n\nCode\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb3_lg = np.append(mb3_lg, grid_result.iloc[0,0])\n\n\n\n\nCode\nresult_mb3 = pd.DataFrame([mb3_rf,mb3_xg,mb3_lg])\nresult_mb3.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb3['model'] = ['MB3_RF','MB3_XG','MB3_Log_Reg']\nresult_mb3\n\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\n\n\nCode\nfinal_result = pd.concat([result_mb1, result_mb2, result_mb3]).sort_values('score')\nfinal_result\n\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\nAnalysis of how the models performed: 1.RandomForest performs best with hyperparameter tuning and a lower decision threshold. However, this model performs worst when using SMOTE. 2.LogisticRegression performs worst when using ‘sample weighting’. 3.XGBoost performs best when using SMOTE. 4.It’s important to note that all models produce similar results when using their best parameters and conditions. 5.In my opinion, the greatest impact is achieved by using hyperparameter tuning and decision threshold tuning, rather than using SMOTE and weighting techniques."
  },
  {
    "objectID": "posts/post-ketiga/index.html#model-interpretation",
    "href": "posts/post-ketiga/index.html#model-interpretation",
    "title": "Telco customer churn analysis",
    "section": "Model Interpretation",
    "text": "Model Interpretation\nIn this section, I want to show you how to interpret a tree-based model, such as Random Forest, so we can have a better understanding of how the model actually works.\n\n\nCode\n#selecting the best parameter for random forest\nrf_param = final_result[final_result['model'] == 'MB1_RF']['params'][0]\nrf_param\n\n\n{'bootstrap': True,\n 'max_depth': 25,\n 'min_samples_leaf': 50,\n 'min_samples_split': 50,\n 'n_estimators': 250}\n\n\n\n\nCode\nrf = RandomForestClassifier(**rf_param)\nrf.fit(X_train, y_train)\n\n\nRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)\n\n\n\nPartial dependence plot (PDP) & Individual conditional expectation (ICE)\nWhat is ICE? It is a plot that shows how a model makes predictions based on changing the value of one or more features, while keeping the values of other features constant. This provides us with more insights and understanding of how the model treats features to make predictions. ICE works per row (or per customer in this case), and PDP is simply the average of ICE.\n\n\nCode\ndef pdp_ice_plot(model, df_test, column, clusters=True):\n    df_test = df_test.copy()\n    pdp_isolate = pdp.PDPIsolate(model = model, df = df_test, \n                      num_grid_points=15,\n                      model_features = df_test.columns, \n                      feature = column, feature_name=column)\n    pdp_isolate.plot(\n                center=True, plot_lines=True,\n                cluster=clusters, n_cluster_centers=5,cluster_method='accurate',\n                plot_pts_dist=False, to_bins=True,\n                show_percentile=False, which_classes=None,\n                figsize=(10,6), dpi=300,\n                ncols=2, plot_params={\"pdp_hl\": True},\n                engine='matplotlib', template='plotly_white')\n    plt.show()\n    \n\n\n\n\nCode\npdp_ice_plot(rf, X_test, 'MonthlyCharges', False)\n\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe light blue lines represent ICE (Individual Conditional Expectation), and the yellowish blue line represents PDP (Partial Dependence Plot). The X-axis represents MonthlyCharges, while the Y-axis represents the change in prediction probability. At MonthlyCharges of 60.7 USD, you can observe that some customers experience a significant increase in churn probability as the MonthlyCharges increase. However, it is important to note that not all customers have the same response. Some customers are minimally affected, and some may not be affected at all.\n\n\nCode\npdp_ice_plot(rf, X_test, 'MonthlyCharges')\n\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThis is the same plot as above, but I have grouped the ICE into 5 clusters for easier viewing and analysis. You can see that there are some customers who experience a significant increase in churn probability as the MonthlyCharges increase.\n\n\nCode\npdp_ice_plot(rf, X_test, 'tenure')\n\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe longer the tenure, the lower the churn probability. However, the effect is not the same for all customers. Some customers are greatly affected, while others are barely affected.\n\n\nCode\npdp_ice_plot(rf, X_test, 'Contract')\n\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\nThe same also goes with Contract. Longer contract means lower churn probability.\n\n\nCode\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=6,\n                              model_features = X_test.columns, \n                              features=['MonthlyCharges','tenure'], \n                              feature_names=['MonthlyCharges','tenure'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s analyze the combination of MonthlyCharges and tenure. We can observe a spike in churn probability for MonthlyCharges ranging from 56.3 USD to 79.2 USD, particularly for customers with a tenure of less than 7 months.\n\n\nCode\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=10,\n                              model_features = X_test.columns, \n                              features=['tenure','Contract'], \n                              feature_names=['tenure','Contract'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model produces similar churn probabilities for customers with a combination of a 2-year contract and low tenure compared to those with a month-to-month contract and medium tenure (24-36 months).\nYou can see how PDP and ICE plots can be very beneficial in understanding how the model utilizes features to make predictions. In the next section, I will demonstrate how to assess the model’s prediction confidence level.\n\n\nConfidence level based on trees’ standard deviation and confidence interval.\nTree-based models like RandomForest make predictions by using the mean of all the trees’ prediction probabilities. However, instead of solely relying on the mean, we can also calculate the standard deviation. A higher standard deviation indicates lower confidence in the predictions. Additionally, we can utilize confidence intervals, such as 95% or even more extreme at 99%.\n\n\nCode\n#extract all trees' prediction probability per row\npredict = np.stack([x.predict_proba(X_test)[:,1] for x in rf.estimators_])\n\n\n\n\nCode\n#assign mean and std. deviation of trees' prediction probability.\ndf_pred = X_test.copy()\ndf_pred['avg'] = np.round(np.mean(predict, axis = 0) * 100, 2)\ndf_pred['std_dev'] = np.round(np.std(predict, axis = 0) * 100, 2)\n\n\n\n\nCode\nplt.figure(figsize=(10,6))\nsns.histplot(df_pred['std_dev'],color='skyblue', kde=True, edgecolor='none')\nplt.title('Standard deviation distribution', weight='bold')\nplt.show()\n\n\n\n\n\nMost of predictions have std.deviation under 10%. Let’s calculate confidence interval with 99%.\n\n\nCode\ndf_pred['CI-99%'] = (2.576 * df_pred['std_dev'] / np.sqrt(len(predict))) * 100 / (df_pred['avg'])\n\n\n\n\nCode\ndf_pred[df_pred.avg &gt; 40].sort_values('CI-99%', ascending=False).head(5)\n\n\n\n\n\n\n\n\n\nContract\ntenure\nFiber_optic\nMonthlyCharges\nFO_LB\nNo_internet\navg\nstd_dev\nCI-99%\n\n\n\n\n852\n2\n7\n1\n94.05\n1\n0\n40.06\n25.08\n10.199818\n\n\n499\n1\n58\n1\n98.70\n1\n0\n41.05\n18.24\n7.239149\n\n\n1186\n1\n59\n1\n101.10\n1\n0\n40.37\n16.73\n6.751699\n\n\n1137\n1\n15\n1\n96.30\n0\n0\n48.14\n19.69\n6.663701\n\n\n1184\n1\n10\n1\n92.50\n0\n0\n48.17\n19.12\n6.466765\n\n\n\n\n\n\n\nLet’s consider the example of row 1. The model predicts a 40% probability of churn for the customer, with a confidence interval of +- 10%. By default, the model’s output indicates that the customer will not churn. However, due to the high confidence interval, it is safer to assume that the customer will churn.\nChecking the standard deviation and confidence interval of the trees is extremely useful, particularly when the cost of ‘False Negative’ is significant and can have severe consequences."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vertikal Willis",
    "section": "",
    "text": "Hi! Welcome to my blog!\n\n\n\n\n\nEverything you need to know about me.\n\n\nABOUT\n\n\n\n\n\n\n\n\nAll of my data science projects and portfolios.\n\n\nPORTFOLIOS\n\n\n\n\n\n\n\n\nTutorials about things related to data science and data analysis (coming soon).\n\n\nTUTORIALS"
  },
  {
    "objectID": "ipynb/final-project-original.html",
    "href": "ipynb/final-project-original.html",
    "title": "Table Of Contents",
    "section": "",
    "text": "• Introduction  • Data Introduction  • Data Preparation (Import libraries, data cleaning & data wrangling) • Basic exploratory data analysis      * Descriptive statistic      * Univariate analysis      * Multivariate analysis  • Deep exploratory data analysis      * Services and internet services analysis      * Monthly charges analysis      * Customer analysis      * Benefits analysis      * Churn analysis  • Modelling     * Features selection and encoding      * Splits data and define custom metrics      * Model building combination 1      * Model building combination 2      * Model building combination 3 \n• Model interpretation     * PDP and ICE plots      * Checking prediction’s confidence using confidence interval"
  },
  {
    "objectID": "ipynb/final-project-original.html#data-preparation-import-libraries-data-cleaning-data-wrangling",
    "href": "ipynb/final-project-original.html#data-preparation-import-libraries-data-cleaning-data-wrangling",
    "title": "Table Of Contents",
    "section": "Data Preparation (Import libraries, data cleaning & data wrangling)",
    "text": "Data Preparation (Import libraries, data cleaning & data wrangling)\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import gaussian_kde\nimport matplotlib as mpl\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nfrom pdpbox import pdp, info_plots\nmpl.rcParams['figure.dpi'] = 300 #set figure dpi\nsns.set() #set figure styling\n\n\n#dataset link\ngithub = 'https://raw.githubusercontent.com/vertikalwil/Data-Analyst/main/telco.csv'\n\n\n#import dataset\ndf = pd.read_csv('telco.csv')\ndf.head()\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\nHobby\n\n\n\n\n0\n7590-VHVEG\nFemale\n0\nYes\nNo\n135\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n29.85\n29.85\nNo\nSwimming\n\n\n1\n5575-GNVDE\nMale\n0\nNo\nNo\n34\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nOne year\nNo\nMailed check\n56.95\n1889.5\nNo\nRunning\n\n\n2\n3668-QPYBK\nMale\n0\nNo\nNo\n140\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nMailed check\n53.85\n7560\nYes\nHiking\n\n\n3\n7795-CFOCW\nMale\n0\nNo\nNo\n136\nNo\nNo phone service\nDSL\nYes\n...\nYes\nNo\nNo\nOne year\nNo\nBank transfer (automatic)\n42.45\n1840.75\nNo\nSwimming\n\n\n4\n9237-HQITU\nFemale\n0\nNo\nNo\n2\nYes\nNo\nFiber optic\nNo\n...\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n70.70\n151.65\nYes\nRunning\n\n\n\n\n5 rows × 22 columns\n\n\n\n\n#take a look at the dataframe\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 7043 entries, 0 to 7042\nData columns (total 22 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   customerID        7043 non-null   object \n 1   gender            7043 non-null   object \n 2   SeniorCitizen     7043 non-null   int64  \n 3   Partner           7043 non-null   object \n 4   Dependents        7043 non-null   object \n 5   tenure            7043 non-null   int64  \n 6   PhoneService      7043 non-null   object \n 7   MultipleLines     7043 non-null   object \n 8   InternetService   7043 non-null   object \n 9   OnlineSecurity    7043 non-null   object \n 10  OnlineBackup      7043 non-null   object \n 11  DeviceProtection  6627 non-null   object \n 12  TechSupport       7043 non-null   object \n 13  StreamingTV       7043 non-null   object \n 14  StreamingMovies   7043 non-null   object \n 15  Contract          6798 non-null   object \n 16  PaperlessBilling  7043 non-null   object \n 17  PaymentMethod     7043 non-null   object \n 18  MonthlyCharges    7043 non-null   float64\n 19  TotalCharges      4859 non-null   object \n 20  Churn             7043 non-null   object \n 21  Hobby             4201 non-null   object \ndtypes: float64(1), int64(2), object(19)\nmemory usage: 1.2+ MB\n\n\n\nThere are 4 columns with missing values which are DeviceProtection, Contract, TotalCharges and Hobby.\n\n\n#checking percentage of missing values\nmissingkolom = ['DeviceProtection','Contract','TotalCharges','Hobby']\nfor x in missingkolom:\n    print(f'Missing value of column {x} (%) : {round(df[x].isna().sum()/len(df) * 100,2)}')\n\nMissing value of column DeviceProtection (%) : 5.91\nMissing value of column Contract (%) : 3.48\nMissing value of column TotalCharges (%) : 31.01\nMissing value of column Hobby (%) : 40.35\n\n\n\n#impute missing values with univariate imputation by value proportion\ndf['DeviceProtection'] = df['DeviceProtection'].fillna(\n                             pd.Series(np.random.choice(['No','Yes','No internet service'], \n                             p = list(df['DeviceProtection'].value_counts(normalize=True)), size=len(df))))\n\ndf['Contract'] = df['Contract'].fillna(\n                     pd.Series(np.random.choice(['Month-to-month','Two year','One year'], \n                     p = list(df['Contract'].value_counts(normalize=True)), size=len(df))))\n\n\nHere I impute DeviceProtection and Contract with univariate imputation by value proportion for the following reasons: 1.The missing values is not that much (&lt;10%). 2.The columns don’t have any relationship with other columns so that multivariate imputation is not possible. 3.Using proportion is more precise in this case rather than use ‘mode’.\n\n\n#delete column Hobby\ndf.drop(columns=['Hobby'],inplace=True)\n\n\nReasons to delete: 1.Missing values is too many. 2.By business context, Hobby doesn’t give enough useful informations. 3.Cannot be imputed by multivariate imputation.\n\n\n#impute TotalCharges from tenure and MonthlyCharges\ndf['TotalCharges'] = df['TotalCharges'].fillna(df['tenure'] * df['MonthlyCharges'])\n\n\nEven this column has so many missing values, I decided to impute it with multivariate imputation because: 1.By business context, TotalCharges is more or less tenure * MonthlyCharges. 2.So even the missing values are high, it can still be imputed with a strong justification.\n\n\n#there's a space in the total charges column.\nfor x in df.TotalCharges:\n    try:\n        float(x)\n    except:\n        print(f'Unable to convert to float with this value : {x}')\n\nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \nUnable to convert to float with this value :  \n\n\n\ndf[df.TotalCharges == ' '].head()\n\n\n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\n\n\n\n\n488\n4472-LVYGI\nFemale\n0\nYes\nYes\n0\nNo\nNo phone service\nDSL\nYes\n...\nYes\nYes\nYes\nNo\nMonth-to-month\nYes\nBank transfer (automatic)\n52.55\n\nNo\n\n\n753\n3115-CZMZD\nMale\n0\nNo\nYes\n0\nYes\nNo\nNo\nNo internet service\n...\nNo internet service\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n20.25\n\nNo\n\n\n936\n5709-LVOEQ\nFemale\n0\nYes\nYes\n0\nYes\nNo\nDSL\nYes\n...\nNo\nNo\nYes\nYes\nTwo year\nNo\nMailed check\n80.85\n\nNo\n\n\n1082\n4367-NUYAO\nMale\n0\nYes\nYes\n0\nYes\nYes\nNo\nNo internet service\n...\nYes\nNo internet service\nNo internet service\nNo internet service\nTwo year\nNo\nMailed check\n25.75\n\nNo\n\n\n1334\n1768-ZAIFU\nFemale\n1\nNo\nNo\n0\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n25.20\n\nYes\n\n\n\n\n5 rows × 21 columns\n\n\n\n\nWhen the tenure value is 0, the TotalCharges value is empty (‘space’). This is because customers who have just joined (less than a month) have not been charged yet, resulting in a TotalCharges value of 0. Since there are only 12 rows with this condition, I will delete them.\n\n\n#drop rows that has empty TotalCharges.\ndf = df.drop(df.index[df.TotalCharges == ' ']).reset_index(drop=True)\n\n\n#check for duplicate data, if True then there's no duplicate.\ndf.customerID.nunique() == len(df) \n\nTrue\n\n\n\n#feature engineered 2 new features for the sake of easier analysis.\ndf['Services'] = df[['PhoneService','InternetService']].apply(\n                     lambda x: 'Both' if list(x).count('No') == 0 else\n                     'Internet Only' if x[0] == 'No' else 'Phone Only', axis=1)\n\ndf['TotalBenefits'] = df.loc[:,'OnlineSecurity':'StreamingMovies']\\\n                          .apply(lambda x: list(x).count('Yes'), axis=1)\n\n\nNew features explanation:  1.Services = Combined values of PhoneService and InternetService. 2.TotalBenefits = Sum of benefits taken on OnlineSecurity until StreamingMovies.\n\n\n#Change values of 1 and 0 to 'Yes' and 'No'\ndf['SeniorCitizen'] = df.SeniorCitizen.apply(lambda x: 'Yes' if x == 1 else 'No')\n\n\nChange numerical value to strings for simpler and consistent analysis.\n\n\n#drop useless column\ndf.drop(columns=['customerID'], inplace=True)\n\n\n#change columns object data type to numerical\ndf.tenure = df.tenure.astype('int64')\ndf.MonthlyCharges = df.MonthlyCharges.astype('float64')\ndf.TotalCharges = df.TotalCharges.astype('float64')\n\n\n#checking values of real totalcharges and calculated totalcharges\ndf['TotalChargesDiff'] = df[['tenure','MonthlyCharges','TotalCharges']].apply(\n                             lambda x: round(abs(1 - (x[0] * x[1] / x[2])) * 100, 3), axis=1)\n\n\nHere, I have created a new column called TotalChargesDiff to check the differences (%) between the actual TotalCharges value (from the dataset) and the calculated TotalCharges value (obtained by multiplying tenure with MonthlyCharges). If the difference is above 40%, I will consider those rows as invalid because the values of tenure and MonthlyCharges cannot be trusted.\n\n\ndf['TotalChargesDiff'].sort_values(ascending=False).head(10)\n\n0       13400.000\n5        1357.404\n18        788.048\n19        330.214\n3         213.633\n128        73.511\n47         72.615\n4631       64.286\n5802       63.380\n20         58.263\nName: TotalChargesDiff, dtype: float64\n\n\n\nYou can observe that some data points have a TotalChargesDiff that reaches hundreds or even thousands.\n\n\n#removing rows that have &gt; 40% TotalChargesDiff.\ndf = df[df.TotalChargesDiff &lt; 40].reset_index(drop=True)\ndf.drop(columns=['TotalChargesDiff'], inplace=True)\n\n\ndef numericategoric(df):\n    num = len(df._get_numeric_data().columns)\n    cat = len(df.columns) - num\n    print(\"TotalNumericalData = \" + str(num))\n    print(\"TotalCategoricalData = \" + str(cat))\n    print(\"Numerical = \" + str(list(df._get_numeric_data().columns )))\n    print(\"Categorical = \" + str(list(df.drop(df._get_numeric_data().columns, axis=1).columns)))\n\n\nnumericategoric(df)\n\nTotalNumericalData = 4\nTotalCategoricalData = 18\nNumerical = ['tenure', 'MonthlyCharges', 'TotalCharges', 'TotalBenefits']\nCategorical = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn', 'Services']\n\n\n\nShow numerical and categorical columns\n\n\n#assign categorical and numerical columns on different dataframe for easier analysis.\ndfnum = df._get_numeric_data()\ndfcat = df.drop(columns = dfnum.columns)"
  },
  {
    "objectID": "ipynb/final-project-original.html#basic-exploratory-data-analysis.",
    "href": "ipynb/final-project-original.html#basic-exploratory-data-analysis.",
    "title": "Table Of Contents",
    "section": "Basic Exploratory Data Analysis.",
    "text": "Basic Exploratory Data Analysis.\n\n\nDescriptive Statistics\n\n#numerical columns describe.\ndfnum.describe()\n\n\n\n\n\n\n\n\ntenure\nMonthlyCharges\nTotalCharges\nTotalBenefits\n\n\n\n\ncount\n7012.000000\n7012.000000\n7012.000000\n7012.000000\n\n\nmean\n32.506560\n64.732760\n2286.410207\n2.041358\n\n\nstd\n24.564234\n30.109753\n2265.759401\n1.835792\n\n\nmin\n1.000000\n12.000000\n13.500000\n0.000000\n\n\n25%\n9.000000\n35.450000\n402.437500\n0.000000\n\n\n50%\n29.000000\n70.300000\n1397.250000\n2.000000\n\n\n75%\n56.000000\n89.850000\n3784.125000\n3.000000\n\n\nmax\n140.000000\n118.750000\n8684.800000\n6.000000\n\n\n\n\n\n\n\n\n1.All columns seems to have a normal min-max values. Nothing weird here. 2.Average tenure is about 30 months which is pretty low. 3.Average MonthlyCharge is about 65-70 USD which is pretty good. 4.Out of 6 benefits available, the average taken by customer is around 2, which is pretty low.\n\n\ndfcat.describe()\n\n\n\n\n\n\n\n\ngender\nSeniorCitizen\nPartner\nDependents\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\nOnlineBackup\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nChurn\nServices\n\n\n\n\ncount\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n7012\n\n\nunique\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n2\n4\n2\n3\n\n\ntop\nMale\nNo\nNo\nNo\nYes\nNo\nFiber optic\nNo\nNo\nNo\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\nNo\nBoth\n\n\nfreq\n3542\n5874\n3624\n4920\n6336\n3372\n3087\n3486\n3075\n3072\n3459\n2798\n2769\n3851\n4155\n2354\n5155\n4821\n\n\n\n\n\n\n\n\n1.Male and Female has the same proportion. 2.Most of customers is non SeniorCitizen with no Partner and No Dependents. 3.Favorite InternetService is Fiber optic. 4.Majority of customers is subscribed with ‘Month-to-month’ Contract. 5.5155 out of 7012 is non-Churn customers which make this dataset is imbalanced. 6.All these columns have low cardiality values.\n\n\nfor col in dfcat.columns:\n    print(f'Value counts for column {col}:')\n    print(df[col].value_counts())\n    print('---'*10)\n    print('\\n')\n\nValue counts for column gender:\nMale      3542\nFemale    3470\nName: gender, dtype: int64\n------------------------------\n\n\nValue counts for column SeniorCitizen:\nNo     5874\nYes    1138\nName: SeniorCitizen, dtype: int64\n------------------------------\n\n\nValue counts for column Partner:\nNo     3624\nYes    3388\nName: Partner, dtype: int64\n------------------------------\n\n\nValue counts for column Dependents:\nNo     4920\nYes    2092\nName: Dependents, dtype: int64\n------------------------------\n\n\nValue counts for column PhoneService:\nYes    6336\nNo      676\nName: PhoneService, dtype: int64\n------------------------------\n\n\nValue counts for column MultipleLines:\nNo                  3372\nYes                 2964\nNo phone service     676\nName: MultipleLines, dtype: int64\n------------------------------\n\n\nValue counts for column InternetService:\nFiber optic    3087\nDSL            2410\nNo             1515\nName: InternetService, dtype: int64\n------------------------------\n\n\nValue counts for column OnlineSecurity:\nNo                     3486\nYes                    2011\nNo internet service    1515\nName: OnlineSecurity, dtype: int64\n------------------------------\n\n\nValue counts for column OnlineBackup:\nNo                     3075\nYes                    2422\nNo internet service    1515\nName: OnlineBackup, dtype: int64\n------------------------------\n\n\nValue counts for column DeviceProtection:\nNo                     3072\nYes                    2416\nNo internet service    1524\nName: DeviceProtection, dtype: int64\n------------------------------\n\n\nValue counts for column TechSupport:\nNo                     3459\nYes                    2038\nNo internet service    1515\nName: TechSupport, dtype: int64\n------------------------------\n\n\nValue counts for column StreamingTV:\nNo                     2798\nYes                    2699\nNo internet service    1515\nName: StreamingTV, dtype: int64\n------------------------------\n\n\nValue counts for column StreamingMovies:\nNo                     2769\nYes                    2728\nNo internet service    1515\nName: StreamingMovies, dtype: int64\n------------------------------\n\n\nValue counts for column Contract:\nMonth-to-month    3851\nTwo year          1697\nOne year          1464\nName: Contract, dtype: int64\n------------------------------\n\n\nValue counts for column PaperlessBilling:\nYes    4155\nNo     2857\nName: PaperlessBilling, dtype: int64\n------------------------------\n\n\nValue counts for column PaymentMethod:\nElectronic check             2354\nMailed check                 1599\nBank transfer (automatic)    1539\nCredit card (automatic)      1520\nName: PaymentMethod, dtype: int64\n------------------------------\n\n\nValue counts for column Churn:\nNo     5155\nYes    1857\nName: Churn, dtype: int64\n------------------------------\n\n\nValue counts for column Services:\nBoth             4821\nPhone Only       1515\nInternet Only     676\nName: Services, dtype: int64\n------------------------------\n\n\n\n\n\nShow all value counts for each categorical columns.\n\n\n\nUnivariate Analysis\n\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    axarr[dfnum.columns.get_loc(x)].boxplot(df[x],patch_artist=True)\n    axarr[dfnum.columns.get_loc(x)].set_xlabel(x)\nplt.suptitle('Outliers checking on numeric columns')\nfig.tight_layout(pad=1)\nplt.show()\n\n\n\n\n\nWill drop outlier in tenure.\n\n\n#drop outlier in tenure\ndf = df[df.tenure &lt; 125]\n\n\n#plot distribution for numerical columns\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=dfnum[x], \n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)])\nplt.suptitle('Distribution plot', weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\n\nAbove plots are distribution plots on all numerical columns. 1.tenure and MonthlyCharges have a ‘U-shaped’ distribution. 2.TotalCharges has a positive-skew distribution.\n\n\n#count plot for categorical columns\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(x=df[features[i-1]], color='green')\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\n\nHere I count plotted all categorical columns.\n\n\n\nMultivariate Analysis\n\n#count plots against 'churn'\nplt.figure(figsize=(15,12))\n\nfeatures = dfcat.columns\nfor i in np.arange(1, len(features)+1):\n    plt.subplot(5, len(features)//3 - 2, i)\n    sns.countplot(data=df, x=df[features[i-1]], hue='Churn')\n    plt.legend(prop={'size': 8})\n    plt.xticks(rotation=10)\n    plt.xlabel(features[i-1])\nplt.suptitle('CountPlot vs Churned', size=19, weight='bold')\nplt.tight_layout(pad = 1)\n\n\n\n\n\nI added Churn count into the categorical plots. 1.You can see for column Gender, the values and Churn count is pretty equal which make this column will have a very low predictive power. 2.For InternetService, fiber optic has way higher in churn probability compare to DSL. 3.Same ways also applied on Month-to-month Contract and Electronic-check PaymentMethod.\n\n\n#distribution plots against 'churn'\nfig, axarr = plt.subplots(1,4, figsize=(10, 4))\nfor x in dfnum.columns:\n    sns.histplot(data=df, \n                 x = dfnum[x],\n                 color='skyblue', \n                 kde=True, \n                 edgecolor='none', \n                 ax=axarr[dfnum.columns.get_loc(x)], \n                 hue='Churn')\n    \nplt.suptitle(\"Distribution plot\", weight='bold')\nfig.tight_layout(pad=1)\n\n\n\n\n\nLet’s also compare Churn distribution on numerical columns. Customers tend to churn when the tenure is low and not churn when the MonthlyCharges is very low. I will do further analysis about these columns later.\n\n\n#change binary column into numerical\ndfcorr = df.copy()\nbinary = ['gender','SeniorCitizen','Partner','Dependents','PhoneService','PaperlessBilling','Churn']\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\n\nfor col in binary:\n    dfcorr[col] = dfcorr[col].map(value_mapping).astype('int64')\n\n\nplt.figure(figsize=(10,8))\nsns.heatmap(dfcorr.corr(), annot=True, fmt='.2f')\nplt.show()\n\n\n\n\n\nCorrelation! 1.TotalCharges and tenure have a high positive correlation (causation : the longer the customers subscribed, the more they paid). 2.TotalBenefits also has a strong correlation with MonthlyCharges and TotalCharges (causation : more benefits taken also make the MonthlyCharges higher). Note : Correlation doesn’t indicate causation. Understanding the specific context, industry knowledge, and conducting further analysis or experiments can help determine if there is a causal relationship between the variables or if other factors are influencing the observed correlations."
  },
  {
    "objectID": "ipynb/final-project-original.html#deep-dive-exploratory-data-analysis",
    "href": "ipynb/final-project-original.html#deep-dive-exploratory-data-analysis",
    "title": "Table Of Contents",
    "section": "Deep-Dive Exploratory Data Analysis",
    "text": "Deep-Dive Exploratory Data Analysis\n\n\n#create a function to plot churn probability for numerical columns.\ndef prob_plot(df,colom,x):\n    means = df[colom].mean()\n    medians = df[colom].median()\n    data = df[df.Churn == 'Yes'][colom].astype('float64')\n    data1 = df[df.Churn == 'No'][colom].astype('float64')\n    \n    kde = gaussian_kde(data)\n    kde1 = gaussian_kde(data1)\n    dist_space = np.linspace( min(data), max(data), 200)\n    dist_space1 = np.linspace( min(data1), max(data1), 200)\n    axarr[x].plot( dist_space, kde(dist_space), label='Churned', color='orange' )\n    axarr[x].plot( dist_space1, kde1(dist_space1), label='Not churn', color='blue')\n    axarr[x].axvline(x = means, linestyle = '--', color='g', label='Mean')\n    axarr[x].axvline(x = medians, linestyle = '--', color='r', label='Median')\n    axarr[x].set_title('Probability', fontweight='bold', size=12)\n    axarr[x].set(ylabel = 'Probability', xlabel = colom)\n    axarr[x].legend()\n\n\nServices & InternetService analysis\n\n#count plot for Services.\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(data=df[df.Services == 'Both'], \n              x='InternetService', \n              ax=axarr[0])\n\nsns.countplot(data=df[df.Services == 'Internet Only'], \n              x='InternetService', \n              ax=axarr[1])\n\naxarr[0].set_title(\"Both phone service & internet service\", weight='bold')\naxarr[1].set_title(\"Internet service only\", weight='bold')\n\nplt.suptitle(\"Comparison of internet services on product services\")\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\n\nIt is observed that customers tend to prefer Fiber optic over DSL for ‘phone & internet service’. However, when considering ‘internet service only’ without phone, there is no option for Fiber optic available. This suggests that in order to utilize Fiber optic, a phone connection (or phone service) is required.\n\n\n#plot churn probability for 'services' & 'internet services'\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\n\ndf.groupby('Services')['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(list(x)))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[0])\n\ndf[df.Services != 'Phone Only'].groupby(['InternetService'])['Churn'].agg(lambda x: list(x).count('Yes') * 100 / len(x))\\\n                               .plot(kind='bar', width=0.3,rot=True, ax=axarr[1])\n\naxarr[0].set_title('Services churn probability', weight='bold')\naxarr[1].set_title('Internet service churn probability', weight='bold')\n\nplt.tight_layout(pad=1)\nplt.show()\n\n\n\n\n\nCustomers that used ‘Both’ services and InternetService fiber optic tends to churn more.\n\n\n\nMonthlyCharges analysis\n\n#checking InternetService price.\ndf_filtered = df[(df.Services == 'Both') & (df.TotalBenefits == 0) & (df.MultipleLines == 'No')].copy()\ndf_filtered.groupby('InternetService')['MonthlyCharges'].mean()\n\nInternetService\nDSL            44.963824\nFiber optic    70.083186\nName: MonthlyCharges, dtype: float64\n\n\n\nThe price of Fiber optic is higher, around 25 USD, compared to DSL. However, it’s important to keep in mind that these prices include a phone service with a single line.\n\n\ndf_filtered = df[(df.Services == 'Phone Only') & (df.TotalBenefits == 0)].copy()\ndf_filtered.groupby('MultipleLines')['MonthlyCharges'].mean()\n\nMultipleLines\nNo     19.953819\nYes    24.973716\nName: MonthlyCharges, dtype: float64\n\n\n\nplt.figure(figsize=(10,5))\nsns.histplot(data=df_filtered, \n             x='MonthlyCharges', \n             hue='MultipleLines', \n             multiple='stack')\n\nplt.title('Phone service distribution', weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nWe can see that the price for a ‘phone service’ with a single line is around 20 USD, while the price for a ‘phone service’ with multiple lines is around 25 USD. This also means that the price for DSL is around 25 USD, while the price for Fiber optic is around 50 USD, which is twice as much as DSL.\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nmc_dist = sns.histplot(data=df, \n                       x = 'MonthlyCharges',\n                       hue='Churn', \n                       ax=axarr[0], \n                       multiple='stack')\n\naxarr[0].set_title('Distribution', fontweight='bold', size=12)\n\nprob_plot(df,'MonthlyCharges',1)\naxarr[1].legend(loc='upper right')\nplt.show()\n\n\n\n\n\nAt a MonthlyCharges range of approximately +- 20 USD, the ratio of non-churn customers is very high. It is known that products within this price range are typically ‘phone service only’. However, between the price range of 60 - 100 USD, the churn probability increases significantly. I am planning to conduct further analysis specifically for customers within this price range.\n\n\ndf_filtered = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both') & (df.MultipleLines == 'No')]\ndf_agg = df_filtered.groupby('TotalBenefits')['MonthlyCharges'].agg('mean').reset_index()\ndf_agg['MonthlyCharges'] = df_agg.MonthlyCharges.round()\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.scatterplot(data=df_filtered, \n                x='MonthlyCharges', \n                y='TotalBenefits', \n                s=35, \n                ax=axarr[0])\n\nsns.barplot(df_agg, x = 'TotalBenefits', y = 'MonthlyCharges')\naxarr[0].set_title('MonthlyCharges vs Totalbenefits', weight='bold')\naxarr[1].set_title('Average MonthlyCharges vs Totalbenefits', weight='bold')\nfig.tight_layout(pad = 1)\nplt.show()\n\n\n\n\n\nHere, you can observe that as more TotalBenefits are taken, the MonthlyCharges also increase. On the left plot, you can see that there are 5 outlier data points, which will be removed later.\n\n\ndf_fil = df[(df.InternetService == 'Fiber optic') & (df.Services == 'Both')\\\n              & (df.MultipleLines == 'No') & (df.TotalBenefits == 1)]\n\nbenefits = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\ndf_benefit = pd.DataFrame()\nfor x in benefits:\n    df_value = pd.DataFrame([x, \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].min(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].max(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].mean(), \n                      df_fil[df_fil[x] == 'Yes']['MonthlyCharges'].median()\n                     ]).transpose()\n    \n    df_benefit = pd.concat([df_benefit, df_value])\ndf_benefit.columns = ['Benefit','MinCharges','MaxCharges','MeanCharges','MedianCharges']    \n\n\ndf_benefit\n\n\n\n\n\n\n\n\nBenefit\nMinCharges\nMaxCharges\nMeanCharges\nMedianCharges\n\n\n\n\n0\nOnlineSecurity\n73.2\n80.3\n74.952857\n75.0\n\n\n0\nOnlineBackup\n72.75\n76.65\n74.708511\n74.65\n\n\n0\nDeviceProtection\n69.55\n76.65\n74.258889\n74.8\n\n\n0\nTechSupport\n73.85\n76.55\n75.045455\n74.7\n\n\n0\nStreamingTV\n77.65\n81.9\n79.746825\n79.75\n\n\n0\nStreamingMovies\n12.0\n86.45\n79.16746\n80.0\n\n\n\n\n\n\n\n\nAbove are the prices of benefits with Fiber optic and a single line phone connection. You can see that StreamingTV and StreamingMovies are more expensive compared to other benefits, approximately +- 5 USD.\n\nNow that we know the prices of every product, here’s a recap:\nDSL = approximately 25 USD. Fiber optic = approximately 50 USD. Phone service (single line) = approximately 20 USD. Phone service (multiple lines) = approximately 25 USD. OnlineSecurity - TechSupport = approximately 5 USD. StreamingTV - StreamingMovies = approximately 10 USD.\nWith this data, we can perform a simple ‘anomaly detection’ by manually calculating the MonthlyCharges and comparing them with the actual MonthlyCharges, similar to how we calculated the TotalChargesDiff above.\n\n#checking for MonthlyCharges values with the calculated one (similar with checking TotalCharges difference).\ndef MonthlyChargesDiff(x):\n    estimation = 0\n    if x['PhoneService'] == 'Yes':\n        estimation += 20\n    if x['MultipleLines'] == 'Yes':\n        estimation += 5\n    if x['InternetService'] == 'DSL':\n        estimation += 25\n    if x['InternetService'] == 'Fiber optic':\n        estimation += 50\n        \n    if (x['StreamingTV'] == 'Yes') & (x['StreamingMovies'] == 'Yes'):\n        estimation += 20 + (x['TotalBenefits'] - 2) * 5\n    elif (x['StreamingTV'] == 'Yes') | (x['StreamingMovies'] == 'Yes'):\n        estimation += 10 + (x['TotalBenefits'] - 1) * 5\n    else:\n        estimation += x['TotalBenefits'] * 5\n        \n    return abs(1 - (estimation / x['MonthlyCharges'])) * 100\n    \n   \n\n\ndf['MonthlyChargesEstimationDifference'] = df.apply(MonthlyChargesDiff, axis=1)\n\n\ndf[df.MonthlyChargesEstimationDifference &gt; 40][['MonthlyCharges','MonthlyChargesEstimationDifference']]\n\n\n\n\n\n\n\n\nMonthlyCharges\nMonthlyChargesEstimationDifference\n\n\n\n\n12\n29.00\n296.551724\n\n\n389\n12.00\n733.333333\n\n\n666\n12.00\n566.666667\n\n\n859\n26.41\n278.644453\n\n\n1439\n18.26\n447.645126\n\n\n2185\n21.63\n362.320851\n\n\n4090\n31.26\n219.897633\n\n\n5848\n15.00\n466.666667\n\n\n6718\n21.00\n304.761905\n\n\n\n\n\n\n\n\nYou can see that there are 9 rows with extreme MonthlyCharges values. These are considered as ‘anomalies’, so let’s remove them.\n\n\n#remove MonthlyCharges extreme values.\ndf = df[df.MonthlyChargesEstimationDifference &lt; 40].reset_index(drop=True)\n\n\n\nCustomer analysis\n\n#creating a function to engineered a new feature.\ndef statuss(x):\n    x = list(x)\n    if (x[0] == 'Yes') & (x[1] == 'Yes'):\n        return 'Both'\n    elif (x[0] == 'Yes') & (x[1] == 'No'):\n        return 'Partner Only'\n    elif (x[0] == 'No') & (x[1] == 'Yes'):\n        return 'Dependent Only'\n    else:\n        return 'Single'\n\n\ndf['Status'] = df[['Partner','Dependents']].apply(statuss, axis=1)\n\n\nI have created a new feature called ‘Status’. This feature is derived from the columns Partner and Dependents. 1.If customers have both Partner and Dependents, it will be labeled as ‘Both’. 2.If customers have Partner but no Dependents, it will be labeled as ‘Partner Only’. 3.If customers have Dependents but no Partner, it will be labeled as ‘Dependent Only’. 4.If customers have neither Partner nor Dependents, it will be labeled as ‘Single’.\n\n\nplt.figure(figsize=(10,5))\nsns.countplot(df.sort_values('Status', ascending=True), x='Status')\nplt.title('Status Count', size=16, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nMajority of customers are Single.\n\n\nfig, axarr = plt.subplots(1,3, figsize=(15, 6))\nk = ['tenure','MonthlyCharges','TotalBenefits']\nfor x in k:\n    sns.barplot(data=df.groupby(['Status'])[[x]].mean().reset_index(), \n                x='Status', \n                y=x, \n                ax=axarr[k.index(x)],\n                palette=['grey', 'g','m','b'])\n    \n    axarr[k.index(x)].set_title(f'{x} average', weight='bold', size=15)\n    \nfig.tight_layout()\nplt.show()\n\n\n\n\n\nCustomers labeled as ‘Partner Only’ are considered the best since they have the longest tenure and the highest MonthlyCharges. The second-best group is ‘Both’, although these customers may not have MonthlyCharges as high as those in the ‘Single’ group, their tenure is almost double that of the ‘Single’ group.\n\n\nplt.figure(figsize=(10,5))\nsns.barplot(data=df.groupby('Status')[['Churn']].agg(lambda x: list(x).count('Yes') / len(x)).reset_index(), \n            x='Status', \n            y='Churn')\n\nplt.title('Churn Probability', weight='bold', size=16)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nSingle customers have the highest churn probability.\n\n\ndf.SeniorCitizen.value_counts(normalize=True)\n\nNo     0.837903\nYes    0.162097\nName: SeniorCitizen, dtype: float64\n\n\n\nThe majority of customers are young people.\n\n\ndf_status = df.groupby('SeniorCitizen')[['Status']]\ndf_status = df_status.agg(Single = ('Status', lambda x: list(x).count('Single') * 100 / len(x)), \n                          PartnerOnly = ('Status', lambda x: list(x).count('Partner Only') * 100  / len(x)), \n                          Both = ('Status', lambda x: list(x).count('Both') * 100  / len(x)), \n                          DependentOnly = ('Status', lambda x: list(x).count('Dependent Only') * 100  / len(x)))\ndf_status = df_status.reset_index().melt(id_vars='SeniorCitizen')\ndf_status = df_status.rename(columns={'variable':'Status'})\n\n\nplt.figure(figsize=(10,5))\n\nsns.barplot(data=df_status, \n            x ='SeniorCitizen', \n            y='value', \n            hue='Status')\n\nplt.title(\"Status comparison between senior citizen\", size=15, weight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nFor non-Senior citizens, ‘Single’ customers have the highest frequency, followed by ‘Both’. For Senior citizens, ‘Single’ is also the highest category, but the difference with ‘PartnerOnly’ is not as significant. From the plots above, we can also conclude that young people tend to have dependents more than older people.\n\n\ndf_status = df.groupby('Status')[['OnlineSecurity','OnlineBackup',\n                                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n                                  .agg(lambda x: list(x).count('Yes'))\n    \ndf_status['total'] = df_status.apply('sum',axis=1)\n\nfor x in df_status.drop(columns='total').columns:\n    df_status[x] = (df_status[x] * 100 / df_status.total).round()\ndf_status.drop(columns='total', inplace=True)\n\n\ndf_status.plot(kind='bar', rot=0)\nplt.title('Benefit count comparison between status (%)', size=12, weight='bold')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()\n\n\n\n\n\nSingle and PartnerOnly customers tend to prefer entertainment benefits such as StreamingTV and StreamingMovies compared to other customers. Additionally, these customers show a lower preference for using TechSupport and OnlineSecurity.\n\n\n\nBenefits analysis\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.countplot(df[df.Services != 'Phone Only'], \n              x = 'TotalBenefits', ax=axarr[0])\n\nsns.barplot(df[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]\\\n            .apply(lambda x: list(x).count('Yes')).reset_index(), x = 'index', y = 0, ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Count', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None)\naxarr[1].set_title('Benefits Count', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\nThe average number of TotalBenefits taken by customers is around 3, with StreamingTV and StreamingMovies being the most popular choices.\n\n\ndf_total = pd.DataFrame()\nfor x in ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']:\n    total = list(df[df[x] == 'Yes']['Churn']).count('Yes') / len(df[df[x] == 'Yes']['Churn'])\n    df_total = pd.concat([df_total, pd.DataFrame([x],[total])])\n\n\nfig, axarr = plt.subplots(1,2, figsize=(12, 6))\nsns.barplot(df.groupby('TotalBenefits')[['Churn']]\\\n            .agg(lambda x: list(x).count('Yes') * 100 / len(x)).round().reset_index(), \n            x='TotalBenefits', \n            y='Churn', ax=axarr[0])\n\nsns.barplot(df_total.reset_index(), \n            x=0, \n            y='index', \n            ax=axarr[1])\n\naxarr[0].set_title('TotalBenefits Churn probability', size=12, weight='bold')\naxarr[0].set(ylabel=None)\n\naxarr[1].set(ylabel=None, xlabel='Benefits')\naxarr[1].set_title('Benefits Churn probability', size=12, weight='bold')\naxarr[1].tick_params(axis='x', rotation=25)\nfig.tight_layout()\nplt.show()\n\n\n\n\n\nWhile StreamingTV and StreamingMovies are the most favored choices, the churn probability associated with them is also the highest.\n\n\n\nChurn analysis\n\nfig, axarr = plt.subplots(1, figsize=(10, 6))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                hue ='Churn', \n                s=20)\n\nplt.fill_between((68 , 97),20, alpha=0.2, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.2, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs Churn', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\n\nHere, I have created two areas, denoted by green and blue, both focusing on MonthlyCharges in the range of 70 - 95 USD. This price range corresponds to the highest churn probability. The green area represents customers with low tenure and is predominantly occupied by churned customers, while the blue area represents customers with high tenure and is predominantly occupied by non-churned customers.\n\n\nplt.subplots(1, figsize=(15, 8))\nsns.scatterplot(data=df, \n                x = 'MonthlyCharges', \n                y = 'tenure', \n                s=35, \n                hue='TotalBenefits', \n                style='InternetService', \n                palette='coolwarm')\n\nplt.fill_between((68 , 97),20, alpha=0.15, color='green')\nplt.fill_between((68 , 97),52.5, 72.5, alpha=0.15, color='blue')\n\nplt.title('MonthlyCharges vs tenure vs TotalBenefits vs InternetService', size = 15, weight = 'bold')\nplt.show()\n\n\n\n\n\nStill on the same plot, I have added TotalBenefits and InternetService. It can be observed that in the green area, Fiber optic is the dominant InternetService with low TotalBenefits. On the other hand, the blue area is dominated by DSL with high TotalBenefits. This indicates that customers, at the same price point, tend to choose DSL with high TotalBenefits rather than Fiber optic with low TotalBenefits. Note that Fiber optic prices are doubled than DSL.\n\nWith the observed pattern above, we can create an important new feature, which we will refer to as ‘FO_LB’ (Fiber optic_Low benefit). I will assign a value of ‘1’ to indicate that the internet service is Fiber optic and the Totalbenefits taken are less than or equal to 3. For other cases, I will assign ‘0’.\n\ndf['FO_LB'] = df[['InternetService','TotalBenefits']].apply(\n    lambda x: 1 if (x['InternetService'] == 'Fiber optic') & (x['TotalBenefits'] &lt;= 3) else 0, axis=1)"
  },
  {
    "objectID": "ipynb/final-project-original.html#modelling",
    "href": "ipynb/final-project-original.html#modelling",
    "title": "Table Of Contents",
    "section": "Modelling",
    "text": "Modelling\n\nOne important thing to address before we proceed is considering the types of errors to make this project as realistic as possible. Typically, there are two types of errors: false positive (FP) and false negative (FN). However, in this project, I will introduce three types of errors.\n1.FP: False positive  2.FN1: False negative for customers with MonthlyCharges below 95 USD  3.FN2: False negative for customers with MonthlyCharges above 95 USD (VIP customers)  Let’s agree on the misclassification ratio, which is FP:FN1:FN2 = 1:3:5 \nIt’s important to note that this dataset is imbalanced, meaning there is a significant difference in the number of samples between the classes.\nBased on these problems, we can set up our model’s parameters as follows: 1.Hyperparameter tuning. 2.Decision threshold tuning. 3.Oversampling data using SMOTE. 4.Applying weights to the models. I will be using Random Forest, XGBoost, and Logistic Regression.\nMetrics: Custom scoring based on sample misclassification. Precision. Recall. F1_score. Once the models are evaluated using these metrics, I will interpret the best model.\n\nFeature selection & encoding\n\ndf1 = df.copy()\n\n\ndf = df1.copy()\n\n\n#drop columns\ndf.drop(columns = ['Services','MonthlyChargesEstimationDifference','Status','PaperlessBilling','PaymentMethod'], inplace=True)\n\n\nI have dropped the columns from ‘Services’ to ‘Status’ as these columns were engineered features created for simpler exploratory data analysis (EDA). Additionally, I have also dropped the ‘PaperlessBilling’ and ‘PaymentMethod’ columns because, in the business context, these columns are considered irrelevant for determining customer churn since they represent optional ‘features’ for customers.\n\n\n#converting 'No internet service' to 'No' in benefit columns.\nKolomBenefit = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfor x in KolomBenefit:\n    df[x] = df[x].apply(lambda x: 'No' if x == 'No internet service' else x)\n\n\n#converting 'No phone service' to 'No'\ndf['MultipleLines'] = df[x].apply(lambda x: 'No' if x == 'No phone service' else x)\n\n\n#dict to mapping string to numerical.\nvalue_mapping = {\n    'No': 0,\n    'Yes' : 1,\n    'Male' : 1,\n    'Female' : 0\n}\n\n\n#binary encoding\nbinary = list(df.drop(columns=['tenure','InternetService','MonthlyCharges','TotalCharges','TotalBenefits','Contract','FO_LB']).columns)\n\nfor col in binary:\n    df[col] = df[col].map(value_mapping).astype('int64')\n\n\n#label encoding\ndf['Contract'] = df['Contract'].apply(lambda x: 1 if x == 'Month-to-month' else 2 if x == 'One year' else 3) \n\n\n#one hot encoding\ndf = pd.get_dummies(df, columns=['InternetService'])\n\n\n#feature selection\ndf = df[['Contract','tenure','InternetService_Fiber optic','MonthlyCharges','FO_LB','InternetService_No','Churn']]\ndf = df.rename(columns={\n                'InternetService_Fiber optic':'Fiber_optic',\n                'InternetService_No':'No_internet'})\n\n\nHere I only choose a feature that have a strong predictive power (by using feature of importances)\n\n\n\nSplits data and define custom function\n\n#split train-test\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns='Churn'), df.Churn.to_numpy(), test_size = 0.2, random_state=123)\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\n\n#custom function to do threshold tuning and custom metrics (used in GridSearchCV)\ndef my_scorer_2(clf, X, y_true, thres = np.arange(0.1,1,0.1)):\n    result_dict = {}\n    for threshold in np.atleast_1d(thres):\n        y_pred = (clf.predict_proba(X)[:,1] &gt; threshold).astype(int)\n        X_segment = (X['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\n        y_stack = np.column_stack((X_segment, y_pred, y_true))\n        y_stack_reg, y_stack_vip = y_stack[y_stack[:,0] == 0], y_stack[y_stack[:,0] == 1]\n        cm_reg = confusion_matrix(y_stack_reg[:,2], y_stack_reg[:,1])\n        cm_vip = confusion_matrix(y_stack_vip[:,2], y_stack_vip[:,1])\n        fn_reg, fn_vip = cm_reg[1][0], cm_vip[1][0]\n        fp = cm_reg[0][1] + cm_vip[0][1]\n        loss_score = (fp * 1) + (fn_reg * 3) + (fn_vip * 5)\n        result_dict[threshold] = np.array([loss_score, metrics.precision_score(y_true, y_pred, zero_division = 0), \n                                           metrics.recall_score(y_true, y_pred), metrics.f1_score(y_true, y_pred)])\n        \n    result_np = np.array([np.insert(value, 0, key) for key, value in result_dict.items()])\n    best_np = result_np[result_np[:,1] == np.min(result_np[:,1])][0]\n    return best_np\n\ndef my_scorer_threshold(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[0]\n\ndef my_scorer_ls(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[1]\n\ndef my_scorer_precision(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[2]\n\ndef my_scorer_recall(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[3]\n\ndef my_scorer_f1(clf, X, y_true):\n    return my_scorer_2(clf, X, y_true)[4]\n        \n        \n\n\n#Grid scoring parameter\ngrid_scoring = {\n    'threshold': my_scorer_threshold,\n    'loss_score': my_scorer_ls,\n    'precision': my_scorer_precision,\n    'recall': my_scorer_recall,\n    'f1': my_scorer_f1\n}\n\n\n#define weight by missclassification cost which is FP:FN1:FN2 = 1:3:5\nX_segment = (X_train['MonthlyCharges'] &gt; 95).to_numpy().astype(int)\narr_weight = np.column_stack((X_segment, y_train))\nweight = np.apply_along_axis(lambda x: 1 if x[1] == 0 else 5 if x[0] == 1 else 3 , axis=1, arr=arr_weight)\n\n\n\nModel building 1 / Hyperparameter tuning + threshold tuning\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train)\n\n#evaluate the model\nmb1_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb1_rf = np.append(mb1_rf, grid_result.iloc[0,0])\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb1_xg = np.append(mb1_xg, grid_result.iloc[0,0])\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train)\n\n#evaluate the model\nmb1_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb1_lg = np.append(mb1_lg, grid_result.iloc[0,0])\n\n\nresult_mb1 = pd.DataFrame([mb1_rf,mb1_xg,mb1_lg])\nresult_mb1.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb1['model'] = ['MB1_RF','MB1_XG','MB1_Log_Reg']\nresult_mb1\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n\n\n\n\n\n\n\nModel building 2 / Hyperparameter tuning + threshold tuning + SMOTE\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf_smote = {\n    'class__n_estimators': [250 , 400],\n    'class__max_depth': [10, 25, 50],\n    'class__min_samples_split': [25, 50, 70, 120],\n    'class__min_samples_leaf': [50, 75, 120],\n    'class__bootstrap' : [True, False]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinerf = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', RandomForestClassifier())])\n\n#run grid search cv\nrf = GridSearchCV(estimator = pipelinerf,\n                  param_grid = param_grid_rf_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nrf = RandomForestClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nrf = rf.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb2_rf = np.append(mb2_rf, params)\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg_smote = {\n    'class__learning_rate': [0.1, 0.01, 0.001],\n    'class__n_estimators': [100, 500],\n    'class__max_depth': [5, 10, 25],\n    'class__subsample': [0.8, 0.9, 1.0],\n    'class__colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#create imbalanced pipeline to SMOTE \npipelinexg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', XGBClassifier())])\n\n#run grid search cv\nxg = GridSearchCV(estimator = pipelinexg,\n                  param_grid = param_grid_xg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nxg = XGBClassifier(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nxg = xg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb2_xg = np.append(mb2_xg, params)\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg_smote = {\n    'class__penalty': ['l1', 'l2'], \n    'class__C': [0.1, 1.0, 10.0],  \n    'class__solver': ['liblinear'],  \n    'class__max_iter': [50,100,200] \n}\n\n\n#create imbalanced pipeline to SMOTE \npipelinelg = Pipeline([\n        ('sampling', SMOTE()),\n        ('class', LogisticRegression())])\n\n#run grid search cv\nlg = GridSearchCV(estimator = pipelinelg,\n                  param_grid = param_grid_lg_smote,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\nparams = grid_result.iloc[0,0]\n\nparams_update = {}\nfor key, value in params.items():\n    new_key = key.replace('class__', '')\n    params_update[new_key] = value\nparams = params_update\n    \n#train model with the best hyperparameter\nlg = LogisticRegression(**params)\n\n#train model with SMOTE train data\nX_train1, y_train1 = SMOTE().fit_resample(X_train, y_train)\nlg = lg.fit(X_train1, y_train1)\n\n#evaluate the model\nmb2_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb2_lg = np.append(mb2_lg, params)\n\n\nresult_mb2 = pd.DataFrame([mb2_rf,mb2_xg,mb2_lg])\nresult_mb2.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb2['model'] = ['MB2_RF','MB2_XG','MB2_Log_Reg']\nresult_mb2\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n\n\n\n\n\n\n\nModel building 3 / Hyperparameter tuning + threshold tuning + custom weight\n\n#RANDOM FOREST MODELLING\n\n#define parameter for tuning\nparam_grid_rf = {\n    'n_estimators': [250 , 400],\n    'max_depth': [10, 25, 50],\n    'min_samples_split': [25, 50, 70, 120],\n    'min_samples_leaf': [50, 75, 120],\n    'bootstrap' : [True, False]\n}\n\n#run grid search cv\nrf = GridSearchCV(estimator = RandomForestClassifier(),\n                  param_grid = param_grid_rf,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nrf.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(rf.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nrf = RandomForestClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nrf = rf.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_rf = my_scorer_2(rf, X_test, y_test, grid_result.iloc[0,1])\nmb3_rf = np.append(mb3_rf, grid_result.iloc[0,0])\n\n\n#XGBOOST MODELLING\n\n#define parameter for tuning\nparam_grid_xg = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'n_estimators': [100, 500],\n    'max_depth': [5, 10, 25],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n#run grid search cv\nxg = GridSearchCV(estimator = XGBClassifier(),\n                  param_grid = param_grid_xg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nxg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(xg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nxg = XGBClassifier(**grid_result.iloc[0,0])\n\n#train model with train data\nxg = xg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_xg = my_scorer_2(xg, X_test, y_test, grid_result.iloc[0,1])\nmb3_xg = np.append(mb3_xg, grid_result.iloc[0,0])\n\n\n#LOGISTIC REGRESSION MODELLING\n\n#define parameter for tuning\nparam_grid_lg = {\n    'penalty': ['l1', 'l2'], \n    'C': [0.1, 1.0, 10.0],  \n    'solver': ['liblinear'],  \n    'max_iter': [50,100,200] \n}\n\n\n#run grid search cv\nlg = GridSearchCV(estimator = LogisticRegression(),\n                  param_grid = param_grid_lg,\n                  cv=5,\n                  scoring = grid_scoring, refit=False, n_jobs = -1)\n\n#fit grid search cv with train data\nlg.fit(X_train, y_train, sample_weight = weight)\n\n#selecting the best parameter and metrics\ngrid_result = pd.DataFrame(lg.cv_results_)\ngrid_result = grid_result[grid_result['mean_test_loss_score'] == grid_result['mean_test_loss_score'].min()][['params','mean_test_threshold','mean_test_loss_score','mean_test_precision','mean_test_recall','mean_test_f1']]\n\n#train model with the best hyperparameter\nlg = LogisticRegression(**grid_result.iloc[0,0])\n\n#train model with train data\nlg = lg.fit(X_train, y_train, sample_weight = weight)\n\n#evaluate the model\nmb3_lg = my_scorer_2(lg, X_test, y_test, grid_result.iloc[0,1])\nmb3_lg = np.append(mb3_lg, grid_result.iloc[0,0])\n\n\nresult_mb3 = pd.DataFrame([mb3_rf,mb3_xg,mb3_lg])\nresult_mb3.columns = ['threshold','score','precision','recall','f1','params']\nresult_mb3['model'] = ['MB3_RF','MB3_XG','MB3_Log_Reg']\nresult_mb3\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\n\nfinal_result = pd.concat([result_mb1, result_mb2, result_mb3]).sort_values('score')\nfinal_result\n\n\n\n\n\n\n\n\nthreshold\nscore\nprecision\nrecall\nf1\nparams\nmodel\n\n\n\n\n0\n0.24\n539.0\n0.473101\n0.828255\n0.602216\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB1_RF\n\n\n2\n0.22\n541.0\n0.467492\n0.836565\n0.599801\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB1_Log_Reg\n\n\n1\n0.44\n546.0\n0.472266\n0.825485\n0.600806\n{'colsample_bytree': 1.0, 'learning_rate': 0.0...\nMB2_XG\n\n\n2\n0.48\n546.0\n0.472178\n0.822715\n0.600000\n{'C': 1.0, 'max_iter': 50, 'penalty': 'l2', 's...\nMB2_Log_Reg\n\n\n0\n0.48\n549.0\n0.456193\n0.836565\n0.590420\n{'bootstrap': True, 'max_depth': 25, 'min_samp...\nMB3_RF\n\n\n1\n0.48\n551.0\n0.465409\n0.819945\n0.593781\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB3_XG\n\n\n0\n0.42\n557.0\n0.454955\n0.839335\n0.590068\n{'bootstrap': False, 'max_depth': 25, 'min_sam...\nMB2_RF\n\n\n1\n0.20\n558.0\n0.449190\n0.844875\n0.586538\n{'colsample_bytree': 0.8, 'learning_rate': 0.0...\nMB1_XG\n\n\n2\n0.44\n571.0\n0.433803\n0.853186\n0.575163\n{'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 's...\nMB3_Log_Reg\n\n\n\n\n\n\n\n\nAnalysis of how the models performed: 1.RandomForest performs best with hyperparameter tuning and a lower decision threshold. However, this model performs worst when using SMOTE. 2.LogisticRegression performs worst when using ‘sample weighting’. 3.XGBoost performs best when using SMOTE. 4.It’s important to note that all models produce similar results when using their best parameters and conditions. 5.In my opinion, the greatest impact is achieved by using hyperparameter tuning and decision threshold tuning, rather than using SMOTE and weighting techniques."
  },
  {
    "objectID": "ipynb/final-project-original.html#model-interpretation",
    "href": "ipynb/final-project-original.html#model-interpretation",
    "title": "Table Of Contents",
    "section": "Model Interpretation",
    "text": "Model Interpretation\n\nIn this section, I want to show you how to interpret a tree-based model, such as Random Forest, so we can have a better understanding of how the model actually works.\n\n#selecting the best parameter for random forest\nrf_param = final_result[final_result['model'] == 'MB1_RF']['params'][0]\nrf_param\n\n{'bootstrap': True,\n 'max_depth': 25,\n 'min_samples_leaf': 50,\n 'min_samples_split': 50,\n 'n_estimators': 250}\n\n\n\nrf = RandomForestClassifier(**rf_param)\nrf.fit(X_train, y_train)\n\nRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier(max_depth=25, min_samples_leaf=50, min_samples_split=50,\n                       n_estimators=250)\n\n\n\nPartial dependence plot (PDP) & Individual conditional expectation (ICE)\nWhat is ICE? It is a plot that shows how a model makes predictions based on changing the value of one or more features, while keeping the values of other features constant. This provides us with more insights and understanding of how the model treats features to make predictions. ICE works per row (or per customer in this case), and PDP is simply the average of ICE.\n\ndef pdp_ice_plot(model, df_test, column, clusters=True):\n    df_test = df_test.copy()\n    pdp_isolate = pdp.PDPIsolate(model = model, df = df_test, \n                      num_grid_points=15,\n                      model_features = df_test.columns, \n                      feature = column, feature_name=column)\n    pdp_isolate.plot(\n                center=True, plot_lines=True,\n                cluster=clusters, n_cluster_centers=5,cluster_method='accurate',\n                plot_pts_dist=False, to_bins=True,\n                show_percentile=False, which_classes=None,\n                figsize=(10,6), dpi=300,\n                ncols=2, plot_params={\"pdp_hl\": True},\n                engine='matplotlib', template='plotly_white')\n    plt.show()\n    \n\n\npdp_ice_plot(rf, X_test, 'MonthlyCharges', False)\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\nThe light blue lines represent ICE (Individual Conditional Expectation), and the yellowish blue line represents PDP (Partial Dependence Plot). The X-axis represents MonthlyCharges, while the Y-axis represents the change in prediction probability. At MonthlyCharges of 60.7 USD, you can observe that some customers experience a significant increase in churn probability as the MonthlyCharges increase. However, it is important to note that not all customers have the same response. Some customers are minimally affected, and some may not be affected at all.\n\n\npdp_ice_plot(rf, X_test, 'MonthlyCharges')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\nThis is the same plot as above, but I have grouped the ICE into 5 clusters for easier viewing and analysis. You can see that there are some customers who experience a significant increase in churn probability as the MonthlyCharges increase.\n\n\npdp_ice_plot(rf, X_test, 'tenure')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\nThe longer the tenure, the lower the churn probability. However, the effect is not the same for all customers. Some customers are greatly affected, while others are barely affected.\n\n\npdp_ice_plot(rf, X_test, 'Contract')\n\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\nThe same also goes with Contract. Longer contract means lower churn probability.\n\n\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=6,\n                              model_features = X_test.columns, \n                              features=['MonthlyCharges','tenure'], \n                              feature_names=['MonthlyCharges','tenure'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s analyze the combination of MonthlyCharges and tenure. We can observe a spike in churn probability for MonthlyCharges ranging from 56.3 USD to 79.2 USD, particularly for customers with a tenure of less than 7 months.\n\n\nX_test_copy = X_test.copy()\npdp_interact = pdp.PDPInteract(model=rf, df=X_test_copy,\n                              num_grid_points=10,\n                              model_features = X_test.columns, \n                              features=['tenure','Contract'], \n                              feature_names=['tenure','Contract'])\npdp_interact.plot(\n            plot_type=\"grid\", plot_pdp=True,\n            to_bins=True, show_percentile=False,\n            which_classes=None, figsize=(10,6),\n            dpi=300, ncols=2, plot_params=None, \n            engine='matplotlib', template='plotly_white',\n)\nplt.show()\n\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\nobtain pred_func from the provided model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model produces similar churn probabilities for customers with a combination of a 2-year contract and low tenure compared to those with a month-to-month contract and medium tenure (24-36 months).\n\nYou can see how PDP and ICE plots can be very beneficial in understanding how the model utilizes features to make predictions. In the next section, I will demonstrate how to assess the model’s prediction confidence level.\n\n\nConfidence level based on trees’ standard deviation and confidence interval.\nTree-based models like RandomForest make predictions by using the mean of all the trees’ prediction probabilities. However, instead of solely relying on the mean, we can also calculate the standard deviation. A higher standard deviation indicates lower confidence in the predictions. Additionally, we can utilize confidence intervals, such as 95% or even more extreme at 99%.\n\n#extract all trees' prediction probability per row\npredict = np.stack([x.predict_proba(X_test)[:,1] for x in rf.estimators_])\n\n\n#assign mean and std. deviation of trees' prediction probability.\ndf_pred = X_test.copy()\ndf_pred['avg'] = np.round(np.mean(predict, axis = 0) * 100, 2)\ndf_pred['std_dev'] = np.round(np.std(predict, axis = 0) * 100, 2)\n\n\nplt.figure(figsize=(10,6))\nsns.histplot(df_pred['std_dev'],color='skyblue', kde=True, edgecolor='none')\nplt.title('Standard deviation distribution', weight='bold')\nplt.show()\n\n\n\n\n\nMost of predictions have std.deviation under 10%. Let’s calculate confidence interval with 99%.\n\n\ndf_pred['CI-99%'] = (2.576 * df_pred['std_dev'] / np.sqrt(len(predict))) * 100 / (df_pred['avg'])\n\n\ndf_pred[df_pred.avg &gt; 40].sort_values('CI-99%', ascending=False).head(5)\n\n\n\n\n\n\n\n\nContract\ntenure\nFiber_optic\nMonthlyCharges\nFO_LB\nNo_internet\navg\nstd_dev\nCI-99%\n\n\n\n\n852\n2\n7\n1\n94.05\n1\n0\n40.06\n25.08\n10.199818\n\n\n499\n1\n58\n1\n98.70\n1\n0\n41.05\n18.24\n7.239149\n\n\n1186\n1\n59\n1\n101.10\n1\n0\n40.37\n16.73\n6.751699\n\n\n1137\n1\n15\n1\n96.30\n0\n0\n48.14\n19.69\n6.663701\n\n\n1184\n1\n10\n1\n92.50\n0\n0\n48.17\n19.12\n6.466765\n\n\n\n\n\n\n\n\nLet’s consider the example of row 1. The model predicts a 40% probability of churn for the customer, with a confidence interval of +- 10%. By default, the model’s output indicates that the customer will not churn. However, due to the high confidence interval, it is safer to assume that the customer will churn.\n\nChecking the standard deviation and confidence interval of the trees is extremely useful, particularly when the cost of ‘False Negative’ is significant and can have severe consequences."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Vertikal Willis",
    "section": "",
    "text": "Telco customer churn\n\n\n\n\n\n\n\nclassification\n\n\nmachine-learning\n\n\ndata-science\n\n\n\n\nHow I deeply process telco customer churn dataset.\n\n\n\n\n\n\nAug 3, 2023\n\n\nvertikal\n\n\n\n\n\n\nNo matching items"
  }
]